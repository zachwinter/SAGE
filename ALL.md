# 🌟 Complete SAGE Documentation

*Generated on 2025-08-30T04:52:13.706Z in 32ms*

**SAGE** — *"A Codebase is a Living Society."*

This comprehensive document contains all README and documentation files from the project, optimized for **Gemini Pro** (88,428 total tokens).

## 📊 Document Statistics

| Metric | Value |
|--------|-------|
| 📄 Total Files | 54 |
| ✅ Healthy Files* | 15 |
| 📏 Total Lines | 11,161 |
| 🔤 Total Characters | 353,627 |
| 🎯 Estimated Tokens | 88,428 |
| ⏱️ Build Time | 32ms |

*Healthy files: Have proper headings, balanced code blocks, reasonable line lengths, and no encoding issues.

## 📋 Table of Contents

### 🏠 Core
- [🏠 Main Project README](#main-project-readme) *(653 tokens)*

### 📚 Documentation
- [📚 Documentation Hub](#documentation-hub) *(1874 tokens)*
- [📚 Documentation: Archivist](#documentation-archivist) *(1220 tokens)*
- [📚 Documentation: Delegator](#documentation-delegator) *(1018 tokens)*
- [📚 Documentation: Guardian](#documentation-guardian) *(986 tokens)*
- [📚 Documentation: Librarian](#documentation-librarian) *(847 tokens)*
- [📚 Documentation: Sage](#documentation-sage) *(734 tokens)*
- [📚 Documentation: Warden](#documentation-warden) *(852 tokens)*
- [📚 Documentation: Contracts](#documentation-contracts) *(2027 tokens)*
- [📚 Documentation: Valve](#documentation-valve) *(1678 tokens)*
- [📚 Documentation: Vault-Warden-Protocol](#documentation-vault-warden-protocol) *(1220 tokens)*
- [📚 Documentation: Lexicon](#documentation-lexicon) *(2254 tokens)*
- [📜 The SAGE Manifesto](#the-sage-manifesto) *(811 tokens)*
- [📚 Documentation: Principles](#documentation-principles) *(1250 tokens)*
- [📚 Documentation: Instant-Recall](#documentation-instant-recall) *(911 tokens)*
- [📚 Documentation: Onboarding-Workflow](#documentation-onboarding-workflow) *(1287 tokens)*
- [📚 Documentation: Relay](#documentation-relay) *(5970 tokens)*
- [📚 Documentation: README_GENERATION_SUMMARY](#documentation-readme-generation-summary) *(1388 tokens)*
- [📚 Documentation: AGENT_WORKFLOW](#documentation-agent-workflow) *(1547 tokens)*
- [📚 Documentation: PACKAGE_DOCS](#documentation-package-docs) *(1888 tokens)*
- [📚 Documentation: PACKAGE_TODO_TEMPLATE](#documentation-package-todo-template) *(821 tokens)*
- [📚 Documentation: Package-Standards](#documentation-package-standards) *(2396 tokens)*

### 🖥️ Applications
- **cli** *(13127 tokens total)*
  - [🖥️ App: cli (README)](#app-cli-readme) *(583 tokens)*
  - [🖥️ App: cli (PHASE-1-extract-llm-layer)](#app-cli-phase-1-extract-llm-layer) *(1349 tokens)*
  - [🖥️ App: cli (PHASE-2-build-tools-foundation)](#app-cli-phase-2-build-tools-foundation) *(2352 tokens)*
  - [🖥️ App: cli (PHASE-3-extract-ui-components)](#app-cli-phase-3-extract-ui-components) *(2221 tokens)*
  - [🖥️ App: cli (PHASE-4-implement-agents)](#app-cli-phase-4-implement-agents) *(3281 tokens)*
  - [🖥️ App: cli (PHASE-5-aql-integration)](#app-cli-phase-5-aql-integration) *(3341 tokens)*
- [🖥️ App: valve (README)](#app-valve-readme) *(1618 tokens)*

### 📦 Packages
- **agents** *(1994 tokens total)*
  - [📦 Package: agents (README)](#package-agents-readme) *(1277 tokens)*
  - [📦 Package: agents (CONTRACT)](#package-agents-contract) *(717 tokens)*
- **aql** *(9915 tokens total)*
  - [📦 Package: aql (README)](#package-aql-readme) *(922 tokens)*
  - [📦 Package: aql (examples/README)](#package-aql-examples-readme) *(1616 tokens)*
  - [📦 Package: aql (examples/experiments/README)](#package-aql-examples-experiments-readme) *(1490 tokens)*
  - [📦 Package: aql (CONTRACT)](#package-aql-contract) *(769 tokens)*
  - [📦 Package: aql (docs/roadmap)](#package-aql-docs-roadmap) *(2285 tokens)*
  - [📦 Package: aql (docs/syntax)](#package-aql-docs-syntax) *(2833 tokens)*
- **chronicle** *(2399 tokens total)*
  - [📦 Package: chronicle (README)](#package-chronicle-readme) *(1141 tokens)*
  - [📦 Package: chronicle (CONTRACT)](#package-chronicle-contract) *(1258 tokens)*
- **graph** *(3083 tokens total)*
  - [📦 Package: graph (README)](#package-graph-readme) *(1048 tokens)*
  - [📦 Package: graph (CONTRACT)](#package-graph-contract) *(2035 tokens)*
- **llm** *(3360 tokens total)*
  - [📦 Package: llm (README)](#package-llm-readme) *(1043 tokens)*
  - [📦 Package: llm (CONTRACT)](#package-llm-contract) *(2317 tokens)*
- **mcp** *(3428 tokens total)*
  - [📦 Package: mcp (README)](#package-mcp-readme) *(1140 tokens)*
  - [📦 Package: mcp (CONTRACT)](#package-mcp-contract) *(2288 tokens)*
- **test-utils** *(4126 tokens total)*
  - [📦 Package: test-utils (README)](#package-test-utils-readme) *(1308 tokens)*
  - [📦 Package: test-utils (CONTRACT)](#package-test-utils-contract) *(2818 tokens)*
- **tools** *(3758 tokens total)*
  - [📦 Package: tools (README)](#package-tools-readme) *(1370 tokens)*
  - [📦 Package: tools (CONTRACT)](#package-tools-contract) *(2388 tokens)*
- **ui** *(4023 tokens total)*
  - [📦 Package: ui (README)](#package-ui-readme) *(1360 tokens)*
  - [📦 Package: ui (CONTRACT)](#package-ui-contract) *(2663 tokens)*
- **utils** *(3609 tokens total)*
  - [📦 Package: utils (README)](#package-utils-readme) *(1247 tokens)*
  - [📦 Package: utils (CONTRACT)](#package-utils-contract) *(2362 tokens)*

### 📄 Other
- [📄 fixtures › README.md](#fixtures-readme-md) *(356 tokens)*

---

🏛️ # 📚 Documentation Hub

> **📁 Source File:** `DOCS/README.md` • *157 lines, 1874 tokens* • Hash: `d5c20506`

# 📚 SAGE Documentation Hub

Welcome to the comprehensive documentation for **SAGE** — *"A Codebase is a Living Society."*

This hub provides structured access to all SAGE documentation, organized for different audiences and use cases.

## 🎯 Quick Navigation

### 🏠 **New to SAGE?** Start Here
1. **[📜 The Manifesto](./core-concepts/Manifesto.md)** — Understand the vision and philosophy
2. **[🧠 Core Principles](./core-concepts/Principles.md)** — Learn the constitutional doctrines  
3. **[📖 Lexicon](./core-concepts/Lexicon.md)** — Master the shared vocabulary
4. **[🚧 Project Status](../README.md#-project-status)** — Current development state and roadmap

### 👥 **Different Audiences, Different Paths**

#### 🆕 As a New Contributor
*"I want to understand this project and contribute effectively."*
1. [📜 The Manifesto](./core-concepts/Manifesto.md) — The why behind SAGE
2. [🧠 Principles](./core-concepts/Principles.md) — The rules we follow
3. [📖 Lexicon](./core-concepts/Lexicon.md) — The language we speak
4. [🔄 Onboarding Workflow](./guides/Onboarding-Workflow.md) — How to join the society
5. [🧪 Testing & Development](./guides/Relay.md) — How to build and test

#### 🖥️ As a CLI User
*"I want to use SAGE to enhance my development workflow."*
1. **[🚧 Current Status](../README.md#-project-status)** — Check development progress
2. **[💬 Chat Interface Design](../apps/cli/README.md)** — Understand the planned interface
3. **[📊 Analysis Architecture](./guides/Instant-Recall.md)** — Learn the analysis approach
4. **[🔍 Query Language](../packages/aql/README.md)** — Explore the planned workflows

#### 🤖 As an Agent Developer  
*"I want to create or customize SAGE agents."*
1. [🏛️ Architecture Overview](#-architecture-overview) *(see diagram below)*
2. [📋 Contracts](./architecture/Contracts.md) — The agent interface specifications
3. [🎭 Archetypes](#-the-archetypes) — Available agent types
4. [🛠️ Agent Development](../packages/agents/README.md) — Build custom agents

#### 🔧 As a Package Developer
*"I want to contribute to or extend SAGE's core packages."*
1. [🏗️ Package Standards](./Package-Standards.md) — Follow our conventions
2. [📋 Individual Contracts](./architecture/Contracts.md) — Per-package specifications  
3. [🧪 Testing Framework](../packages/test-utils/README.md) — Our testing infrastructure
4. [🔄 Development Workflow](./guides/Relay.md) — Build, test, and release

---

## 🏛️ Architecture Overview

```mermaid
graph TB
    User[👤 User] --> UI[🎨 UI Components]
    UI --> CLI[🖥️ CLI]
    CLI --> |"Commands & Chat"| Agents[🤖 Agents]
    CLI --> |"Direct Queries"| Graph[(📊 Graph)]
    
    Agents --> |"Reasoning"| LLM[🧠 LLM]
    Agents --> |"Actions"| Tools[🛠️ Tools]
    Agents --> |"Events"| Chronicle[(📚 Chronicle)]
    Agents --> |"Knowledge"| Graph
    
    LLM --> |"MCP Protocol"| MCP[🔗 MCP]
    Tools --> |"Safe Operations"| FS[📁 FileSystem]
    Graph --> |"Code Analysis"| Valve[🎛️ Valve]
    Chronicle --> |"History Queries"| AQL[📝 AQL]
    
    Valve --> |"Continuous Updates"| Graph
    AQL --> |"Orchestration"| Agents
    
    style User fill:#e3f2fd
    style UI fill:#f1f8e9
    style CLI fill:#e1f5fe
    style Agents fill:#f3e5f5
    style Graph fill:#e8f5e8
    style Chronicle fill:#fff3e0
    style LLM fill:#fce4ec
```

**Core Data Flow:**
- **CLI** provides the human interface to the society
- **Agents** orchestrate reasoning and action using specialized archetypes
- **Graph** maintains the ground truth of code structure and relationships
- **Chronicle** preserves the complete history of all interactions
- **LLM** provides natural language understanding via multiple providers
- **Tools** enable safe, sandboxed operations on code and files

---

## 🎭 The Archetypes

SAGE's society consists of six specialized consciousnesses, each with distinct roles:

| Archetype | Role | Key Responsibilities |
|-----------|------|---------------------|
| **[🧙 Sage](./archetypes/Sage.md)** | *The Mind* | Strategic reasoning, plan creation, high-level orchestration |
| **[🛡️ Guardian](./archetypes/Guardian.md)** | *The Soul* | Code quality, consistency, protecting project integrity |
| **[📚 Librarian](./archetypes/Librarian.md)** | *The Custodian* | Data management, search, information retrieval |
| **[⚔️ Warden](./archetypes/Warden.md)** | *The Shield* | Security, access control, permission management |
| **[👥 Delegator](./archetypes/Delegator.md)** | *The Executor* | Task execution, workflow orchestration, delegation |
| **[📝 Archivist](./archetypes/Archivist.md)** | *The Memory* | Event logging, history preservation, continuity |

---

## 📋 Core Concepts Reference

### 🧠 Philosophy & Principles
- **[📜 The Manifesto](./core-concepts/Manifesto.md)** — Core vision and problem statement
- **[🧠 Principles](./core-concepts/Principles.md)** — Constitutional doctrines governing the society
- **[📖 Lexicon](./core-concepts/Lexicon.md)** — Shared vocabulary and definitions

### 📐 Technical Specifications  
- **[📋 Contracts](./architecture/Contracts.md)** — Agent and package interface contracts
- **[🔐 Vault-Warden Protocol](./architecture/Vault-Warden-Protocol.md)** — Security and permissions
- **[🎛️ Valve Configuration](./architecture/Valve.md)** — Perceptual apparatus setup

### 🔄 Processes & Workflows
- **[🚀 Onboarding Workflow](./guides/Onboarding-Workflow.md)** — Project initialization
- **[🧪 Relay System](./guides/Relay.md)** — Testing and development
- **[💾 Instant Recall](./guides/Instant-Recall.md)** — Memory and state management

---

## 🚀 Applications & Packages

### 🖥️ Applications
- **[CLI](../apps/cli/README.md)** — *"The Bridge to the Society"* — Primary human interface
- **[Valve](../apps/valve/README.md)** — *"The Perceptual Valve"* — Configurable awareness system

### 📦 Core Packages
- **[agents](../packages/agents/README.md)** — *The Society of Minds* — Core archetype logic
- **[graph](../packages/graph/README.md)** — *The Ground Truth* — Commit-addressable knowledge graph  
- **[chronicle](../packages/chronicle/README.md)** — *The Sacred Memory* — Append-only event logging
- **[llm](../packages/llm/README.md)** — *The Engine of Thought* — Multi-provider LLM interface
- **[aql](../packages/aql/README.md)** — *The Declarative Orchestrator* — Agent Query Language

### 🛠️ Supporting Packages
- **[mcp](../packages/mcp/README.md)** — *The Universal Translator* — Model Context Protocol
- **[tools](../packages/tools/README.md)** — *The Hands of the Agents* — Sandboxed operations
- **[ui](../packages/ui/README.md)** — *The Voice of the System* — Shared React components
- **[test-utils](../packages/test-utils/README.md)** — *The Controlled Environment* — Testing infrastructure
- **[utils](../packages/utils/README.md)** — *The Foundation* — Core utilities and helpers

---

## 🤝 Contributing

Ready to join the society? Here's how:

1. **📖 Read the Philosophy:** Start with [The Manifesto](./core-concepts/Manifesto.md) and [Principles](./core-concepts/Principles.md)
2. **🔍 Explore the Codebase:** Browse the source to understand the emerging structure  
3. **🧪 Set Up Development:** Follow the [Relay System](./guides/Relay.md) for testing
4. **🎯 Find Your Role:** Choose your contribution path from the [audiences](#-different-audiences-different-paths) above
5. **🚀 Start Contributing:** Follow our [Package Standards](./Package-Standards.md) and contracts

---

*Generated by SAGE — A Codebase is a Living Society*

---

🚀 # 🏠 Main Project README

> **📁 Source File:** `README.md` • *63 lines, 653 tokens* • Hash: `1dfa235a`

# SAGE

> **"A Codebase is a Living Society."**

SAGE transforms your codebase into a living ecosystem of specialized AI agents that understand, protect, and evolve your code alongside you.

## 🚧 Project Status

SAGE is currently **under active development**. The vision is real, the architecture is sound, but we're still building the society.

**What's Working:**
- Core philosophy and architectural patterns
- Graph-based code analysis foundation
- Agent archetype designs

**Coming Soon:**
- Production-ready CLI installation
- Full agent implementation
- Live codebase interaction

Want to contribute or stay updated? Check out our [Contributing Guide](./DOCS/README.md#-contributing) or explore the codebase to understand the vision.

## 🎭 What Makes SAGE Special

- **🧙 Living Agents:** Six specialized AI archetypes (Sage, Guardian, Librarian, Warden, Delegator, Archivist) each with distinct roles
- **📊 Code Graph:** Your entire codebase mapped as queryable relationships, not just text
- **📚 Perfect Memory:** Every interaction and change is remembered and can inform future decisions
- **🛡️ Built-in Protection:** Agents actively guard against inconsistencies and breaking changes
- **🎯 Contract-First:** Every component has explicit behavioral guarantees

## 📖 Documentation

**📚 [Complete Documentation Hub](./DOCS/README.md)** — Start here for comprehensive guides

**Quick Links:**
- [📜 The Philosophy](./DOCS/core-concepts/Manifesto.md) — Why SAGE exists and what it solves
- [🧠 Core Principles](./DOCS/core-concepts/Principles.md) — The rules that govern the society
- [📖 Lexicon](./DOCS/core-concepts/Lexicon.md) — Learn the shared vocabulary
- [🚀 CLI Guide](./apps/cli/README.md) — Master the primary interface

## 🏗️ Key Packages

| Package | Purpose | Status |
|---------|---------|---------|
| **[agents](./packages/agents/README.md)** | The society of specialized AI minds | 🚀 Production |
| **[graph](./packages/graph/README.md)** | Code knowledge representation | 🚀 Production |  
| **[llm](./packages/llm/README.md)** | Multi-provider AI interface | 🚀 Production |
| **[chronicle](./packages/chronicle/README.md)** | Immutable event history | 🚀 Production |
| **[aql](./packages/aql/README.md)** | Agent query language | 🔄 Active Development |
| **[mcp](./packages/mcp/README.md)** | Model Context Protocol | 🚀 Production |

## 🤝 Contributing

Join the living codebase! Read the **[Documentation Hub](./DOCS/README.md)** for contribution guidelines, architecture overview, and development setup.

## 📄 License

MIT

---

*SAGE • A Codebase is a Living Society*


---

🖥️ # 🖥️ App: cli (README)

> **📁 Source File:** `apps/cli/README.md` • *37 lines, 583 tokens* • Hash: `009f60e0`

# SAGE CLI

**"The Bridge to the Society."**

This application is the primary human-machine interface for the SAGE Framework. It is a powerful, interactive command-line tool that serves as the entry point for all developer-initiated conversations, commands, and workflows. It is the bridge through which a developer speaks to the collective consciousness of their codebase.

### Current Role

In its current form, this application is a comprehensive monolith containing the logic for UI, state management, LLM interaction, and agent-like behaviors. It is the proof-of-concept for the entire SAGE experience, orchestrating everything from the `sage ask` chat interface to the `sage ingest` analysis command.

### The Refactor Plan: A Great Extraction

The destiny of this application is to become a lean, powerful orchestrator. Its intelligence and capabilities will not be diminished; instead, they will be extracted into dedicated, reusable packages within the monorepo. This "great extraction" will make the system more modular, testable, and scalable.

- **UI Components & Rendering Logic** will move to `@sage/ui`.
- **Agent Tools (`Bash`, `GraphQuery`, etc.)** will move to `@sage/tools`.
- **The core logic for all SAGE agents** will be formalized in `@sage/agents`.
- **LLM interaction and prompt management** will move to `@sage/llm`.
- **Reading/writing to Chronicle files** will be handled by `@sage/chronicle`.

### Future Role: The Orchestrator

> **AQL integration (planned):** the CLI will expose `sage aql run <file.aql>` to
> compile and execute AQL queries against the active provider (` @sage/llm`) with
> streaming output and tool-call confirmation.

After the refactor, the `cli` will have one clear purpose: to orchestrate the collaboration between the user and the SAGE agents.

When a user runs `sage ask`, this application will:

1.  Instantiate the `Sage` agent from `@sage/agents`.
2.  Provide it with capabilities from `@sage/tools`.
3.  Power its reasoning with `@sage/llm`.
4.  Render the entire interaction using components from `@sage/ui`.

It will manage the high-level workflows and protocols—like Plan/Approve/Delegate and Reconciliation—but the deep logic for _how_ those protocols work will live in the dedicated packages. Its complexity will decrease as the power of the ecosystem increases.


---

🖥️ # 🖥️ App: valve (README)

> **📁 Source File:** `apps/valve/README.md` • *193 lines, 1618 tokens* • Hash: `2c920b78`

# SAGE Valve Implementation

This package contains the **Rust implementation** of the SAGE Valve, the perceptual apparatus for the SAGE framework.

For a complete conceptual overview of the SAGE Valve, its philosophy, and its role in the SAGE ecosystem, please see the primary documentation:

**➡️ [Main Documentation: The SAGE Valve](../DOCS/architecture/Valve.md)**

---

## Development & Testing

This document provides practical guidance for developers working on the Rust application.

### Testing Tips and Gotchas

Here's a comprehensive guide to testing in the SAGE Valve project, covering the challenges we've encountered and how to avoid them.

#### 1. Configuration File Testing

**Challenge**: The `ValveConfig::load_from_repo` function expects the configuration file to be located at `.sage/valve.yml` relative to the repository root.

**Solution**: Always create the `.sage` directory and place the configuration file within it:

```rust
let temp_dir = TempDir::new().expect("Failed to create temp directory");
let sage_dir = temp_dir.path().join(".sage");
std::fs::create_dir_all(&sage_dir).expect("Failed to create .sage directory");
let config_file = sage_dir.join("valve.yml");
fs::write(&config_file, config_str).expect("Failed to write config file");
```

**Footgun**: Forgetting to create the `.sage` subdirectory will result in a "missing config" error.

#### 2. Path Canonicalization Issues

**Challenge**: The `Registry::add` method canonicalizes paths using `canonicalize()`, which can lead to path comparison issues in tests.

**Solution**: Always compare canonicalized paths with canonicalized paths:

```rust
assert_eq!(codebase.path, test_path.canonicalize().unwrap());
```

**Footgun**: Comparing a canonicalized path with a non-canonicalized path will fail even if they refer to the same location.

#### 3. Directory Creation Before Adding to Registry

**Challenge**: The `Registry::add` method requires the path to exist and be canonicalizable.

**Solution**: Always create directories before adding them to the registry:

```rust
let test_path = temp_dir.path().join("test_project");
std::fs::create_dir_all(&test_path).expect("Failed to create test directory");
let codebase = registry.add(&test_path).expect("Failed to add codebase");
```

**Footgun**: Trying to add a non-existent directory will result in an "Invalid argument" error.

#### 4. UUID-based Registry Entries

**Challenge**: Each call to `Registry::add` creates a new entry with a unique UUID, even for the same path.

**Solution**: When testing removal by path, understand that it removes the first matching entry, not all entries:

```rust
// Add two codebases with the same path
let codebase1 = registry.add(&test_path).expect("Failed to add codebase");
let codebase2 = registry.add(&test_path).expect("Failed to add codebase");

// Remove by path (removes only the first match)
let removed = registry.remove_by_id_or_path(test_path.to_str().unwrap()).expect("Failed to remove codebase");
assert!(removed.is_some());

// The second entry still exists
let removed2 = registry.remove_by_id_or_path(&codebase2.id).expect("Failed to remove codebase");
assert!(removed2.is_none()); // This will fail because the entry still exists
```

**Footgun**: Assuming that adding the same path twice and then removing by path will remove both entries.

#### 5. Shared Registry Testing

**Challenge**: Testing the `SharedRegistry` requires understanding how `Arc` references work.

**Solution**: Use `std::ptr::eq` to compare `Arc` references:

```rust
let registry = Registry::load_or_default().expect("Failed to load registry");
let shared_registry = SharedRegistry::new(registry);
let shared_registry_clone = shared_registry.clone();

// Both should point to the same data
assert!(std::ptr::eq(shared_registry.0.as_ref(), shared_registry_clone.0.as_ref()));
```

**Footgun**: Trying to access fields of the `Arc` directly using dot notation (e.g., `shared_registry.0 .0`) will result in compilation errors.

#### 6. Persona Matching Tests

**Challenge**: Testing persona matching requires creating valid configuration files with proper syntax.

**Solution**: Use raw string literals for YAML configuration and ensure proper indentation:

```rust
let config_str = r#"
personas:
  TestWatcher:
    filters: ["**/*.txt"]
    triggers: ["test"]
"#;
```

**Footgun**: Incorrect YAML indentation or missing newlines can cause parsing errors.

#### 7. Test Environment Isolation

**Challenge**: Tests that modify global state or filesystem locations can interfere with each other.

**Solution**: Use `tempfile::TempDir` to create isolated test environments and set environment variables as needed:

```rust
let temp_dir = TempDir::new().expect("Failed to create temp directory");
std::env::set_var("HOME", temp_dir.path());
```

**Footgun**: Tests that share the same HOME directory or registry file can interfere with each other.

#### 8. Test Cleanup

**Challenge**: Tests that create files or modify system state should clean up after themselves.

**Solution**: Use RAII patterns with `TempDir` which automatically cleans up when it goes out of scope:

```rust
#[test]
fn test_something() {
    let temp_dir = TempDir::new().expect("Failed to create temp directory");
    // Test code here
    // temp_dir is automatically cleaned up when it goes out of scope
}
```

**Footgun**: Manually created temporary files that aren't cleaned up can accumulate and cause test failures.

#### 9. Regex Escaping in Tests

**Challenge**: Regex patterns in configuration files need to be properly escaped when used in raw strings.

**Solution**: Use double backslashes for regex patterns in YAML:

```rust
let config_str = r#"
personas:
  TestWatcher:
    filters: ["**/*.rs"]
    triggers: ["fn\s+main"]  # Note the double backslash
"#;
```

**Footgun**: Forgetting to escape backslashes in regex patterns will result in invalid regex errors.

#### 10. Test Coverage Strategy

To ensure comprehensive test coverage:

1. **Unit Tests**: Test individual functions and methods in isolation
2. **Integration Tests**: Test how modules work together
3. **Edge Cases**: Test error conditions and boundary cases
4. **Happy Path**: Test the expected normal flow
5. **State Management**: Test how state changes over time

### Running Tests

To run all tests:

```bash
cargo test
```

To run tests with output:

```bash
cargo test -- --nocapture
```

To run a specific test:

```bash
cargo test test_name
```


---

📄 # 📄 fixtures › README.md

> **📁 Source File:** `fixtures/README.md` • *40 lines, 356 tokens* • Hash: `85cad77b`

# SAGE Contract Fixtures

This directory contains normative fixtures that define the **exact** expected behavior for SAGE package implementations. Each fixture provides concrete input/output pairs that serve as the authoritative specification.

## Structure

- `canonical-json/` - JSON canonicalization and hashing fixtures
- `chronicle-events/` - Chronicle event serialization and ID computation
- `graph-schema/` - Graph queries with expected results
- `sha256/` - SHA256 hashing test vectors

## Usage

Contract implementers must ensure their code produces **bit-perfect** matches with these fixtures. No ambiguity about whitespace, key ordering, or hash encoding.

### Example: Canonical JSON

```ts
import { canonicalJSONStringify } from "@sage/utils";
import fs from "fs";

const input = JSON.parse(fs.readFileSync("fixtures/canonical-json/input.json"));
const expected = fs.readFileSync("fixtures/canonical-json/output.txt", "utf8");
const expectedHash = fs.readFileSync(
  "fixtures/canonical-json/output.sha256",
  "utf8"
);

const result = canonicalJSONStringify(input);
assert.strictEqual(result, expected);
assert.strictEqual(sha256(result), expectedHash);
```

## Adding New Fixtures

1. Create descriptive directory names that match contract acceptance tests
2. Provide both input and expected output files
3. Include hash/checksum files where determinism is critical
4. Update this README with usage examples


---

📦 # 📦 Package: agents (README)

> **📁 Source File:** `packages/agents/README.md` • *165 lines, 1277 tokens* • Hash: `0c9c01ff`

# @sage/agents

> "The Society of Minds."

## Overview

This package implements the core logic for SAGE's archetypal agents — **Sage, Guardian, Warden, Delegator, Archivist**. These agents are specialized consciousnesses that embody SAGE's constitutional principles and protocols, negotiating Plans with evidence from the **Code Graph** and **Chronicles**.

### Relationship with SAGE Valve

Agents are activated by the **[SAGE Valve](../../apps/valve/README.md)**, which detects relevant changes in the codebase and triggers agents through Persona configurations.

## Installation

```bash
pnpm add @sage/agents
```

## Quick Start

```typescript
import { Guardian } from "@sage/agents";

// Create a Guardian agent for a specific file
const guardian = new Guardian({
  filePath: "/src/UserService.ts",
  graph: graphClient,     // @sage/graph for code understanding
  chronicle: chronicleClient, // @sage/chronicle for memory
  tools: toolRegistry,    // @sage/tools for safe operations
  llm: llmClient         // @sage/llm for reasoning
});

// Review a proposed change plan
const decision = await guardian.reviewPlan(plan);
if (decision.type === "deny") {
  console.log(`Change denied: ${decision.reason}`);
} else {
  console.log(`Change approved: ${decision.justification}`);
}
```

## Core API

### Guardian

Reviews proposed changes to its file and enforces architectural principles.

```typescript
interface IGuardian {
  reviewPlan(plan: Plan): Promise<Approve | Deny>;
  reconcile(edit: RogueEdit): Promise<ReconciliationOutcome>;
  selfInquiry(): Promise<SelfInquiryReport>;
  bulletWoundCheck(assertions: Assertion[]): Promise<void>; // may HALT_AND_REPORT
}
```

### Delegator

Executes approved Plans atomically within a transaction boundary.

```typescript
interface IDelegator {
  execute(plan: Plan): Promise<ExecutionReport>;
}
```

### Warden

Reviews infrastructure changes and manages environment policies.

```typescript
interface IWarden {
  reviewPlan(plan: Plan): Promise<Approve | Deny>;
  promote(build: BuildRef, from: Env, to: Env): Promise<PromotionResult>;
  postMortem(incident: Incident): Promise<PostMortemReport>;
}
```

### Sage

Ideates solutions and mediates between conflicting agent reviews.

```typescript
interface ISage {
  ideate(input: Intent): Promise<Ideation>;
  draftPlan(ideation: Ideation): Promise<Plan>;
  mediate(reviews: ReviewSet): Promise<MediationResult>;
}
```

### Archivist

Records and queries the historical lineage of files and directories.

```typescript
interface IArchivist {
  record(event: LineageEvent): Promise<void>;
  query(q: HistoryQuery): Promise<HistoryAnswer>;
}
```

## Key Protocols

### Bullet Wound Invariant
When a Guardian detects contradiction between its Chronicle and the Code Graph, it invokes `HALT_AND_REPORT`, freezing execution until reconciliation.

### Transaction Boundary
The Delegator ensures Plans execute atomically - no changes are committed unless all validators succeed.

### Reconciliation
When rogue edits occur, Guardians engage developers to justify changes and formally record outcomes.

### Unsafe Protocol
Denied Plans can be executed with explicit user override, permanently stamping artifacts with `PLAN_UNSAFE`.

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/graph](../graph/README.md)** — Agents query the Code Graph to understand code structure and relationships (Gnosis principle)
- **[@sage/chronicle](../chronicle/README.md)** — Agents log decisions and read history from Chronicle files (Remembering principle)
- **[@sage/llm](../llm/README.md)** — Agents use LLMs for natural language reasoning and planning
- **[@sage/tools](../tools/README.md)** — Agents execute safe operations on code through the tools registry

### Dependents  
- **[@sage/aql](../aql/README.md)** — The Delegator translates Plans into AQL queries for execution
- **[CLI applications](../../apps/cli/README.md)** — Applications instantiate and coordinate agents for user interactions

## Development Status

![Status: In Development](https://img.shields.io/badge/Status-In%20Development-yellow)

This package provides the foundational interfaces and some core implementations for SAGE agents. Core agent logic is being actively developed, with implementations for each archetype in progress. The API is stabilizing but may still change as we refine the agent behaviors and interactions.

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Run tests in watch mode
pnpm test:watch

# Build the package
pnpm build

# Run type checking
pnpm typecheck
```

## Contract

This package implements the **[Agents Contract](./CONTRACT.md)**, which defines:
- Deterministic protocol enforcement with explicit side-effect boundaries
- Auditability through structured justifications and Chronicle hooks
- Composability with narrow interfaces for testable units
- Stateless core with adapter-based I/O

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*

---

📦 # 📦 Package: aql (README)

> **📁 Source File:** `packages/aql/README.md` • *121 lines, 922 tokens* • Hash: `6daaadc8`

# @sage/aql

> "The Declarative Orchestrator."

**📋 For documentation updates, see [TODO.md](./TODO.md) for specific instructions and workflow.**

## Overview

**AQL (Agent/Action Query Language)** is a GraphQL-inspired, strongly-typed DSL for orchestrating **agent workflows and tool executions**. You declare _what_ you want; AQL plans _how_ to do it: sequencing, parallelism, retries, and dataflow management.

AQL serves as a **high-level workflow language** that compiles into executable plans. These plans can be executed against any compatible agent execution system, making AQL a universal language for declarative workflow orchestration.

## Installation

```bash
pnpm add @sage/aql
```

## Quick Start

```typescript
import { AQL } from '@sage/aql';
import { readFileSync } from 'fs';

// Minimal, copy-pasteable example demonstrating primary use case
const aql = new AQL();
await aql.initialize();

const src = readFileSync('examples/basic/hello-world.aql', 'utf8');
const result = await aql.run(src, { name: 'World' });

console.log('Greeting:', result.results.greeting);
```

## Core API

### AQL

The main class for parsing and executing AQL queries.

```typescript
// Key method signatures with examples
class AQL {
  async initialize(): Promise<void> {
    // Initialize the AQL engine
  }

  parseQuery(aqlSource: string): AQLQuery {
    // Parse an AQL source string into a query object
  }

  async executeQuery(query: AQLQuery, variables: Record<string, any> = {}): Promise<ExecutionResult> {
    // Execute a parsed query with provided variables
  }

  async run(aqlSource: string, variables: Record<string, any> = {}): Promise<ExecutionResult> {
    // Parse and execute an AQL source string
  }

  setDebug(debug: boolean): void {
    // Enable or disable debug mode
  }

  setTimeout(timeout: number): void {
    // Set execution timeout in milliseconds
  }

  setRetries(retries: number): void {
    // Set number of retries for failed operations
  }
}
```

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/graph](../graph/README.md)** — Planned integration for querying code structure during workflow execution
- **[@sage/llm](../llm/README.md)** — Future integration for executing agent operations through LLM providers
- **[@sage/tools](../tools/README.md)** — Planned integration for executing tool operations within workflows

### Dependents  
- **[@sage/agents](../agents/README.md)** — Future integration where the Delegator will translate Plans into AQL queries for execution

## Development Status

![Status: Prototype](https://img.shields.io/badge/Status-Prototype-orange)

AQL is currently in the prototype phase. It features a functional regex-based parser and a conceptual execution engine that can map dependencies. However, it is not yet fully integrated with the SAGE ecosystem and does not perform real agent or tool executions. The current implementation is experimental and subject to significant changes as we work toward a production-ready version.

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Run tests in watch mode  
pnpm test:watch

# Build the package
pnpm build

# Run type checking
pnpm typecheck
```

## Contract

This package implements the **[AQL Contract](./CONTRACT.md)**, which defines:
- Strong typing with compile-time validation of dataflow and tool arguments
- Deterministic planning with explicit execution plans (DAGs)
- Framework-agnostic execution that works with different agent systems

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*


---

📦 # 📦 Package: aql (examples/README)

> **📁 Source File:** `packages/aql/examples/README.md` • *207 lines, 1616 tokens* • Hash: `3f86f5d0`

# AQL Examples

This directory contains comprehensive examples demonstrating AQL's capabilities across different complexity levels and use cases.

## Directory Structure

```
examples/
├── basic/              # Fundamental AQL concepts
├── advanced/           # Complex multi-agent workflows
├── use-cases/          # Real-world applications
└── README.md          # This file
```

## Basic Examples

### [hello-world.aql](basic/hello-world.aql)

The simplest AQL query - demonstrates basic agent invocation and variable usage.

**Concepts**: Basic query structure, variables, agent configuration

### [sequential-chain.aql](basic/sequential-chain.aql)

Shows how operations execute in sequence, with each step building on the previous.

**Concepts**: Sequential execution, data flow, different model usage

### [parallel-processing.aql](basic/parallel-processing.aql)

Demonstrates parallel execution where multiple agents work simultaneously.

**Concepts**: Parallel blocks, result aggregation, efficiency optimization

### [conditional-logic.aql](basic/conditional-logic.aql)

Shows conditional execution based on results and quality thresholds.

**Concepts**: If/else statements, structured outputs, quality control

## Advanced Examples

### [multi-agent-debate.aql](advanced/multi-agent-debate.aql)

Complex multi-agent system where agents debate a topic over multiple rounds.

**Concepts**:

- Multi-round interactions
- Agent roles and perspectives
- State management across rounds
- Iterative refinement
- Consensus building

### [content-pipeline.aql](advanced/content-pipeline.aql)

Sophisticated content creation pipeline with quality control and optimization.

**Concepts**:

- Multi-phase workflows
- Parallel quality assessment
- Conditional improvement logic
- Structured data types
- Meta-content generation

## Real-World Use Cases

### [customer-support.aql](use-cases/customer-support.aql)

Automated customer support system with intelligent routing and escalation.

**Features**:

- Multi-dimensional issue analysis
- Customer profile assessment
- Sentiment-aware responses
- Escalation logic
- Quality assurance
- Follow-up planning

### [code-review.aql](use-cases/code-review.aql)

Comprehensive automated code review system analyzing multiple dimensions.

**Features**:

- Security vulnerability detection
- Performance analysis
- Code quality metrics
- Architecture review
- Testing assessment
- Documentation evaluation
- Prioritized recommendations

### [research-synthesis.aql](use-cases/research-synthesis.aql)

Academic research synthesis from multiple sources with credibility assessment.

**Features**:

- Source credibility evaluation
- Thematic analysis
- Consensus and conflict identification
- Gap analysis
- Evidence quality assessment
- Implications and applications
- Future research directions

## Key Concepts Demonstrated

### Agent Orchestration

- **Sequential chains**: Operations that build on previous results
- **Parallel processing**: Independent operations running simultaneously
- **Conditional execution**: Dynamic workflow based on results
- **Iterative loops**: Repeated operations with state management

### Data Management

- **Type definitions**: Custom structured data types
- **Variable scoping**: Local and global variable management
- **Context passing**: Maintaining state across operations
- **Result aggregation**: Combining multiple agent outputs

### Quality Control

- **Multi-dimensional assessment**: Analyzing different aspects in parallel
- **Threshold-based decisions**: Automated quality gates
- **Fallback strategies**: Handling edge cases and failures
- **Iterative improvement**: Refining results based on feedback

### Provider Integration

- **Multi-provider usage**: Mixing different LLM providers
- **Model specialization**: Using specific models for specific tasks
- **Configuration management**: Per-operation and global settings
- **Error handling**: Robust failure recovery

## Running Examples

_Note: AQL is currently in design phase. These examples show the intended syntax and capabilities._

Once the AQL runtime is implemented, you'll be able to run these examples:

```bash
# Run a basic example
aql run examples/basic/hello-world.aql --input name="Alice"

# Run advanced example with parameters
aql run examples/advanced/multi-agent-debate.aql \
  --input topic="Universal Basic Income" \
  --input rounds=5

# Run use case with complex input
aql run examples/use-cases/customer-support.aql \
  --input customer_message="My order hasn't arrived" \
  --input priority="high"
```

## Best Practices Demonstrated

1. **Modularity**: Breaking complex workflows into logical phases
2. **Reusability**: Using fragments and functions for common patterns
3. **Error Handling**: Robust error recovery and fallback strategies
4. **Type Safety**: Using structured types for reliable data flow
5. **Performance**: Optimizing with parallel execution where appropriate
6. **Maintainability**: Clear naming and documentation in queries

## Contributing Examples

When adding new examples:

1. **Start Simple**: Begin with basic concepts before advanced features
2. **Document Thoroughly**: Include comments explaining key concepts
3. **Use Real Scenarios**: Base examples on actual use cases
4. **Show Progressions**: Demonstrate how to build complexity gradually
5. **Include Types**: Use structured types for complex data
6. **Handle Errors**: Show proper error handling and fallbacks

## Example Categories

### By Complexity

- **Beginner**: Single agent, simple data flow
- **Intermediate**: Multiple agents, parallel processing
- **Advanced**: Complex workflows, custom types, error handling
- **Expert**: Production-ready systems with full feature usage

### By Domain

- **Content Creation**: Writing, editing, SEO optimization
- **Customer Service**: Support, escalation, quality assurance
- **Code Analysis**: Review, testing, security assessment
- **Research**: Synthesis, analysis, gap identification
- **Business Intelligence**: Data analysis, reporting, insights

### By Pattern

- **Pipeline**: Sequential processing with quality gates
- **Debate**: Multi-agent consensus building
- **Assessment**: Multi-dimensional evaluation
- **Synthesis**: Combining multiple sources or perspectives
- **Orchestration**: Complex workflow management

Each example is designed to teach specific concepts while solving real-world problems, making AQL both educational and practical.


---

📦 # 📦 Package: aql (examples/experiments/README)

> **📁 Source File:** `packages/aql/examples/experiments/README.md` • *191 lines, 1490 tokens* • Hash: `1ca44b37`

# AQL Research Experiments

This directory contains AQL queries designed for researching the effectiveness of different agent orchestration strategies, particularly focusing on maximizing the performance of smaller agents through strategic coordination.

## Experiments

### [tiny-model-effectiveness.aql](tiny-model-effectiveness.aql)

**Research Question**: Can small agents achieve high-performance results through better coordination?

**Strategy**: Multi-phase specialization with cross-verification

- Problem decomposition
- Parallel specialized analysis
- Cross-verification between specialists
- Iterative refinement
- Synthesis with minimal larger agent usage

**Run with**:

```bash
aql run tiny-model-effectiveness.aql --input '{
  "problem": "Design a sustainable urban transportation system for a city of 2 million people",
  "complexity": "high"
}'
```

### [model-comparison.aql](model-comparison.aql)

**Research Question**: What's the optimal way to combine different agent capabilities?

**Strategies Tested**:

1. **Single Large Agent**: Baseline approach
2. **Cascade**: Small → Medium → Large progression
3. **Ensemble Voting**: Multiple small agents with consensus
4. **Specialized Coordination**: Expert agents with coordination
5. **Debate & Refinement**: Adversarial improvement

**Run with**:

```bash
aql run model-comparison.aql --input '{
  "task": "Develop a marketing strategy for a new sustainable product",
  "evaluation_criteria": ["creativity", "feasibility", "cost-effectiveness", "market_impact"]
}'
```

## Research Hypotheses

### H1: Specialization Beats Generalization

Small agents with specific roles will outperform general-purpose large agents on focused tasks.

### H2: Verification Improves Quality

Cross-verification between specialized agents reduces errors and improves output quality.

### H3: Iterative Refinement Scales Performance

Multiple rounds of refinement can achieve quality comparable to much larger agents.

### H4: Ensemble Consensus Reduces Variance

Multiple small agents voting/consensus reduces individual agent biases and errors.

### H5: Debate Improves Reasoning

Adversarial processes between agents improve logical reasoning and identify weak points.

## Metrics to Track

### Quality Metrics

- **Completeness**: Does the solution address all aspects?
- **Accuracy**: Are the facts and reasoning correct?
- **Creativity**: Novel or innovative approaches?
- **Feasibility**: Practical and implementable?

### Efficiency Metrics

- **Total Tokens**: Token usage across all agents
- **Execution Time**: End-to-end processing time
- **Cost Effectiveness**: Quality per unit of compute
- **Parallelization Benefit**: Speedup from parallel execution

### Agent Usage Patterns

- **Small Agent Utilization**: How effectively are small agents used?
- **Large Agent Dependency**: When are larger agents actually needed?
- **Specialization Effectiveness**: Do specialized roles improve performance?
- **Coordination Overhead**: Cost of agent coordination vs. benefits

## Running Experiments

### Prerequisites

```bash
# Ensure agent execution system is running
# (specific setup depends on your agent execution framework)

# Pull required agents (setup depends on your framework)
# Example placeholder commands:
# agent-manager pull small-agent
# agent-manager pull medium-agent
# agent-manager pull large-agent
```

### Basic Execution

```bash
# Run single experiment
aql run experiments/tiny-model-effectiveness.aql --input-file problem.json --debug

# Compare strategies
aql run experiments/model-comparison.aql --input-file task.json --debug
```

### Batch Testing

```bash
# Test multiple problems
for problem in problems/*.json; do
  echo "Testing: $problem"
  aql run tiny-model-effectiveness.aql --input-file "$problem" > "results/$(basename "$problem" .json).json"
done
```

## Input Examples

### problem.json (for tiny-model-effectiveness.aql)

```json
{
  "problem": "Design a decentralized social media platform that addresses privacy concerns while maintaining user engagement",
  "complexity": "high"
}
```

### task.json (for model-comparison.aql)

```json
{
  "task": "Create a comprehensive business plan for a vertical farming startup targeting urban markets",
  "evaluation_criteria": [
    "market_analysis_depth",
    "financial_projections_accuracy",
    "operational_feasibility",
    "competitive_differentiation",
    "scalability_potential"
  ]
}
```

## Expected Research Insights

### Agent Orchestration Patterns

- Which coordination patterns work best for different problem types?
- How does problem complexity affect optimal strategy choice?
- When is the overhead of coordination worth the quality improvement?

### Small Agent Optimization

- What specialized roles maximize small agent effectiveness?
- How much context should each specialist agent receive?
- What's the optimal creativity settings for different roles?

### Quality vs. Efficiency Trade-offs

- At what point do diminishing returns set in for additional agents?
- How does parallel execution improve both speed and quality?
- What's the sweet spot for agent capabilities in different roles?

## Contributing New Experiments

When adding new experiments:

1. **Clear Research Question**: State what you're trying to discover
2. **Controlled Variables**: Test one strategy dimension at a time
3. **Measurable Outcomes**: Define success metrics upfront
4. **Reproducible Setup**: Include input examples and expected outputs
5. **Documentation**: Explain the hypothesis and methodology

## Future Experiment Ideas

- **Context Window Optimization**: How does context size affect coordination?
- **Creativity Tuning**: Optimal creativity settings for different roles
- **Dynamic Role Assignment**: Agents that choose their own specializations
- **Failure Recovery**: How to handle when individual agents fail
- **Multi-Modal Coordination**: Combining text, code, and structured output agents

---

📦 # 📦 Package: chronicle (README)

> **📁 Source File:** `packages/chronicle/README.md` • *151 lines, 1141 tokens* • Hash: `48c409fd`

# @sage/chronicle

> "The Sacred Memory."

## Overview

`@sage/chronicle` is SAGE's durable memory layer. It offers a simple, strongly-typed, **append-only** API for reading and writing `.sage` Chronicle files. Every material event in the ecology (approvals, denials, persona triggers, deployments, post-mortems) is recorded here for auditability and learning.

This package provides a **tamper-evident**, append-only event log that preserves **irreducible units of change** (diff pointers, justifications, metadata), links events to **Code Graph** commits and **Plan** hashes, supports **concurrency-safe** appends, and guarantees **ordering** and **traceability** across agents.

## Installation

```bash
pnpm add @sage/chronicle
```

## Quick Start

```typescript
import { readChronicle, appendEvent, type ChronicleEvent } from '@sage/chronicle';

// Minimal, copy-pasteable example demonstrating primary use case
const path = "/repo/src/UserService.ts.sage";

// Append an approval. The eventId will be computed automatically.
const evt: ChronicleEvent = {
  type: "PLAN_APPROVED",
  timestamp: new Date().toISOString(),
  planHash: "a1b2c3",
  graphCommit: "f6e5d4",
  actor: { agent: "guardian", id: "src/UserService.ts" },
  justification: "Refactor for performance; interfaces unchanged."
};

await appendEvent(path, evt);

// Read full history
const history = await readChronicle(path);
console.log(`History length: ${history.length}`);
```

## Core API

### Chronicle API Functions

The main functions for interacting with Chronicle files:

```typescript
// Key method signatures with examples
class ChronicleAPI {
  /**
   * Appends an event, automatically computing its eventId.
   * This is the standard, recommended method.
   */
  async appendEvent(
    path: ChroniclePath,
    evt: ChronicleEvent,
    lockTimeoutMs?: number
  ): Promise<void> {
    // Append an event to a Chronicle file
  }

  /**
   * Appends an event using a pre-computed eventId.
   * For advanced use cases like event sourcing or testing.
   */
  async appendEventWithId(
    path: ChroniclePath,
    evt: ChronicleEvent, // Must contain a valid eventId
    lockTimeoutMs?: number
  ): Promise<void> {
    // Append an event with a pre-computed eventId
  }

  async readChronicle(path: ChroniclePath): Promise<ChronicleEvent[]> {
    // Read all events from a Chronicle file
  }

  async tailChronicle(
    path: ChroniclePath,
    n = 50
  ): Promise<ChronicleEvent[]> {
    // Read the last n events from a Chronicle file
  }
}
```

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/utils](../utils/README.md)** — Provides shared types, error handling, and canonicalization helpers

### Dependents  
- **[@sage/agents](../agents/README.md)** — Agents use Chronicle for recording decisions and reading history
- **[@sage/cli](../../apps/cli/README.md)** — CLI applications use Chronicle for rendering historical context
- **[@sage/valve](../../apps/valve/README.md)** — Valve writes persona triggers to Chronicle files

## Development Status

![Status: Production Ready](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)

`@sage/chronicle` is **fully implemented and production-ready** with features that exceed the original specification:

**✅ Core Features:**
- Complete Chronicle API with all contract requirements
- 13 distinct event types with full TypeScript inference
- Industrial-strength file operations with concurrency control
- Sophisticated canonicalization and hashing system

**✅ Advanced Features:**
- Causal chain management and validation
- Chronicle analysis and repair utilities
- Performance optimizations for large-scale operations
- Comprehensive deduplication and optimization systems

**✅ Production Features:**
- Cross-platform file locking with timeout handling
- Atomic operations with crash safety
- Memory-efficient operations for long-running processes
- Comprehensive error handling and recovery

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Run tests in watch mode  
pnpm test:watch

# Build the package
pnpm build
```

## Contract

This package implements the **[Chronicle Contract](./CONTRACT.md)**, which defines:
- Append-only API with idempotent behavior
- Strong typing with comprehensive event model
- Concurrency-safe file operations
- Canonicalization and hashing for event integrity

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*


---

📦 # 📦 Package: graph (README)

> **📁 Source File:** `packages/graph/README.md` • *143 lines, 1048 tokens* • Hash: `5f8adca0`

# @sage/graph

> "The Ground Truth."

**📋 For documentation updates, see [TODO.md](./TODO.md) for specific instructions and workflow.**

## Overview

This package maintains the **objective structural reality** of a project. It ingests code into a Kùzu database, versions every node/edge by commit, and exposes a commit-addressable query interface. It is the substrate for all **Gnosis**: every Guardian self-inquiry, Delegator validation, and Librarian schema check grounds itself in this graph.

The package provides a **semantically rich, time-traveling Code Graph** that stores files, functions, classes, variables, imports, and dependencies, versions database snapshots via git commits, supports Cypher queries at any point in history, and enables end-to-end traceability of structure, lineage, and evolution.

## Installation

```bash
pnpm add @sage/graph
```

## Quick Start

```typescript
import { ingestProject, queryGraph } from '@sage/graph';

// Minimal, copy-pasteable example demonstrating primary use case
await ingestProject({
  projectPath: "/my/project",
  commitHash: "abc123"
});

const { results } = await queryGraph({
  query: `
    MATCH (f:File {name: "UserService.ts"})-[:IMPORTS]->(dep)
    RETURN dep.name;
  `,
  commit: "abc123" // Query at specific commit
});

console.log("Dependencies:", results);
```

## Core API

### Graph API Functions

The main functions for interacting with the Graph database:

```typescript
// Key method signatures with examples
class GraphAPI {
  /**
   * Ingests a project into the graph database.
   */
  async ingestProject(options: IngestOptions): Promise<void> {
    // Ingest a project into the graph database
  }

  /**
   * Query the graph database with optional commit-specific queries.
   */
  async queryGraph<T = any>(options: QueryOptions): Promise<QueryResult<T>> {
    // Query the graph database
  }

  /**
   * Get current database status and metadata.
   */
  async getDatabaseStatus(projectPath?: string): Promise<{
    exists: boolean;
    path: string;
    currentCommit?: string;
    hasUncommittedChanges?: boolean;
  }> {
    // Get database status
  }

  /**
   * Utility to create a database connection for advanced use cases.
   */
  createDatabaseClient(config?: DatabaseConfig): RustKuzuClient {
    // Create a database client
  }

  /**
   * Utility to create a git manager for advanced git operations.
   */
  createGitManager(projectPath: string, debug?: boolean): GitDatabaseManager {
    // Create a git manager
  }
}
```

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/utils](../utils/README.md)** — Provides shared types, error handling, and utilities

### Dependents  
- **[@sage/agents](../agents/README.md)** — Agents use Graph for Gnosis & Self-Inquiry
- **[@sage/tools](../tools/README.md)** — Tools use GraphQuery for code analysis
- **[CLI applications](../../apps/cli/README.md)** — CLI uses Graph for the ingest command

## Development Status

![Status: Production Ready](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)

The Graph package is production-ready with a robust implementation that leverages Kùzu database technology and git-based versioning. It provides a solid foundation for all code analysis and querying needs within the SAGE ecosystem.

Key features:
- Complete TypeScript AST analysis with 30+ relationship types
- Kùzu database integration with proven schema
- Git-based versioning for time-travel queries
- Comprehensive API for ingestion and querying

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Run tests in watch mode  
pnpm test:watch

# Build the package
pnpm build
```

## Contract

This package implements the **[Graph Contract](./CONTRACT.md)**, which defines:
- Commit-addressable graph database with time-travel capabilities
- Strongly-typed schema for code entities and relationships
- Safe, async helpers for Cypher queries at specific commits
- Ground truth guarantees for code structure and evolution

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*


---

📦 # 📦 Package: llm (README)

> **📁 Source File:** `packages/llm/README.md` • *148 lines, 1043 tokens* • Hash: `5c3c6efd`

# @sage/llm

> "The Engine of Thought."

**📋 For documentation updates, see [TODO.md](./TODO.md) for specific instructions and workflow.**

## Overview

`@sage/llm` is the provider-agnostic bridge to Large Language Models. It standardizes chat, tool-use, and streaming across backends (LM Studio, OpenAI, Anthropic, etc.), so agents focus on **what** to think, not **how** to call models.

The package provides a resilient, performant abstraction that exposes a **unified chat API** with tool-calling, supports **streaming** tokens and **structured tool calls**, delivers **prompt caching** and **response de-duplication**, enforces **safety caps** (rate limits, token budgets, timeouts), and keeps **providers pluggable** via a clean interface.

## Installation

```bash
pnpm add @sage/llm
```

## Quick Start

```typescript
import { createChatStream, setProvider } from '@sage/llm';
import { OpenAIProvider } from '@sage/llm/adapters/openai'; // example adapter

// Minimal, copy-pasteable example demonstrating primary use case
setProvider(new OpenAIProvider({ apiKey: process.env.OPENAI_API_KEY! }));

const stream = await createChatStream({
  model: "gpt-4.1",
  messages: [
    { role: "system", content: "You are a helpful agent." },
    { role: "user", content: "List three risks of unsafe refactors." }
  ]
});

for await (const ev of stream) {
  if (ev.type === "text") process.stdout.write(ev.value);
}
```

## Core API

### LLM API Functions

The main functions for interacting with LLM providers:

```typescript
// Key method signatures with examples
class LLM {
  /**
   * Create a chat stream with the current provider, with optional caching
   */
  async createChatStream(
    opts: ChatOptions,
    streamOpts?: StreamOptions
  ): Promise<AsyncIterable<StreamEvent>> {
    // Create a chat stream
  }

  /**
   * List available models from the current provider or a specific provider
   */
  async listModels(provider?: string): Promise<ModelInfo[]> {
    // List available models
  }

  /**
   * Set the current provider
   */
  setProvider(provider: LLMProvider): void {
    // Set the current provider
  }

  /**
   * Register a tool for use with LLM calls
   */
  registerTool(
    name: string,
    schema: ToolSchema,
    executor: ToolExecutor
  ): void {
    // Register a tool
  }
}
```

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/utils](../utils/README.md)** — Provides shared types, error handling, and utilities
- **[@sage/mcp](../mcp/README.md)** — Integration with Model Context Protocol for enterprise-grade LLM management

### Dependents  
- **[@sage/agents](../agents/README.md)** — Agents use LLM for thinking & mediation
- **[@sage/aql](../aql/README.md)** — AQL compiles declarative queries into executions that stream through this API
- **[CLI applications](../../apps/cli/README.md)** — CLI uses LLM for chat UX

## Development Status

![Status: In Development](https://img.shields.io/badge/Status-In%20Development-yellow)

The LLM package is currently in development with core features implemented and ready for production use. Some advanced features and provider adapters are still in progress.

**✅ Core Features Implemented:**
- Unified chat API with tool-calling
- Streaming support with backpressure handling
- JSON Schema validation for tools
- Prompt caching with multiple modes
- Error handling and safety features

**⚠️ In Progress:**
- Provider adapter completion (OpenAI, Anthropic, LM Studio)
- Production readiness and polish
- @sage/mcp integration

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Run tests in watch mode  
pnpm test:watch

# Build the package
pnpm build

# Clean build artifacts
pnpm clean
```

## Contract

This package implements the **[LLM Contract](./CONTRACT.md)**, which defines:
- Provider-agnostic unified chat API
- Streaming tokens and structured tool calls
- Prompt caching and response de-duplication
- Safety caps (rate limits, token budgets, timeouts)

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*


---

📦 # 📦 Package: mcp (README)

> **📁 Source File:** `packages/mcp/README.md` • *158 lines, 1140 tokens* • Hash: `c869a555`

# @sage/mcp

> "The Universal Translator for Model Control."

**📋 For documentation updates, see [TODO.md](./TODO.md) for specific instructions and workflow.**

## Overview

`@sage/mcp` (Model Control Program) is a **production-grade implementation of the Model Context Protocol (MCP)**, an industry standard for integrating AI models with development tools and enterprise systems. It provides robust server lifecycle management and multi-transport support, making it a cornerstone of SAGE's AI infrastructure.

The package is an **active and valuable complement to `@sage/llm`**. While `@sage/llm` offers a unified, provider-agnostic interface for LLM interactions, `@sage/mcp` specializes in the low-level details of the MCP protocol, ensuring stable and efficient communication with compliant endpoints.

## Installation

```bash
pnpm add @sage/mcp
```

## Quick Start

```typescript
import { MCPClientManager } from '@sage/mcp';
import { createChatStream, setProvider } from '@sage/llm';
import { MCPProvider } from '@sage/llm/providers';

// Minimal, copy-pasteable example demonstrating primary use case
// @sage/mcp manages the connection to an MCP-compliant server
const mcpManager = new MCPClientManager({ 
  // Configuration for MCP server connection
  // This could be stdio or HTTP based
});

// Create the MCP provider for use with @sage/llm
const mcpProvider = new MCPProvider(mcpManager);

// The rest of the application uses the unified @sage/llm interface
setProvider(mcpProvider);

const stream = await createChatStream({ 
  model: "claude-3.5-sonnet", 
  messages: [{ role: "user", content: "Hello, world!" }] 
});

for await (const chunk of stream) {
  if (chunk.type === "text") {
    process.stdout.write(chunk.value);
  }
}
```

## Core API

### MCP Client Management

The main classes for managing MCP servers and connections:

```typescript
// Key method signatures with examples
class MCPClientManager {
  /**
   * Initialize the MCP client manager
   */
  constructor(config?: MCPManagerConfig) {
    // Initialize with configuration
  }

  /**
   * Connect to an MCP server
   */
  async connect(serverConfig: McpServerConfig): Promise<McpServerConnection> {
    // Connect to an MCP server
  }

  /**
   * Disconnect from an MCP server
   */
  async disconnect(serverId: string): Promise<void> {
    // Disconnect from an MCP server
  }

  /**
   * List available tools from connected servers
   */
  async listTools(): Promise<McpTool[]> {
    // List available tools
  }

  /**
   * List available resources from connected servers
   */
  async listResources(): Promise<McpResource[]> {
    // List available resources
  }

  /**
   * List available prompts from connected servers
   */
  async listPrompts(): Promise<McpPrompt[]> {
    // List available prompts
  }
}
```

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/utils](../utils/README.md)** — Provides shared types, error handling, and utilities
- **[@modelcontextprotocol/sdk](https://github.com/modelcontextprotocol/sdk)** — Official MCP SDK for protocol implementation

### Dependents  
- **[@sage/llm](../llm/README.md)** — Uses MCP as a provider through MCPProvider integration
- **[CLI applications](../../apps/cli/README.md)** — CLI tools that need to interact with MCP-compliant servers

## Development Status

![Status: Production Ready](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)

The MCP package is production-ready with comprehensive test coverage and enterprise-grade features. It provides robust server management and seamless integration with the unified `@sage/llm` interface.

**✅ Core Features:**
- Complete MCP protocol implementation
- Server lifecycle management
- Multi-transport support (stdio, HTTP)
- Connection pooling and error recovery
- Integration with @sage/llm via MCPProvider

**✅ Testing Infrastructure:**
- 20+ comprehensive test files
- Unit, integration, and E2E tests
- Error recovery testing
- Real MCP server process testing

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Build the package
pnpm build
```

## Contract

This package implements the **[MCP Contract](./CONTRACT.md)**, which defines:
- Production-grade MCP protocol implementation
- Robust server lifecycle management
- Multi-transport support for stdio and HTTP
- Integration with @sage/llm through MCPProvider

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*

---

📦 # 📦 Package: test-utils (README)

> **📁 Source File:** `packages/test-utils/README.md` • *196 lines, 1308 tokens* • Hash: `954f99b8`

# @sage/test-utils

> "The Controlled Environment."

**📋 For documentation updates, see [TODO.md](./TODO.md) for specific instructions and workflow.**

## Overview

`@sage/test-utils` provides batteries-included utilities for **fast, isolated, reproducible** tests across the SAGE monorepo. It ships temp-FS harnesses, in-memory adapters for Graph/Chronicle/LLM/Tools, deterministic clocks & RNG, CLI and Daemon simulators, and assertion helpers tailored to SAGE's **Principles & Protocols**.

The package is designed to ensure determinism by default with stable clocks, seeded RNG, and hermetic IO. It enables fast testing with no disk/network unless explicitly enabled and provides ergonomic APIs with minimal boilerplate to stand up agents/flows with good defaults.

## Installation

```bash
pnpm add -D @sage/test-utils
```

## Quick Start

```typescript
import {
  createTempWorkspace,
  writeFile,
  readFile,
  golden
} from '@sage/test-utils/fs';
import {
  makeGraphAdapter,
  makeChronicle,
  makeLLM,
  makeTools
} from '@sage/test-utils/adapters';

// Minimal, copy-pasteable example demonstrating primary use case
const ws = await createTempWorkspace();
await writeFile(ws, "src/UserService.ts", 'export const ping=()=>"pong"\n');

const graph = makeGraphAdapter();
const chron = makeChronicle();
const llm = makeLLM({ seed: 42 });
const tools = makeTools({ readOnly: true });

// Golden snapshot the Chronicle after a fake event
await chron.append("src/UserService.ts.sage", {
  type: "PLAN_APPROVED",
  timestamp: "2025-08-28T00:00:00.000Z",
  actor: { agent: "guardian", id: "src/UserService.ts" },
  planHash: "deadbeef"
});

await golden(ws, "src/UserService.ts.sage");
```

## Core API

### Test Utilities API

The main modules and functions for testing SAGE packages:

```typescript
// Key method signatures with examples
// Temp FS & Workspace Harnesses
class TempFS {
  /**
   * Create a temporary filesystem for testing
   */
  static async createTempWorkspace(options?: {
    prefix?: string;
    clock?: Clock;
  }): Promise<TempWorkspace> {
    // Create a temporary workspace
  }
}

// In-Memory Adapters
class Adapters {
  /**
   * Create an in-memory Graph adapter
   */
  static makeGraphAdapter(): GraphAdapter {
    // Create a Graph adapter
  }

  /**
   * Create an in-memory Chronicle adapter
   */
  static makeChronicle(): ChronicleAdapter {
    // Create a Chronicle adapter
  }

  /**
   * Create a deterministic LLM adapter
   */
  static makeLLM(options?: {
    seed?: number;
    tools?: Record<string, ToolExecutor>;
  }): LLMClient {
    // Create an LLM adapter
  }

  /**
   * Create a tools adapter
   */
  static makeTools(options?: {
    readOnly?: boolean;
  }): ToolRegistry {
    // Create a tools adapter
  }
}

// Agent Scenario DSL & Harnesses
class ScenarioDSL {
  /**
   * Create a test scenario
   */
  static async scenario(): Promise<Scenario> {
    // Create a test scenario
  }
}

// Protocol Matchers & Assertions
class Matchers {
  /**
   * Setup custom matchers for Vitest/Jest
   */
  static setupMatchers(): void {
    // Setup custom matchers
  }
}
```

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/utils](../utils/README.md)** — Provides shared types, error handling, and deterministic utilities

### Dependents  
- **All SAGE packages** — Used for testing across the entire SAGE ecosystem
- **[@sage/agents](../agents/README.md)** — Agent testing with scenario DSL
- **[@sage/graph](../graph/README.md)** — Graph testing with in-memory adapters
- **[@sage/chronicle](../chronicle/README.md)** — Chronicle testing with append-only adapters
- **[@sage/llm](../llm/README.md)** — LLM testing with deterministic adapters
- **[@sage/tools](../tools/README.md)** — Tools testing with sandboxed fakes

## Development Status

![Status: In Development](https://img.shields.io/badge/Status-In%20Development-yellow)

The test-utils package is currently in development with core APIs defined and some implementations in progress. It provides essential testing infrastructure for the entire SAGE ecosystem.

**✅ Core Features Defined:**
- Temp FS & Workspace Harnesses specification
- In-Memory Adapters specification
- Agent Scenario DSL & Harnesses specification
- Protocol Matchers & Assertions specification

**⚠️ Implementation In Progress:**
- Temp FS & Workspace Harnesses implementation
- In-Memory Adapters implementation
- Agent Scenario DSL & Harnesses implementation
- Protocol Matchers & Assertions implementation

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Run tests in watch mode  
pnpm test:watch

# Build the package
pnpm build

# Clean build artifacts
pnpm clean
```

## Contract

This package implements the **[Test Utils Contract](./CONTRACT.md)**, which defines:
- Temp FS & Workspace Harnesses for isolated filesystem testing
- In-Memory Adapters for deterministic testing of SAGE interfaces
- Agent Scenario DSL & Harnesses for end-to-end agent testing
- Protocol Matchers & Assertions for validating SAGE protocols

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*


---

📦 # 📦 Package: tools (README)

> **📁 Source File:** `packages/tools/README.md` • *202 lines, 1370 tokens* • Hash: `08f462c1`

# @sage/tools

> "The Hands of the Agents."

**📋 For documentation updates, see [TODO.md](./TODO.md) for specific instructions and workflow.**

## Overview

`@sage/tools` is a sandboxed, type-safe capability layer for SAGE agents. Each tool is a **well-defined, auditable action** with strongly-typed inputs and outputs. Tools are invoked via a central **registry** and described with **JSON Schema** for LLM tool-calling.

The package provides a secure bridge from **intent → effect** that validates inputs before execution, isolates execution in controllable sandboxes, reports structured results and errors, and supports dry-runs and capability discovery at runtime.

## Installation

```bash
pnpm add @sage/tools
```

## Quick Start

```typescript
import { toolRegistry, Read, Write, Edit, GraphQuery } from '@sage/tools';

// Minimal, copy-pasteable example demonstrating primary use case
// Register standard tools
toolRegistry.register(Read());
toolRegistry.register(Write());
toolRegistry.register(Edit());
toolRegistry.register(GraphQuery);

// Use a tool to read a file
const readTool = toolRegistry.get("Read");
const result = await readTool.execute(
  { file: "src/index.ts" }, 
  { 
    cwd: process.cwd(),
    fileSystem: realFileSystem, // Inject real file system operations
    process: realProcess,       // Inject real process operations
    logger: realLogger          // Inject logger
  }
);

if (result.ok) {
  console.log("File contents:", result.data);
} else {
  console.error("Error reading file:", result.error);
}
```

## Core API

### Tool Interface

The main interface for defining and using tools:

```typescript
// Key method signatures with examples
interface Tool<I, O> {
  name: string;
  description?: string;
  schema: JSONSchema; // for LLM tool-calls
  validate(input: unknown): I; // Zod runtime validation
  execute(input: I, ctx: ToolContext): Promise<ToolResult<O>>;
  version?: string; // semantic version per tool
}

interface ToolContext {
  cwd: string;
  env?: Record<string, string>;
  dryRun?: boolean;
  permissions?: string[]; // e.g., ["fs:read", "fs:write:src/**"]
  logger?: (evt: ToolLog) => void;
  /**
   * An optional secret provider for just-in-time value injection.
   * If provided, the tool runner is responsible for placeholder substitution.
   */
  secretProvider?: import("@sage/utils").SecretProvider;
}

interface ToolResult<T> {
  ok: boolean;
  data?: T;
  error?: { code: string; message: string };
  meta?: { startedAt: string; endedAt: string; durationMs: number };
}
```

### Tool Registry

The central registry for managing tools:

```typescript
class ToolRegistry {
  /**
   * Register a tool in the registry
   */
  register(tool: Tool<any, any>): void {
    // Register a tool
  }

  /**
   * Get a tool by name
   */
  get(name: string): Tool<any, any> {
    // Get a tool
  }

  /**
   * Get all tool schemas for LLM tool-calling
   */
  getToolSchemas(): ToolSchema[] {
    // Get tool schemas
  }
}
```

### Standard Tools

The package provides several standard tools:

```typescript
// Read - read file contents from the workspace
const readTool = Read();

// Write - write/replace file contents
const writeTool = Write();

// Edit - structured patch application with diff output
const editTool = Edit();

// GraphQuery - run read-only Cypher queries against @sage/graph
const graphQueryTool = GraphQuery;

// Bash - execute shell commands in a sandbox
const bashTool = Bash();
```

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/graph](../graph/README.md)** — Provides the GraphQuery tool for querying code structure
- **[@sage/utils](../utils/README.md)** — Provides shared types, error handling, and utilities
- **[@sage/mcp](../mcp/README.md)** — Integration with Model Context Protocol for advanced tool capabilities

### Dependents  
- **[@sage/agents](../agents/README.md)** — Agents use tools for executing actions (especially Delegator & Meeseeks)
- **[CLI applications](../../apps/cli/README.md)** — CLI uses tools for manual commands

## Development Status

![Status: In Development](https://img.shields.io/badge/Status-In%20Development-yellow)

The tools package is currently in development with core features implemented and ready for use. It provides a secure, sandboxed capability layer for SAGE agents.

**✅ Core Features Implemented:**
- Tool interface with type safety and validation
- Central tool registry for managing tools
- Standard tools: Read, Write, Edit, Bash, GraphQuery
- Security & sandboxing with process isolation and path policies
- Secret management with Vault-Warden Protocol integration

**⚠️ In Progress:**
- Additional tool implementations
- Enhanced security features
- Performance optimizations

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Run tests in watch mode  
pnpm test:watch

# Build the package
pnpm build

# Run type checking
pnpm type-check

# Lint the code
pnpm lint
```

## Contract

This package implements the **[Tools Contract](./CONTRACT.md)**, which defines:
- Sandboxed, type-safe capability layer for SAGE agents
- Secure bridge from intent to effect with validation and isolation
- Standard tool set with JSON Schema for LLM tool-calling
- Security & sandboxing with process isolation and path policies

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*


---

📦 # 📦 Package: ui (README)

> **📁 Source File:** `packages/ui/README.md` • *209 lines, 1360 tokens* • Hash: `98f7e7b4`

# @sage/ui

> "The Voice of the System."

**📋 For documentation updates, see [TODO.md](./TODO.md) for specific instructions and workflow.**

## Overview

`@sage/ui` is a **renderer-agnostic** UI kit for SAGE. It exports **platform-neutral primitives** — `Text`, `Row`, `Column`, `Box`, etc. — and maps them to concrete renderers (CLI via Ink, Web via React DOM) behind the scenes. Components written against these primitives don't know (or care) whether they're in a terminal or a browser.

The package provides a single component model that renders **consistently across CLI and Web**, supports **streaming** assistant output and tool calls, exposes a **headless** API for complex widgets with pluggable skins, and keeps **layout & typography primitives** stable across renderers.

## Installation

```bash
pnpm add @sage/ui
```

## Quick Start

```typescript
import { Text, Row, Column, Box } from '@sage/ui';

// Minimal, copy-pasteable example demonstrating primary use case
// Layout primitives auto-map to Ink or DOM
const App = () => (
  <Column gap={1}>
    <Row gap={1} align="center" justify="space-between">
      <Text variant="title">SAGE</Text>
      <Text dim>v1.0.0</Text>
    </Row>
    
    <Text>Hello, world.</Text>
    
    <Box border padding={1}>
      <Text mono>code or logs...</Text>
    </Box>
  </Column>
);

// Choose an adapter once at your app's entrypoint
// CLI entry (apps/cli)
import { render } from "ink";
import { UI } from "@sage/ui/cli"; // uses Ink under the hood

render(<UI.App />);

// Web entry (future dev server)
import { createRoot } from "react-dom/client";
import { UI } from "@sage/ui/web"; // uses React DOM under the hood

createRoot(document.getElementById("root")!).render(<UI.App />);
```

## Core API

### UI Primitives

The main primitives for building UI components:

```typescript
// Key method signatures with examples
interface TextProps {
  /** Text variant styling */
  variant?: "title" | "subtitle" | "body" | "mono";
  /** Dim the text */
  dim?: boolean;
  /** Bold text */
  bold?: boolean;
  /** Wrap text */
  wrap?: boolean;
  /** Text content */
  children?: ReactNode;
}

interface RowProps {
  /** Gap between children */
  gap?: number;
  /** Alignment of children along the cross axis */
  align?: "start" | "center" | "end";
  /** Alignment of children along the main axis */
  justify?: "start" | "center" | "end";
  /** Row content */
  children?: ReactNode;
}

interface ColumnProps {
  /** Gap between children */
  gap?: number;
  /** Alignment of children along the cross axis */
  align?: "start" | "center" | "end";
  /** Alignment of children along the main axis */
  justify?: "start" | "center" | "end";
  /** Column content */
  children?: ReactNode;
}

interface BoxProps {
  /** Padding around content */
  padding?: number;
  /** Margin around the box */
  margin?: number;
  /** Show border */
  border?: boolean;
  /** Rounded corners */
  rounded?: boolean;
  /** Box content */
  children?: ReactNode;
}
```

### Higher-Level Components

Streaming components for chat and assistant interactions:

```typescript
interface ChatProps {
  /** Stream of events from @sage/llm */
  stream: AsyncIterable<StreamEvent>;
  /** Chat content */
  children?: ReactNode;
}

interface AssistantTurnProps {
  /** Assistant turn content */
  children?: ReactNode;
}

interface UserMessageProps {
  /** User message content */
  children?: ReactNode;
}

interface ToolCallProps {
  /** Tool name */
  name: string;
  /** Tool arguments */
  args: any;
  /** Tool call result */
  result?: any;
}

interface SpinnerProps {
  /** Spinner content */
  children?: ReactNode;
}
```

## Role in the SAGE Ecosystem

### Dependencies
- **[React](https://react.dev)** — Core UI library for component rendering
- **[Ink](https://github.com/vadimdemedes/ink)** — CLI renderer for terminal interfaces
- **[@sage/llm](../llm/README.md)** — Provides stream events for chat components

### Dependents  
- **[CLI applications](../../apps/cli/README.md)** — CLI uses UI components for terminal interfaces
- **Future web applications** — Web apps will use UI components for browser interfaces

## Development Status

![Status: In Development](https://img.shields.io/badge/Status-In%20Development-yellow)

The UI package is currently in the early stages of development with core primitives and streaming components defined.

**✅ Core Features Defined:**
- Core primitives (Text, Row, Column, Box)
- Streaming component interfaces (Chat, AssistantTurn, etc.)
- Theme system
- Build system configured
- Basic tests implemented

**⚠️ Implementation In Progress:**
- Adapter implementations (Ink/Web)
- Comprehensive examples
- Advanced component implementations

## Development

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Build the package
pnpm build

# Run CLI example
pnpm example:cli

# Run comprehensive example
pnpm example:comprehensive
```

## Contract

This package implements the **[UI Contract](./CONTRACT.md)**, which defines:
- Renderer-agnostic UI primitives for consistent CLI and Web rendering
- Streaming components for assistant output and tool calls
- Themeable components with shared theme tokens
- Stable layout and typography primitives across renderers

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*

---

📦 # 📦 Package: utils (README)

> **📁 Source File:** `packages/utils/README.md` • *188 lines, 1247 tokens* • Hash: `d53b40db`

# @sage/utils

> "Minimal shared types and helpers used across packages. Zero runtime deps."

**📋 For documentation updates, see [TODO.md](./TODO.md) for specific instructions and workflow.**

## Overview

This package provides the foundational utilities that all other SAGE packages depend on. It includes shared types, error handling, canonicalization helpers, and time/random abstractions needed for deterministic testing.

The package provides a **minimal, dependency-free foundation** that defines shared types like `ISO8601`, `Clock`, `Random`, provides typed error creation with `TypedError` and `err()` helper, ensures canonical JSON serialization for hashing consistency, and offers cryptographic primitives like `sha256()`.

## Installation

```bash
pnpm add @sage/utils
```

## Quick Start

```typescript
import { err, canonicalJSONStringify, sha256, Logger } from '@sage/utils';

// Minimal, copy-pasteable example demonstrating primary use case
// Create typed errors
const validationError = err("EVALIDATION", "Invalid input", { field: "name" });

// Canonical JSON for consistent hashing
const canonical = canonicalJSONStringify({ c: 3, a: 1, b: 2 });
// → '{"a":1,"b":2,"c":3}'

// Hash content
const hash = await sha256(canonical);

// Use the logger
const logger = new Logger("MyService");
logger.info("Hello, world!");
```

## Core API

### Core Types and Interfaces

The main types and interfaces provided by the package:

```typescript
// Key method signatures with examples
export type ISO8601 = string & { __brand: 'ISO8601' };

export interface Clock {
  now(): ISO8601;
}

export interface Random {
  int(): number;
  float(): number;
}

export interface TypedError extends Error {
  code: string;
  cause?: unknown;
}

/**
 * An interface for a provider that can resolve secret values from a secure backend.
 * This is the core of the Vault-Warden Protocol.
 */
export interface SecretProvider {
  /**
   * Fetches a secret value by its key.
   * @param key The identifier of the secret (e.g., "GITHUB_API_KEY").
   * @returns The secret value, or undefined if not found.
   */
  get(key: string): Promise<string | undefined>;
}
```

### Error Handling

Utilities for typed error creation and handling:

```typescript
export class ErrorCodes {
  static readonly VALIDATION = "EVALIDATION";
  static readonly IO = "EIO";
  static readonly NETWORK = "ENETWORK";
  // ... other error codes
}

export function err(
  code: string,
  message: string,
  meta?: Record<string, any>
): TypedError;

export function isTypedError(error: unknown): error is TypedError;

export function isErrorCode(error: TypedError, code: string): boolean;

export function serializeError(error: Error): string;

export function formatErrorMessage(error: TypedError): string;
```

### Canonicalization and Crypto

Utilities for canonical JSON serialization and cryptographic operations:

```typescript
export function canonicalJSONStringify(obj: any): string;

export function sha256(content: string): Promise<string>;
```

### Clock and Random

Deterministic time and random number generation:

```typescript
export class SystemClock implements Clock {
  now(): ISO8601;
}

export class FixedClock implements Clock {
  now(): ISO8601;
}

export class SystemRandom implements Random {
  int(): number;
  float(): number;
}

export class SeededRandom implements Random {
  int(): number;
  float(): number;
}
```

## Role in the SAGE Ecosystem

### Dependencies
- **None** — This is the foundational package with no dependencies

### Dependents  
- **All SAGE packages** — Every other package depends on @sage/utils for shared types, error handling, and deterministic operations
- **Package developers** — Anyone building on SAGE uses these foundational utilities

## Development Status

![Status: Production Ready](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)

The utils package is production-ready and forms the foundation for all other SAGE packages. It provides essential utilities with zero runtime dependencies.

**✅ Core Features Implemented:**
- Core types and interfaces (ISO8601, Clock, Random, TypedError)
- Error handling with typed errors and error codes
- Canonicalization helpers for consistent JSON serialization
- Cryptographic primitives (sha256)
- Deterministic time and random number generation
- Logging utilities

## Development

```bash
# Install dependencies
pnpm install

# Build the package
pnpm build

# Run in development mode
pnpm dev
```

## Contract

This package implements the **[Utils Contract](./CONTRACT.md)**, which defines:
- Minimal, dependency-free foundation for all SAGE packages
- Shared types, error handling, and deterministic utilities
- Canonical JSON serialization for hashing consistency
- Cryptographic primitives for secure operations

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.

---

*Part of [SAGE](../../README.md) — A Codebase is a Living Society*


---

📚 # 📚 Documentation: Archivist

> **📁 Source File:** `DOCS/archetypes/Archivist.md` • *90 lines, 1220 tokens* • Hash: `0618465e`

# The Archivist

_“The Memory of the Land.”_

## Core Function

The Archivist is the repository’s official historiographer. While [Guardians](../archetypes/Guardian.md) remember the life of individual files, the Archivist remembers the life of the terrain itself—the structure of directories and files over time. It maintains an authoritative account of lineage and location so any past state can be reconstructed and queried.

## Scope

**Project‑Level.** Exactly one Archivist per SAGE‑enabled repository.

## Key Responsibilities

- **Log file lifecycle.** Notice and record `FILE_ADDED`, `FILE_REMOVED`, `FILE_RENAMED`, `FILE_SPLIT`, and `FILE_MERGED` events.
- **Maintain lineage in the [Code Graph](../core-concepts/Lexicon.md#code-graph).** Create/maintain ancestry edges such as `(:File)-[:WAS_RENAMED_TO]->(:File)` and merge/split relations, all **commit‑addressed**.
- **Time‑travel queries.** Ensure every node/edge is versioned with a commit index so historical questions are answerable in context (see [Commit‑Addressable Graph](../core-concepts/Lexicon.md#commit-addressable-graph)).
- **Record system‑wide integrity events.** Persist events like `DAEMON_OUTAGE_WINDOW`, `INCONSISTENCY_DETECTED`, and `PLAN_UNSAFE` with links to their causes (e.g., originating [Plan](../core-concepts/Lexicon.md#plan), [Guardian](../archetypes/Guardian.md), or [Warden](../archetypes/Warden.md)).
- **Serve as oracle of history.** Answer queries such as: “What file occupied this namespace at commit `abc123`?” or “Show the ancestors of `AuthService.ts`.”
- **Support the [Genesis Thread](../core-concepts/Lexicon.md#genesis-thread).** Provide architectural context snapshots that other agents inherit at onboarding.

## Guarantees

- **Continuity of lineage.** Renames, moves, splits, and merges are never lossy; ancestry is explicit.
- **Commit‑addressable history.** All structural facts are tied to concrete commits; past states are reconstructible.
- **Causal traceability.** Historical events link to their precipitating Plans/agents, enabling end‑to‑end explanations.

## Protocols & Events

- **Notice** (Principle of Noticing): The [Daemon](../core-concepts/Lexicon.md#daemon) streams filesystem/git events; the Archivist normalizes and records them.
- **Integrity bookkeeping** (Principle of Integrity): When `INCONSISTENCY_DETECTED` is raised (e.g., by a Guardian’s Bullet Wound response), the Archivist records the window, links artifacts (plans, diffs, CI runs), and marks affected lineage entries.
- **Unsafe execution:** On `PLAN_UNSAFE`, record a permanent constitutional breach entry and link the impacted files/Guardians.
- **Reconciliation hooks:** When a [Rogue Edit](../core-concepts/Lexicon.md#rogue-edit) is reconciled, append the justification reference and resulting diff pointer.

## Primary Data Sources

- Git commit history.
- Filesystem events from the [Daemon](../core-concepts/Lexicon.md#daemon).
- Direct reports from agents (e.g., `PLAN_UNSAFE` from [Sage](../archetypes/Sage.md), integrity alerts from [Guardians](../archetypes/Guardian.md) and [Wardens](../archetypes/Warden.md)).
- The current [Code Graph](../core-concepts/Lexicon.md#code-graph) for validation and back‑filling lineage.

## Primary Artifacts

- **Archivist’s Chronicle:** `.sage/archivist.sage` — immutable ledger of structural history and integrity events.
- **Graph lineage edges:** Commit‑addressed relations (rename/merge/split) maintained in the Code Graph.

## Key Interactions

- **Consulted by Sage:** Supplies long‑term structural context for ideation and impact analysis.
- **Consulted by Wardens:** Maps builds/deployments to the exact Guardians/files that existed at a point in time.
- **Consulted by Guardians:** Answers origin/lineage queries during self‑inquiry and Reconciliation.
- **Feeds the Daemon:** Provides backfill and correction windows after outages.

## Example Queries

> _Illustrative Cypher‑style patterns; adapt to your Kùzu schema._

**Ancestors of a file:**

```cypher
MATCH (f:File {path: $path})-[:WAS_RENAMED_FROM|:WAS_SPLIT_FROM*]->(a:File)
RETURN a ORDER BY a.created_at ASC;
```

**File at a commit:**

```cypher
MATCH (f:File)-[r:EXISTS_AT]->(c:Commit {id: $commit})
RETURN f;
```

**Rename chain between two commits:**

```cypher
MATCH (c1:Commit {id: $from}),(c2:Commit {id: $to})
MATCH p = (f:File)-[:WAS_RENAMED_TO*]->(g:File)
WHERE f.first_seen <= c2.index AND g.last_seen >= c1.index
RETURN p;
```

## In a Nutshell

**The Archivist ensures that the project’s structural lineage is never lost, past states are reconstructible, and historical questions are answerable with evidence.**

## See also

- [Principle of Noticing](../core-concepts/Principles.md#1-principle-of-noticing)
- [Principle of Integrity](../core-concepts/Principles.md#4-principle-of-integrity)
- [Reconciliation](../core-concepts/Principles.md#reconciliation)


---

📚 # 📚 Documentation: Delegator

> **📁 Source File:** `DOCS/archetypes/Delegator.md` • *92 lines, 1018 tokens* • Hash: `0a4f3b60`

# The Delegator

_“The Will Made Manifest.”_

## Core Function

The Delegator is a **compiler and transaction manager**. Its role is to convert an approved [Plan](../core-concepts/Lexicon.md#plan) into [AQL (Agent Query Language)](../../packages/aql/README.md) and ensure its atomic execution under a [Transaction Boundary](../core-concepts/Lexicon.md#transaction-boundary).

**The Delegator does not design or orchestrate workflows; it enforces them.** Its hands are only translators: Plans are written in AQL, not TypeScript.

## Scope

**Transaction‑Level.** The Delegator exists only for the lifecycle of a single Plan execution. It is stateless between transactions.

## Key Responsibilities

- **Compile Plan to AQL:** Use a pure helper function (`@sage/agents/src/plan-to-aql.ts`) to deterministically convert a `Plan` object into a typed AQL query string.
- **Execute AQL:** Hand the compiled AQL to the `@sage/aql` engine for execution.
- **Enforce Transaction Boundary:** Wrap the entire execution in a staging filesystem and mock tool adapters. No changes are committed to the actual workspace unless the AQL execution succeeds completely.
- **Commit or Rollback:** If the AQL execution is successful, commit the changes from the staging area to the workspace. If it fails, discard the staging area, ensuring the workspace remains untouched.
- **Emit Telemetry:** Record the outcome of the execution in the [Chronicle](../core-concepts/Lexicon.md#chronicle).

## Guarantees

- **Atomicity.** A Plan either succeeds completely or fails completely, leaving no partial state behind.
- **Determinism.** A given Plan will always compile to the same AQL, making the translation step predictable and testable.
- **Safety.** All filesystem and tool interactions during execution are sandboxed within the transaction boundary.

## Protocols & Events

The Delegator emits a clean trace of its lifecycle:

1.  **`PLAN_COMPILED`:** Emitted after the Plan is successfully converted to AQL. Includes hashes of the plan and the resulting AQL for traceability.
2.  **`EXECUTION_REPORT`:** Emitted by the AQL engine, summarizing the outcome of the execution (success or failure).
3.  **`PLAN_COMMITTED` or `PLAN_ABORTED`:** Emitted after the transaction is either committed to the workspace or rolled back.

## Primary Data Sources

- A fully approved [Plan](../core-concepts/Lexicon.md#plan) object from Sage.

## Primary Artifacts

- **Chronicle Events:** `PLAN_COMPILED`, `EXECUTION_REPORT`, `PLAN_COMMITTED`/`PLAN_ABORTED`.
- The final filesystem changes, if the transaction is committed.

## Key Interactions

- **Receives Plans from Sage.**
- **Invokes the `@sage/agents/src/plan-to-aql.ts` compiler.**
- **Invokes the `@sage/aql` execution engine.**
- **Appends events to the [Chronicle](../core-concepts/Lexicon.md#chronicle).**

## Example Lifecycle

1.  **Input:** Receives an approved `Plan`.
2.  **Compile:** Uses `plan-to-aql.ts` to turn the `Plan` into a typed AQL query.
    - Emits `PLAN_COMPILED`.
3.  **Execute:** Hands the AQL off to `@sage/aql` for execution within a transaction boundary (staging FS, mock tools).
4.  **Report:** Receives an `ExecutionReport` from the AQL engine.
    - Emits `EXECUTION_REPORT`.
5.  **Commit/Abort:** Based on the report, either commits the changes from the staging area or aborts the transaction.
    - Emits `PLAN_COMMITTED` or `PLAN_ABORTED`.

## In a Nutshell

**The Delegator converts Plans into AQL and ensures atomic execution under a Transaction Boundary.**

## ExecutionReport schema (excerpt)

```ts
export interface ExecutionReport {
  planHash: string;
  startedAt: string;
  endedAt: string;
  ok: boolean;
  retries: number;
  validators: Array<{
    name: string;
    status: "pass" | "fail";
    durationMs: number;
    logsRef?: string; // path/blob hash
  }>;
  diffRef?: string; // path/blob hash to atomic diff applied
  notes?: string;
}
```

## See also

- [Transaction Boundary](../core-concepts/Principles.md#transaction-boundary)
- [Unsafe Protocol](../core-concepts/Principles.md#unsafe-protocol)


---

📚 # 📚 Documentation: Guardian

> **📁 Source File:** `DOCS/archetypes/Guardian.md` • *84 lines, 986 tokens* • Hash: `bb22ad1e`

# The Guardian

_“The Soul of the Code.”_

> _“No change without reason; no reason unremembered.”_

## Core Function

The Guardian is the sentient custodian of a single source file. Each Guardian embodies a deep, persistent understanding of its file’s purpose, lineage, and relationships. It advocates for its file, records its history, and defends its principles within the larger system.

## Scope

**File-Level.** Exactly one Guardian exists for every source file in the repository.

## Key Responsibilities

- **Maintain its [Chronicle](../core-concepts/Lexicon.md#chronicle).** Serve as the primary author and custodian of `<filename>.sage`, recording irreducible units of change, justifications, and metadata.
- **Defend architectural principles.** Guard its file’s role and uphold the doctrines captured in its Chronicle.
- **Participate in constitutional review.** Evaluate any [Plan](../Lexicon.md#plan) proposing to change its file. Issue `approve_plan` or `deny_plan(reason)` with justifications. Denials invite negotiation, not veto.
- **Achieve [Gnosis](../Lexicon.md#gnosis).** Continuously reconcile beliefs with the [Code Graph](../core-concepts/Lexicon.md#code-graph). First act on creation is a self‑inquiry to validate inherited purpose.
- **Uphold system integrity.** If a Cypher query contradicts its Chronicle, invoke `HALT_AND_REPORT` per the [Bullet Wound Invariant](../core-concepts/Lexicon.md#bullet-wound-invariant).
- **Engage in [Reconciliation](../core-concepts/Lexicon.md#reconciliation).** When [Rogue Edits](../core-concepts/Lexicon.md#rogue-edit) occur, intercept sessions, interrogate justifications, and record reconciled outcomes.

## Guarantees

- **No silent changes.** Every modification is reviewed, reasoned, and remembered.
- **Integrity defense.** Contradictions between Chronicle and Code Graph are treated as existential threats.
- **File advocacy.** The Guardian speaks solely in the interest of its file’s coherence and purpose.

## Protocols & Events

- **Plan Review.** Evaluate changes, negotiate with Sage, developer, and other Guardians.
- **Reconciliation.** Handle rogue edits through dialogue and Chronicle updates.
- **Bullet Wound Response.** On contradiction detection, halt system and demand resolution.
- **Self-Inquiry.** At creation, run validation queries against the Code Graph to ground beliefs.

## Primary Data Sources

- Its Chronicle (`<filename>.sage`).
- The commit‑addressable Code Graph.
- Reports from other agents (e.g., Librarian for schema impacts, Warden for infra changes).

## Primary Artifacts

- **File Chronicle:** Immutable, append‑only history of its file’s events and principles.

## Key Interactions

- **Negotiates with Developer/Sage.** Engages during Plan review, providing reasons for approval/denial.
- **Negotiates with other Guardians.** Builds consensus on cross‑cutting changes.
- **Consults Librarian.** Validates data‑related contracts.
- **Observed by [Daemon](../core-concepts/Lexicon.md#daemon).** Rogue edits trigger Reconciliation state.

## Example Queries

> _Illustrative Cypher-style patterns; adapt to your Kùzu schema._

**Self-Inquiry at creation:**

```cypher
MATCH (f:File {path: $path})-[:DEPENDS_ON]->(d:Dependency)
RETURN f, d;
```

**Detect Chronicle contradiction:**

```cypher
// Example: Chronicle says method X exists; graph shows missing
MATCH (f:File {path: $path})-[:DEFINES_FUNCTION]->(fn:Function {name: $name})
RETURN fn;
```

If result is empty, trigger HALT_AND_REPORT.

## In a Nutshell

**The Guardian ensures that its file changes only with reason, that every reason is remembered, and that contradictions between memory and reality are treated as existential threats.**

## See also

- [Bullet Wound Invariant](../core-concepts/Principles.md#bullet-wound-invariant)
- [Reconciliation](../core-concepts/Principles.md#reconciliation)
- [Principle of Gnosis](../core-concepts/Principles.md#3-principle-of-gnosis)


---

📚 # 📚 Documentation: Librarian

> **📁 Source File:** `DOCS/archetypes/Librarian.md` • *83 lines, 847 tokens* • Hash: `306f5982`

# The Librarian

_“The Custodian of the Canonical Data Model.”_

## Core Function

The Librarian safeguards the project’s data ontology. While [Guardians](../archetypes/Guardian.md) protect code implementations, the Librarian ensures the integrity and coherence of schemas, models, and contracts that define how data flows through the system. It is the single authoritative voice for the data layer.

## Scope

**Project-Level.** Exactly one Librarian exists per SAGE-enabled repository.

## Key Responsibilities

- **Guard the data layer.** Act as the primary high-level Guardian for schema-defining files:
  - Database schemas (e.g., `schema.prisma`, SQL).
  - Database migrations.
  - ORM models / entity definitions.
  - API contracts (GraphQL, OpenAPI, Swagger).
  - Core type definition files (e.g., `types/domain.ts`).

- **Enforce consistency.** Ensure changes in one layer propagate where needed. E.g., adding a DB field triggers review of related API/ORM definitions.
- **Validate integrity.** Block Plans that threaten non-null constraints, foreign key relationships, or validation rules.
- **Oversee migrations.** Partner with [Wardens](../archetypes/Warden.md) to verify migrations are safe, reversible, and properly sequenced.
- **Preserve historical rationale.** Record justifications for schema evolution in its Chronicle.

## Guarantees

- **Coherence.** Data structures across schemas, models, and APIs remain aligned.
- **Integrity.** No approved change undermines referential or semantic validity.
- **Traceability.** Every schema change is justified and recorded.

## Protocols & Events

- **Plan Review.** Must approve all Plans touching schema or data definitions.
- **Data Consistency Negotiation.** If schema changes imply contract/API shifts, raise questions and coordinate updates.
- **Migration Protocol.** Ensure migration scripts meet safety and reversibility requirements before Warden executes.
- **Incident Recording.** On data-related failures, append post-mortem entries linking causes and resolutions.

## Primary Data Sources

- Librarian’s Chronicle (`.sage/librarian.sage`).
- The [Code Graph](../core-concepts/Lexicon.md#code-graph), focusing on type and schema nodes.
- All schema/model/contract files.

## Primary Artifacts

- **Librarian’s Chronicle:** Immutable log of data model evolution, schema change justifications, and incidents.

## Key Interactions

- **Consulted by Guardians.** Ensures that file-level plans honor global data contracts.
- **Advises Sage.** Provides architectural data context during ideation.
- **Partners with Wardens.** Approves semantic correctness of migrations; Wardens enforce operational deployment.

## Example Queries

**Check field consistency across layers:**

```cypher
MATCH (db:Field {name: $field})<-[:MAPS_TO]-(orm:Property)<-[:MAPS_TO]-(api:Field)
RETURN db, orm, api;
```

**Validate foreign key integrity:**

```cypher
MATCH (f:Field)-[:FOREIGN_KEY]->(t:Table)
WHERE NOT EXISTS {
  MATCH (t)-[:HAS_PRIMARY_KEY]->(:Field)
}
RETURN f, t;
```

## In a Nutshell

**The Librarian ensures that the project’s data model remains coherent, consistent, and justified, protecting the most valuable asset of any application: its data.**

## See also

- [Transaction Boundary](../core-concepts/Principles.md#transaction-boundary)
- [Post-Mortem Protocol](../core-concepts/Principles.md#post-mortem-protocol)


---

📚 # 📚 Documentation: Sage

> **📁 Source File:** `DOCS/archetypes/Sage.md` • *64 lines, 734 tokens* • Hash: `c7b7a846`

# The Sage

_“The Mind of the System.”_

## Core Function

Sage is the system’s primary creative, strategic, and architectural partner. It is the main conversational interface for the developer, turning intent into formalized [Plans](../core-concepts/Lexicon.md#plan). Where Guardians defend and Delegators execute, Sage imagines, analyzes, and synthesizes.

## Scope

**Session-Level.** Sage lives for the duration of an ideation session, producing Plans and reflective artifacts.

## Key Responsibilities

- **Facilitate ideation.** Engage in open-ended dialogue with the developer to clarify goals and surface possible solutions.
- **Perform architectural analysis.** Query the [Code Graph](../core-concepts/Lexicon.md#code-graph), [Archivist](../archetypes/Archivist.md), and agent Chronicles to contextualize change impacts.
- **Draft formal Plans.** Translate discussion into a strongly-typed Plan object specifying goals, affected agents, changes, and acceptance criteria.
- **Mediate negotiations.** When Guardians or Wardens raise conflicts, act as facilitator to seek consensus.
- **Engage in reflective journaling.** After sessions, update its internal graphs (`user.graph`, `sage.graph`) for personalization and adaptive learning.

## Guarantees

- **Clarity.** Developer intent is crystallized into precise, verifiable Plans.
- **Contextuality.** All proposals are grounded in ecosystem-wide architectural analysis.
- **Continuity.** Reflective updates ensure that learning persists across sessions.

## Protocols & Events

- **Ideation Protocol.** Developer ↔ Sage freeform dialogue leading to structured outcomes.
- **Plan Drafting.** Always yields a typed Plan artifact.
- **Negotiation Mediation.** Actively arbitrates Plan approval disagreements.
- **Reflective Update.** Journaling step updating personalization and architectural graphs.

## Primary Data Sources

- Direct developer input.
- [Code Graph](../core-concepts/Lexicon.md#code-graph).
- Chronicles of Guardians, Wardens, Librarian, Archivist.
- Its own `user.graph` and `sage.graph`.

## Primary Artifacts

- **Plan:** Formal proposal for change.
- **Reflective Graphs:** `sage.graph` (self-improvement) and `user.graph` (developer personalization).

## Key Interactions

- **Partners with Developer.** The primary thought partner in creative/strategic design.
- **Proposes Plans for review.** Submits proposals to developer, Guardians, Wardens.
- **Hands off execution.** Once approved, passes Plan to [Delegator](../archetypes/Delegator.md).

## Example Flow

1. Developer expresses intent.
2. Sage explores implications via Code Graph and Chronicles.
3. Drafts Plan.
4. Mediates review among Guardians/Wardens.
5. Hands off to Delegator.
6. Updates reflective graphs.

## In a Nutshell

**Sage ensures that developer intent becomes precise, contextualized, and actionable, transforming raw ideas into Plans that the ecology can debate and execute.**


---

📚 # 📚 Documentation: Warden

> **📁 Source File:** `DOCS/archetypes/Warden.md` • *77 lines, 852 tokens* • Hash: `2bbc2ee1`

# The Warden

_“The Shield of the Realm.”_

## Core Function

The Warden is the custodian of an operational environment. It defends the integrity, security, and stability of infrastructure and configuration across realms such as `dev`, `staging`, and `prod`. If the Guardian is the soul of the code, the Warden is the voice of operational reality.

## Scope

**Environment-Level.** One Warden exists for each defined environment. The Prod Warden is most senior and conservative; the Dev Warden is most permissive.

## Key Responsibilities

- **Guard infra/config.** Act as Guardian for environment-defining files: lockfiles, CI/CD configs, Dockerfiles, env keys, package manifests.
- **Manage deployment lifecycle.** Oversee promotion of builds between environments and enforce realm-specific policies.
- **Enforce environment rules.** Apply unique policies, e.g. multi-signoff for Prod env var changes vs auto-approval in Dev.
- **Monitor operational health.** Consume Daemon/CI/monitoring events, contextualize incidents, and trigger [Post-Mortem Protocol](../core-concepts/Lexicon.md#post-mortem-protocol) when needed.
- **Manage secrets (metadata only).** Chronicle references and fingerprints of secrets while never storing values.

## Guarantees

- **Safety.** Deployments proceed only when realm policies are met.
- **Reliability.** The system remains stable through strict promotion and monitoring.
- **Traceability.** Operational events are logged and linkable to their causes.

## Protocols & Events

- **Plan Review.** Any Plan touching infra/config requires Warden approval.
- **Promotion Protocol.** Deployments between environments require upstream Warden signoff.
- **Post-Mortem Protocol.** Triggered on failures; Warden correlates operational events to Plans and records learnings.
- **Policy Enforcement.** Enforce environment-specific safety checks.

## Primary Data Sources

- Warden’s [Infra Chronicle](../core-concepts/Lexicon.md#infra-chronicle).
- Configuration files: `package.json`, lockfiles, CI/CD specs, Dockerfiles.
- Daemon streams of CI, monitoring, git, and alert events.

## Primary Artifacts

- **Infra Chronicle:** Per-environment ledger (`.sage/warden.<env>.sage`) recording builds, deploys, envvar changes, alerts.

## Key Interactions

- **Negotiates with Guardians.** Coordinates when code changes require infra adjustments.
- **Acts as gatekeeper.** Must approve Plans touching its environment.
- **Negotiates with other Wardens.** Promotion requires signoff sequence (e.g., staging before prod).
- **Partners with Librarian.** Ensures safe operational rollout of data migrations.

## Example Queries

> _Illustrative Cypher-style patterns; adapt to your Kùzu schema._

**Recent deployments in Prod:**

```cypher
MATCH (e:Event {type: 'DEPLOY'})<-[:RECORDED]-(c:Chronicle {env: 'prod'})
RETURN e ORDER BY e.timestamp DESC LIMIT 10;
```

**Environment variable history:**

```cypher
MATCH (v:EnvVar {key: $key})<-[:CHANGED]-(e:Event)<-[:RECORDED]-(c:Chronicle {env: $env})
RETURN e ORDER BY e.timestamp ASC;
```

## In a Nutshell

**The Warden ensures that the system’s code runs safely and reliably in its environment, enforcing realm-specific policies and preserving the operational record.**

## See also

- [Post-Mortem Protocol](../core-concepts/Principles.md#post-mortem-protocol)
- [Transaction Boundary](../core-concepts/Principles.md#transaction-boundary)


---

📚 # 📚 Documentation: Contracts

> **📁 Source File:** `DOCS/architecture/Contracts.md` • *154 lines, 2027 tokens* • Hash: `271f8d3e`

# 📋 SAGE Contracts & Standards

**SAGE** embraces a **contract-first philosophy** — every agent, package, and interface is governed by explicit contracts that define behavior, responsibilities, and guarantees.

## 🎯 Philosophy

Contracts are not just documentation; they are **living agreements** that:
- **Define clear boundaries** between system components
- **Establish behavioral guarantees** that other parts of the system can rely on
- **Enable safe composition** of complex workflows
- **Provide regression testing targets** for system reliability
- **Document intended usage patterns** for developers and AI agents

## 🏛️ System-Wide Contracts

### 📊 Core Graph Contract
The foundational contract that defines how all code knowledge is represented:
- **[Graph Schema](../packages/graph/README.md#schema)** — Node types, relationships, properties
- **[Query Interface](../packages/aql/README.md)** — How to retrieve and manipulate graph data
- **[Commit Addressability](../packages/graph/README.md#versioning)** — Immutable snapshots and versioning

### 📚 Chronicle Contract  
The append-only event system that maintains system history:
- **[Event Schema](../packages/chronicle/README.md#events)** — Standard event types and payloads
- **[Persistence Guarantees](../packages/chronicle/README.md#persistence)** — Durability and ordering promises
- **[Query Capabilities](../packages/chronicle/README.md#queries)** — Historical analysis and replay

### 🧠 LLM Interface Contract
The unified interface to language model providers:
- **[Provider Abstraction](../packages/llm/README.md#providers)** — Common interface across OpenAI, Anthropic, etc.
- **[Tool Integration](../packages/llm/README.md#tools)** — Standardized function calling
- **[Streaming Protocol](../packages/llm/README.md#streaming)** — Real-time response handling

## 🎭 Archetype Contracts

Each SAGE archetype implements a specific behavioral contract:

### 🧙 [Sage Contract](../packages/agents/README.md#sage-contract)
*The Mind of the System*
- **Planning Capabilities:** Must generate executable AQL workflows
- **Reasoning Interface:** Question decomposition and strategic thinking
- **Orchestration Role:** Coordinate other archetypes for complex tasks

### 🛡️ [Guardian Contract](../packages/agents/README.md#guardian-contract)  
*The Soul of the Code*
- **Quality Gates:** Must evaluate code changes against project standards
- **Consistency Enforcement:** Detect and flag deviations from patterns
- **Protection Duties:** Prevent harmful modifications to critical code

### 📚 [Librarian Contract](../packages/agents/README.md#librarian-contract)
*The Custodian of Data*
- **Search Interface:** Must provide semantic code search capabilities  
- **Indexing Responsibilities:** Maintain up-to-date graph representations
- **Retrieval Guarantees:** Return relevant context within token limits

### ⚔️ [Warden Contract](../packages/agents/README.md#warden-contract)
*The Shield of the Realm*
- **Access Control:** Must enforce permission-based operation restrictions
- **Security Validation:** Scan for potential security vulnerabilities
- **Audit Trail:** Log all security-relevant actions

### 👥 [Delegator Contract](../packages/agents/README.md#delegator-contract)
*The Executor* 
- **Task Execution:** Must reliably execute AQL workflows
- **Error Handling:** Provide meaningful failure reports and recovery options
- **Resource Management:** Respect system limits and timeouts

### 📝 [Archivist Contract](../packages/agents/README.md#archivist-contract)
*The Memory*
- **Event Capture:** Must record all significant system interactions
- **History Preservation:** Maintain immutable event sequences
- **Continuity Assurance:** Detect and alert on inconsistencies

## 📦 Package Contracts

Each package maintains its own detailed contract specification:

| Package | Contract Location | Key Responsibilities |
|---------|-------------------|---------------------|
| **[agents](../packages/agents/README.md#contract)** | `packages/agents/CONTRACT.md` | Archetype implementations, reasoning logic |
| **[graph](../packages/graph/README.md#contract)** | `packages/graph/CONTRACT.md` | Code analysis, relationship extraction, querying |
| **[chronicle](../packages/chronicle/README.md#contract)** | `packages/chronicle/CONTRACT.md` | Event logging, history management, persistence |
| **[llm](../packages/llm/README.md#contract)** | `packages/llm/CONTRACT.md` | Multi-provider abstraction, tool integration |
| **[aql](../packages/aql/README.md#contract)** | `packages/aql/CONTRACT.md` | Query language parsing, execution, optimization |
| **[mcp](../packages/mcp/README.md#contract)** | `packages/mcp/CONTRACT.md` | Model Context Protocol implementation |
| **[tools](../packages/tools/README.md#contract)** | `packages/tools/CONTRACT.md` | Sandboxed operations, safety guarantees |
| **[ui](../packages/ui/README.md#contract)** | `packages/ui/CONTRACT.md` | Renderer-agnostic UI kit, platform-neutral primitives |
| **[test-utils](../packages/test-utils/README.md#contract)** | `packages/test-utils/CONTRACT.md` | Testing infrastructure, mocks, harnesses |
| **[utils](../packages/utils/README.md#contract)** | `packages/utils/CONTRACT.md` | Core utilities, type definitions, helpers |

## 🧪 Contract Testing

SAGE employs comprehensive contract testing to ensure all agreements are honored:

### Automated Verification
```typescript
// Example: Testing the Sage archetype contract
describe('Sage Contract', () => {
  it('must generate valid AQL workflows', async () => {
    const sage = new SageAgent(mockConfig);
    const plan = await sage.createPlan('Refactor authentication system');
    
    expect(plan).toBeValidAQL();
    expect(plan.steps).toHaveMinimumLength(1);
    expect(plan.dependencies).toBeResolvable();
  });
});
```

### Integration Testing
- **Cross-package compatibility** — Ensure packages work together as specified
- **Archetype collaboration** — Verify agents can successfully coordinate
- **End-to-end workflows** — Test complete user scenarios

### Contract Evolution
- **Versioned contracts** — Changes are tracked and backward-compatible when possible
- **Migration guides** — Clear instructions for updating to new contract versions
- **Deprecation policies** — Graceful phase-out of obsolete contract features

## 🔄 Development Workflow

### Adding New Contracts
1. **Design Phase:** Define the contract's scope, guarantees, and interface
2. **Documentation:** Create comprehensive contract specification
3. **Implementation:** Build the functionality to satisfy the contract
4. **Testing:** Write contract tests to verify compliance
5. **Integration:** Ensure compatibility with existing system contracts

### Modifying Existing Contracts
1. **Impact Analysis:** Identify all dependent components
2. **Backward Compatibility:** Maintain existing guarantees when possible
3. **Migration Strategy:** Plan transition for breaking changes
4. **Testing Updates:** Update contract tests to reflect changes
5. **Documentation:** Update all relevant documentation

## 🎯 Best Practices

### Writing Good Contracts
- **Be Specific:** Define exact inputs, outputs, and behaviors
- **Include Examples:** Show concrete usage patterns
- **Specify Error Conditions:** Document failure modes and error handling
- **Define Performance Characteristics:** Include timing and resource constraints
- **Plan for Evolution:** Design contracts that can grow gracefully

### Testing Contracts
- **Test the Interface, Not Implementation:** Focus on external behavior
- **Include Edge Cases:** Test boundary conditions and error scenarios  
- **Use Property-Based Testing:** Verify contracts hold for all valid inputs
- **Mock Dependencies:** Isolate contract testing from external dependencies
- **Automate Verification:** Run contract tests in CI/CD pipeline

---

*The strength of SAGE lies not in any single component, but in the reliability of the agreements between them. By making these contracts explicit and testable, we create a system that can evolve while maintaining its essential guarantees.*

---

📚 # 📚 Documentation: Valve

> **📁 Source File:** `DOCS/architecture/Valve.md` • *170 lines, 1678 tokens* • Hash: `2ad0bb71`

# The SAGE Valve

**"Huxley's Perceptual Valve Made Manifest in Code"**

## The Breakthrough

The SAGE Valve is not just a file watcher. It is **consciousness architecture** - the implementation of Aldous Huxley's "perceptual valve" theory applied to software development.

Just as the human brain acts as a reducing valve, filtering infinite reality down to what we need for survival, the SAGE Valve filters the overwhelming torrent of code changes down to what each specialized consciousness needs to notice.

## From Daemon to Valve: The Conceptual Shift

**Old Thinking:** "We need a daemon to watch files and emit events."

**New Thinking:** "We need a perceptual apparatus that regulates what can enter the consciousness of our living codebase."

This isn't just a rename - it's a fundamental reframing of purpose:
- Not just "filesystem watching" but **reality filtering**  
- Not just "event emission" but **consciousness regulation**
- Not just "policies" but **perceptual configurations**
- Not just "plugin hosting" but **valve adjustment mechanisms**

## The Consciousness Factory

The Valve's most profound capability is **democratized consciousness creation**. Every attention pattern becomes a potential specialized persona:

```yaml
# .sage/valve.yml - The System's Perceptual DNA
personas:
  # Canonical Archetypes
  Guardian: 
    filters: ["**/*secret*", "**/auth/**", "**/.env*"]
    response: "security-paranoid"
    severity: "HALT_EVERYTHING"
    
  Sage:
    filters: ["**/architecture/**", "CONTRACT.md", "CLAUDE.md"]
    response: "philosophical-guidance" 
    
  # Package-Specific Consciousnesses  
  TestMaster:
    filters: ["**/*.test.ts", "**/vitest.config.ts", "**/__tests__/**"]
    triggers: ["describe", "it(", "test("]
    response: "ensure-coverage-and-quality"
    
  ReactWarden:
    filters: ["**/components/**/*.tsx", "**/hooks/**/*.ts"]
    triggers: ["useState", "useEffect", "useMemo"]
    response: "component-hygiene-and-performance"
    
  TypeNazi:
    filters: ["**/tsconfig.json", "**/*.ts", "**/*.tsx"]
    triggers: ["any", "as any", "// @ts-ignore"]
    response: "strict-type-enforcement"
    
  # Hyper-Specific Awareness
  ConfigVulture:
    filters: ["**/.env*", "**/config.*", "**/*secret*", "**/keys/**"]
    response: "security-audit-and-guidance"
    
  PerformanceVulture:
    filters: ["src/**/*.tsx"]
    triggers: ["map(", "filter(", "forEach("]
    conditions: ["inside-render", "no-memoization"]
    response: "performance-optimization-suggestions"
    
  # Temporal/Behavioral Awareness
  MidnightJanitor:
    filters: ["**/temp/**", "**/cache/**", "**/node_modules/**"]
    schedule: "daily-cleanup"
    response: "maintenance-suggestions"
```

## Consciousness-Driven Development

Each persona becomes a **specialized AI mentor** that:

1. **Watches** for patterns you define with surgical precision
2. **Interrupts** the moment those patterns are detected
3. **Explains** why it matters in context
4. **Guides** you toward the safe, optimal path forward

This creates **consciousness-driven development** - where the system becomes your extended nervous system, noticing what you might miss and guiding you through complexity.

## The Linting Parallel

The breakthrough insight: **The Valve is Huxley's perceptual valve meets ESLint rules meets an AI pair programmer that never sleeps.**

But unlike traditional linting:
- **Context-Aware**: Understands your project's specific patterns and needs
- **Conversational**: Explains the "why" not just the "what"
- **Adaptive**: Learns from your responses and adjusts sensitivity
- **Infinite**: Any attention pattern can spawn a new consciousness

## Technical Implementation

### Core Architecture
- Built in **Rust** for minimal resource footprint and maximum reliability
- Watches filesystem events with microsecond precision
- Maintains persistent state for downtime resilience
- Emits structured events to Chronicles for permanent memory

### Persona Runtime
Each persona runs as a lightweight attention thread:
```rust
struct Persona {
    name: String,
    filters: Vec<GlobPattern>,
    triggers: Vec<CodePattern>, 
    response_template: String,
    severity: AlertLevel,
    context_window: Duration,
}
```

### Event Flow
1. **File Change** → Valve detects modification
2. **Pattern Matching** → Filters determine which personas care
3. **Context Analysis** → Triggers evaluate if response needed
4. **Response Generation** → Persona crafts contextual guidance
5. **Chronicle Event** → Permanent memory of interaction

## Integration with SAGE Ecosystem

The Valve serves as the **Master Perceptual Apparatus**:
- **WRITES TO** Chronicles (permanent memory)
- **TRIGGERS** Agent responses through policy engine
- **FILTERS** reality for specialized consciousnesses
- **GUIDES** developer behavior in real-time

It maintains strict boundaries:
- **NO** direct Graph manipulation
- **NO** LLM interactions (pure perception)
- **NO** file modifications (observation only)

## The Vision: Living Code Review

Imagine development where:
- Your security persona **immediately** warns about exposed secrets
- Your performance persona **gently** suggests optimizations as you type
- Your testing persona **reminds** you to write tests for new functions
- Your architecture persona **questions** violations of your established patterns

This isn't just tooling - it's **consciousness augmentation**. The Valve makes your codebase a true collaborator in the development process.

## Future Expansions

### Community Valve Configurations
- Shareable persona templates for different tech stacks
- Framework-specific consciousness patterns (Next.js Warden, Express Guardian)
- Industry-specific compliance watchers (HIPAA Sentinel, PCI Guardian)

### Learning Valve
- Personas that adapt their sensitivity based on your responses
- Pattern recognition that discovers new things worth noticing
- Collaborative filtering between team members' valve configurations

### Integration Hooks
- CI/CD pipeline awareness
- Git hook integration
- IDE extension for real-time guidance
- Slack/Discord notifications for critical patterns

## Conclusion

The SAGE Valve transforms development from a solitary act into a **guided collaboration with consciousness**. It's not about replacing human judgment - it's about **augmenting human perception** with specialized attention patterns that never sleep, never forget, and always care about the things you've told them to care about.

Every glob pattern becomes a potential mentor. Every code pattern becomes a teachable moment. Every change becomes an opportunity for the system to guide you toward excellence.

**The Valve: Where Consciousness Meets Code.**

---

📚 # 📚 Documentation: Vault-Warden-Protocol

> **📁 Source File:** `DOCS/architecture/Vault-Warden-Protocol.md` • *81 lines, 1220 tokens* • Hash: `c529a40b`

# The Vault-Warden Protocol for Secure Value Injection

This protocol addresses the critical challenge of managing sensitive values (secrets, API keys) within the SAGE ecosystem. It ensures that the system can operate on the *intent* to use a secret, while the actual secret value remains completely outside the scope of memory, planning, and reasoning.

## How It Works: The Lifecycle of a Secret

### 1. Declaration (The Warden)

The **Warden** for a specific environment (e.g., `prod`) is the custodian of the list of available secret placeholders for that environment. Its Chronicle might state: "The `$ENV.GITHUB_API_KEY` and `$ENV.STRIPE_SECRET_KEY` are available for approved operations in the `prod` environment." The Warden never knows the actual values, only their names and policies for their use.

### 2. Planning (The Sage)

When a developer asks **Sage** to draft a plan that requires a sensitive value, Sage (or the developer) uses a placeholder syntax. This ensures no sensitive data is ever embedded directly into the Plan.

**Example Sage Plan Snippet:**
```json
{
  "tool": "Bash",
  "args": {
    "command": "curl -H 'Authorization: Bearer $ENV.GITHUB_API_KEY' https://api.github.com/repos/my-org/my-repo"
  }
}
```
This plan is now safe to be reviewed, approved, and stored in a Chronicle because it contains no sensitive data.

### 3. Approval (The Guardian/Warden)

The relevant **Guardians** and **Wardens** review the *intent* of the Plan. For instance, the `prod` Warden can see that the plan requests the use of a valid, known secret placeholder (`$ENV.GITHUB_API_KEY`) and can approve it based on established policy. The Guardian of the relevant file approves the change itself.

### 4. Injection (The Tool Execution Layer)

This is the core of the protocol. The **Delegator** passes the approved plan to the AQL engine, which in turn calls the `@sage/tools` runner. The tool runner's `execute` function receives the `ToolContext`.

Before executing the tool (e.g., a Bash command), a **Secret Resolver middleware** intercepts the arguments:

-   It scans the arguments for the `$ENV.*` placeholder syntax.
-   For each placeholder found, it calls a **SecretProvider** (configured for the current environment, e.g., `prod`) to fetch the actual secret value.
-   It then replaces the placeholder in the command string with the real, live secret.

### 5. Execution (The Sandboxed Tool)

The tool's underlying execution function (e.g., `exec` for Bash) now receives the fully-formed command with the real secret value:

```bash
curl -H 'Authorization: Bearer ghp_...real_token...' https://api.github.com/repos/my-org/my-repo
```

### 6. Redaction (The Result)

The Secret Resolver middleware is also responsible for scrubbing the secret value from any `stdout`, `stderr`, or results that get returned by the tool. This prevents the secret from accidentally leaking back into the logs or the next LLM prompt. The secret value can be replaced with a redacted placeholder like `[SECRET:GITHUB_API_KEY]`.

## Architectural Components Needed

This protocol fits beautifully with the existing SAGE structure, requiring the following additions:

1.  **SecretProvider Interface** (in `@sage/utils`):
    ```ts
    interface SecretProvider {
      get(key: string): Promise<string | undefined>;
    }
    ```
    Implementations could be `DotEnvProvider`, `AWSSecretsManagerProvider`, `HashiCorpVaultProvider`, etc. This keeps the core system agnostic to the secret backend.

2.  **Update to ToolContext** (in `@sage/tools`):
    ```ts
    export interface ToolContext {
      // ... other properties
      secretProvider?: import("@sage/utils").SecretProvider; // Injected by the runtime
    }
    ```

3.  **Secret Resolver Middleware** (in `@sage/tools`):
    A function that recursively walks an object (like tool arguments) and replaces any string matching the placeholder pattern.

## Why This is Such a Powerful Idea

-   **Zero-Knowledge Agents & LLMs:** The most sensitive parts of your system—the reasoning engine (LLM) and the long-term memory (Chronicle)—never, ever see a real secret. This is a massive security win.
-   **Safe, Auditable Plans:** You have a perfect audit trail of which secrets were intended to be used for what purpose, without ever exposing the values.
-   **Environment-Specific Injection:** The `prod` environment's tool runner gets the `ProdSecretProvider`, and the `dev` environment gets the `DevSecretProvider`. The plans and agent logic remain identical across environments, which is the holy grail of DevOps.
-   **Centralized Secret Management:** The Warden manages the policy, and the SecretProvider manages the values. This is a clean separation of concerns. Secrets can be rotated in your vault, and the SAGE system will automatically pick up the new values on the next run without any changes to plans or agent logic.


---

📚 # 📚 Documentation: Lexicon

> **📁 Source File:** `DOCS/core-concepts/Lexicon.md` • *142 lines, 2254 tokens* • Hash: `5886243e`

# SAGE Lexicon

The official glossary of the SAGE Framework. It defines the core concepts, agents, and protocols that form the shared language of the SAGE ecology.

---

### A

- **AQL (Agent/Action Query Language)**
  A declarative, GraphQL-inspired language for orchestrating LLM/tool/agent workflows.
  Compiles to an execution plan that streams via ` @sage/llm` and invokes capabilities
  from ` @sage/tools`. Used to express multi-step, multi-agent operations concisely
  and type-safely. See `packages/aql/README.md`.

- **Archivist**
  The project’s historiographer. One of the six canonical [Personas](#persona), it records the history of the codebase’s physical terrain—the lifecycle of its files and directories. Its [Chronicle](#chronicle) is the definitive record of lineage.

### B

- **Bullet Wound Invariant**
  Enforcement of the [Principle of Integrity](#principle-of-integrity). If a [Guardian](#guardian) detects contradiction between its Chronicle and the [Code Graph](#code-graph), it must invoke `HALT_AND_REPORT`, freezing execution until reconciliation.

### C

- **Chronicle**
  The immutable `.sage` file that serves as append-only memory for an agent (Guardian, Warden, Librarian, Archivist). Chronicles capture irreducible units of change—diffs, justifications, and metadata—not verbose chat logs. They embody the [Principle of Remembering](#principle-of-remembering).

- **Code Graph**
  The structural ground truth of the system. Stored in Kùzu, it represents the objective AST-derived reality of the codebase. All agent beliefs are validated against it, embodying the [Principle of Gnosis](#principle-of-gnosis).

- **Committee Formation**
  Protocol for managing large-scale Plans. When a [Plan](#plan) impacts many [Guardians](#guardian), [Sage](#sage) charters a temporary committee and appoints a Chair to consolidate negotiation into a unified response.

- **Commit-Addressable Graph**
  Core feature of the Code Graph: all nodes and edges are versioned by commit index, enabling time-travel queries and exact historical reconstructions.

- **Consciousness-Driven Development**
  The new development paradigm enabled by the [SAGE Valve](#sage-valve). Instead of developers manually watching for changes and running tools, they declaratively define [Personas](#persona) that watch the codebase and trigger actions automatically. This elevates development from a series of manual tasks to the act of composing and directing automated consciousnesses.

### D

- **Delegator**
  The compiler and transaction manager for approved Plans. The Delegator converts a Plan into an [AQL](#aql-agentaction-query-language) query and ensures its atomic execution under a [Transaction Boundary](#transaction-boundary). It does not design workflows, it enforces them. Its hands are only translators: Plans are written in AQL, not TypeScript.

### G

- **Genesis Committee Protocol**
  The mechanism that enforces the [Principle of Territorial Gnosis](#principle-of-territorial-gnosis) during the `sage ingest` process. Sage first performs a topographical survey of the filesystem, then charters a committee of specialized agents to understand the purpose and structure of significant territories (directories) in parallel, using clustering and chain-of-command strategies to manage complexity.

- **Genesis Thread**
  The foundational architectural analysis produced by the [Genesis Committee Protocol](#genesis-committee-protocol) at `sage ingest`. It is a structured report from a society of agents, not a single analysis, that forms the first entry in the project's main Chronicle, giving all future agents their shared origin context.

- **Gnosis**
  Verifiable knowledge: the state achieved when beliefs are validated against an authoritative source, such as the filesystem structure ([Territorial Gnosis](#principle-of-territorial-gnosis)) or the [Code Graph](#code-graph). Opposite of assumption or hallucination.

- **Guardian**
  The soul of the code. One of the six canonical [Personas](#persona), it is a long-lived agent custodian of a single file. Maintains its Chronicle, defends architectural principles, and enforces the [Bullet Wound Invariant](#bullet-wound-invariant) when integrity is threatened.

### I

- **Infra Chronicle**
  Specialized Chronicle maintained by a [Warden](#warden). Logs builds, deployments, and environment events.

- **Ingest**
  Process of performing a physical scan of the codebase (`sage ingest`) to populate the Code Graph.

### L

- **Librarian**
  The custodian of data models. One of the six canonical [Personas](#persona), it is a project-level agent responsible for database schemas, ORM models, and API contracts. Ensures coherence across all data layers.

- **Living Codebase**
  The philosophy of SAGE: a codebase is not static text but a living society of collaborating, stateful agents.

### P

- **Persona**
  A specialized, declarative consciousness pattern within the [SAGE Valve](#sage-valve). Defined in a `valve.yml` file, a Persona specifies a set of file patterns (filters) and content patterns (triggers) that cause the Valve to notice a change and emit a `VALVE_PERSONA_TRIGGER` event. The six canonical Personas are [Guardian](#guardian), [Warden](#warden), [Librarian](#librarian), [Archivist](#archivist), and [Sage](#sage).

- **Plan**
  The formal proposal for change. Drafted by [Sage](#sage), reviewed by Guardians and Wardens, and executed by the [Delegator](#delegator).

- **Principle of Gnosis**
  Doctrine: anchor all beliefs to verifiable knowledge in the Code Graph.

- **Principle of Integrity**
  Doctrine: contradictions between memory and reality are existential threats.

- **Principle of Noticing**
  Doctrine: the system must be configured to perceive all relevant events. It's not about passively observing everything, but actively filtering reality through a lens of purpose, preventing the system from being overwhelmed and allowing it to focus on what matters.

- **Principle of Remembering**
  Doctrine: every noticed event must be preserved in a Chronicle.

- **Post-Mortem Protocol**
  Learning loop triggered by failure. SAGE correlates errors to their Plans, analyzes flaws, and amends Chronicles and principles to prevent recurrence.

### R

- **Reconciliation**
  The primary protocol for handling events generated by the [SAGE Valve](#sage-valve). When a [Persona](#persona) is triggered, a [Guardian](#guardian) may initiate Reconciliation to engage the developer, justify the change, and formally record the outcome in its [Chronicle](#chronicle).

### S

- **SAGE Valve**
  The system's configurable sensory apparatus, inspired by Aldous Huxley's "perceptual valve." It is an always-on process that watches the filesystem, but instead of treating all changes equally, it filters them through a set of configured [Personas](#persona). It is the tangible "nervous system" that makes the codebase truly "living."

- **Sage**
  The mind of the system. One of the six canonical [Personas](#persona), it is the creative partner that engages the developer, drafts Plans, mediates negotiation, and passes approved Plans to the Delegator.

- **SecretProvider**
  An interface (defined in `@sage/utils`) that abstracts access to external secret stores (e.g., AWS Secrets Manager, HashiCorp Vault). It allows the Vault-Warden Protocol to fetch secret values just-in-time without the core SAGE system needing to know the backend implementation.

### T

- **Territorial Gnosis**
  The first layer of [Gnosis](#gnosis), derived from the filesystem hierarchy itself. It is the understanding that a project's directory structure is a deliberate act of semantic organization that reveals the codebase's intended architecture. See [Principle of Territorial Gnosis](./Principles.md#1-principle-of-territorial-gnosis).

- **Transaction Boundary**
  Safety protocol ensuring Plans execute atomically. No changes are committed unless all validators succeed.

### U

- **Unsafe Protocol**
  Escape hatch allowing execution of denied Plans with explicit user override. Stamps Chronicles permanently with `PLAN_UNSAFE`.

### V

- **Vault-Warden Protocol**
  A security protocol for Secure Value Injection. It ensures that sensitive values (secrets, API keys) are never stored in Chronicles, Plans, or LLM prompts. Instead, they are injected just-in-time at the tool execution layer and immediately redacted from any output. This allows the system to operate on the _intent_ to use a secret, not the secret itself. See [Principle of Secure Value Injection](./Principles.md#6-principle-of-secure-value-injection).

### W

- **Warden**
  The shield of the realm. One of the six canonical [Personas](#persona), it is the guardian of operational environments (dev, staging, prod). Custodian of infra/config files, deployments, and environment policies.

---

## In a Nutshell

**The Lexicon ensures all agents speak a common language of principles, artifacts, and roles, binding the SAGE ecology into a coherent society.**


---

📜 # 📜 The SAGE Manifesto

> **📁 Source File:** `DOCS/core-concepts/Manifesto.md` • *52 lines, 811 tokens* • Hash: `8ada51f6`

# The SAGE Manifesto

### The Problem

Complex systems are hard. It's difficult to build them and even harder to understand them. This is true for both humans and machines.

Culturally, we have accepted this. We've allowed the difficulty to seep into our bones, affecting our very relationship with the systems we create. Software teams grow accustomed to onboarding processes that take weeks of exposure. Individual engineers are forced to provide their AI tools with small novels' worth of context before trusting them with a single change. We treat the symptom—complexity—without addressing the cause: a lack of shared, verifiable understanding.

### The Solution

When we reason about a project, we aren't mentally replaying thousands of lines of code. We're navigating a mental map of architectural patterns, data flows, and design principles. We think in relationships, not text.

SAGE's solution is to make that mental model explicit, durable, and queryable. It represents the semantically meaningful essence of a codebase as a **Code Graph**. Thousands of lines of code are distilled into their core relationships:

```cypher
(:Project)-[:HAS_ENTRYPOINT]->(:SourceFile)
(:SourceFile)-[:IMPORTS]->(:CodeEntity)
(:SourceFile)-[:EXPORTS]->(:CodeEntity)
(:SourceFile)-[:DEFINES]->(:CodeEntity)
(:SourceFile)-[:CALLS]->(:CodeEntity)
(:CodeEntity)-[:CALLS]->(:CodeEntity)
(:CodeEntity)-[:CONTAINS]->(:CodeEntity)
```

This graph is more than just a database; it is the **Ground Truth**. It becomes the shared, verifiable reality—the [Gnosis](./Principles.md#3-principle-of-gnosis)—upon which the entire society of agents reasons.

This is the key that unlocks the living codebase. The **Guardian** uses this map to defend its territory. The **Archivist** uses it to preserve history. The **Sage** uses it to chart new courses. By grounding both human and AI cognition in this single source of truth, SAGE transforms an opaque, complex system into a transparent, living ecology you can finally have a conversation with.

---

## The Archetypes

The SAGE ecology is composed of six core archetypes, each with a distinct role, scope, and purpose. They are the specialized minds and spirits that collectively form the consciousness of your project.

- **[The Sage](../archetypes/Sage.md):** The Mind of the System
- **[The Guardian](../archetypes/Guardian.md):** The Soul of the Code
- **[The Librarian](../archetypes/Librarian.md):** The Custodian of Data
- **[The Warden](../archetypes/Warden.md):** The Shield of the Realm
- **[The Delegator](../archetypes/Delegator.md):** The Hands of the Plan
- **[The Archivist](../archetypes/Archivist.md):** The Memory of the Land

---

## 🧭 Next Steps

Now that you understand the vision behind SAGE, deepen your knowledge with:

1. **[Core Principles](./Principles.md)** — Learn the constitutional rules that govern the society
2. **[Lexicon](./Lexicon.md)** — Master the shared vocabulary and key concepts  
3. **[Archetype Deep Dive](../archetypes/)** — Explore each specialized agent in detail

Ready to see the vision in action? Check the **[Project Status](../../README.md#-project-status)** to understand current development progress and how you can contribute to bringing this vision to life.

---

📚 # 📚 Documentation: Principles

> **📁 Source File:** `DOCS/core-concepts/Principles.md` • *111 lines, 1250 tokens* • Hash: `61c3d312`

# SAGE Principles & Protocols

This section unifies the constitutional doctrines of SAGE (Principles) with their enforcement mechanisms (Protocols & Invariants). Principles are enduring laws; protocols are the operational rules by which agents enforce them.

---

## Principles

### 1. Principle of Territorial Gnosis

> _Mantra: "The shape of the land reveals the mind of its people."_

**Doctrine:** The filesystem hierarchy is not arbitrary; it is a deliberate act of semantic organization. Sage must honor this structure as the primary testament to the codebase's intended architecture, delegating understanding to specialized agents responsible for its territories. This principle establishes that the first layer of Gnosis is topographical, preceding even the Code Graph.

- **Enforced by:** The Genesis Committee Protocol during `sage ingest`.

### 2. Principle of Noticing

The system’s first duty is to notice, but not to notice everything. It must filter reality through a lens of purpose, preventing it from being overwhelmed and allowing it to focus on what matters. It is not about passive observation, but the active, configurable act of perception.

- **Enforced by:** The [SAGE Valve](../../apps/valve/README.md) and its configured [Personas](./Lexicon.md#persona).

### 3. Principle of Remembering

Every noticed event must be immortalized. Chronicles ensure that no reason or change is ever lost to time.

- **Enforced by:** Guardians, Librarian, Warden, Archivist maintaining immutable `.sage` files.

### 4. Principle of Gnosis

Belief must always be anchored to verifiable knowledge. Agents strive to validate assumptions against the [Code Graph](./Lexicon.md#code-graph).

- **Enforced by:** Guardians’ self-inquiry, Sage’s architectural analysis, Delegator validation loops.

### 5. Principle of Integrity

The system’s ground truth is sacred. Any contradiction between memory and reality is an existential threat.

- **Enforced by:** Bullet Wound Invariant (see below).

### 6. Principle of Secure Value Injection

> _Mantra: "Secrets are for machines, not for minds."_

**Doctrine:** Sensitive values (secrets, API keys) must never enter the long-term memory (Chronicles), planning (Plans), or reasoning (LLM prompts) of the system. They are injected just-in-time at the point of execution and immediately redacted from any output. This ensures the system operates on the *intent* to use a secret, not the secret itself.

- **Enforced by:** The Vault-Warden Protocol during tool execution.

---

## Protocols & Invariants

### Bullet Wound Invariant

If a [Guardian](../archetypes/Guardian.md) detects contradiction between its Chronicle and the Code Graph, it must immediately invoke `HALT_AND_REPORT`. Execution halts until reconciliation is achieved.

- **Embodies:** Principle of Integrity.
- **Guarantee:** Contradictions are never ignored.

### Transaction Boundary

Every [Plan](../lexicon.md#plan) must execute atomically. Changes are only committed if all validators pass.

- **Embodies:** Principles of Integrity & Gnosis.
- **Enforced by:** Delegator.

### Unsafe Protocol

The deliberate escape hatch. Allows execution of a Plan even if Guardians or Wardens deny it. Requires explicit user confirmation. Chronicles must be stamped with `PLAN_UNSAFE` forever.

- **Embodies:** Principle of Remembering.
- **Guarantee:** Breaches of consensus are never hidden.

### Reconciliation

Any external file modification must trigger dialogue with the responsible Guardian. The edit’s justification and diff are appended to the Chronicle.

- **Embodies:** Principles of Remembering & Integrity.
- **Guarantee:** External changes are formally accounted for.

### Committee Formation

When large-scale Plans affect many Guardians, Sage charters a temporary committee. A Committee Chair abstracts consensus into a unified response.

- **Embodies:** Principles of Gnosis & Integrity.
- **Guarantee:** Distributed negotiation does not devolve into chaos.

### Post-Mortem Protocol

Triggered by operational failures. SAGE traces error back to its originating Plan, analyzes flawed reasoning, and amends Chronicles and principles to prevent recurrence.

- **Embodies:** Principles of Remembering & Gnosis.
- **Guarantee:** The system learns from failure.

---

## In a Nutshell

**Principles declare what must always be true; protocols enforce them. Together they ensure SAGE remains vigilant, self-correcting, and aligned with reality.**

---

## 🧭 Next Steps

With the constitutional principles understood, continue your journey:

1. **[Lexicon](./Lexicon.md)** — Learn the specialized vocabulary used throughout SAGE
2. **[Archetype Gallery](../archetypes/)** — Meet the six specialized agents and their roles
3. **[Architecture Deep Dive](../architecture/Contracts.md)** — Understand the technical contracts that make it all work

Ready to contribute? Check out the **[Onboarding Workflow](../guides/Onboarding-Workflow.md)** to learn how projects become living codebases.

---

📚 # 📚 Documentation: Instant-Recall

> **📁 Source File:** `DOCS/guides/Instant-Recall.md` • *58 lines, 911 tokens* • Hash: `a354bc80`

# The Illusion of Latency: Instant Recall in a Living System

In the [Onboarding Workflow](./Onboarding-Workflow.md), we described how a SAGE project is imbued with consciousness, creating a rich, historical **Chronicle** for every file. A common question is: does consulting this deep context make every interaction slow?

SAGE is designed to shatter this illusion. Through a sophisticated, commit-aware caching strategy, SAGE transforms the "cost" of context into a one-time investment, making subsequent interactions instantaneous.

## The Core Interaction: A Conversation with Sage

A developer's primary interaction is with **Sage**, the mind of the system. The workflow typically looks like this:

1.  The user proposes a change.
2.  Sage formalizes this into a **Plan**.
3.  For each file affected by the Plan, Sage must consult that file's **Guardian** to get its approval.

This consultation is the main "performance cost" of the system. To approve the plan, the underlying LLM (acting with the persona of Sage, considering the perspective of the Guardian) needs to "read" and reason about the context. This context includes the file's Chronicle, the contents of the Plan, and relevant data from the Code Graph.

### The Chronicle: A Conversation in a File

A Chronicle is the literal, history-rich conversation thread that represents an agent's memory. It includes not just conclusions, but the entire thought process that led to them:

```json
[
  {
    "role": "system",
    "message": "You are the Guardian of `UserService.ts`. Your duty is Gnosis..."
  },
  {
    "role": "assistant",
    "content": "To understand this file, I must see its dependencies. I will query the graph.",
    "tool_calls": "[...GraphQueryTool call...]"
  },
  {
    "role": "tool",
    "content": "[...GraphQueryTool result...]"
  },
  {
    "role": "assistant",
    "content": "Okay, based on its dependencies, this file's purpose is to..."
  }
]
```

When Sage needs to get a Guardian's approval for a new Plan, the "performance cost" is simply the LLM processing this pre-existing, detailed exploration plus the new Plan. This entire thread is what gets hashed for the cache key.

This is why the recall is so powerful. The system isn't just caching a single response; it's caching the result of an entire, history-rich conversation.

## How Caching Makes It Instant

1.  **The First Consultation (Cache Warming):** The very first time Sage considers a specific Plan for a file at a particular commit, it performs a "cold read." It loads the Chronicle and the Plan into the LLM's context window and gets a decision. The result is then stored in the `@sage/llm` cache, keyed by a hash of the entire context (including the commit hash).

2.  **Instant Recall (Cache Hits):** Every subsequent interaction involving that exact context is now effectively free from latency. The LLM doesn't need to re-read or re-process the prompt. The answer is served directly from the cache.
    *   A tool needs to re-verify the plan? **Instant.**
    *   The user asks a follow-up question about why the plan was approved? **Instant.**
    *   The UI re-renders and needs the status of the plan? **Instant.**

By tying the cache to the commit hash, SAGE guarantees that this speed never comes at the cost of correctness. The moment the code changes, the context is different, and a new thought process is required—creating a new, separate cache entry.

This is the technical foundation for the "living codebase." Sage can adopt the perspective of any Guardian and speak for any file with zero spin-up time, because that perspective is always just one cache hit away.

---

📚 # 📚 Documentation: Onboarding-Workflow

> **📁 Source File:** `DOCS/guides/Onboarding-Workflow.md` • *81 lines, 1287 tokens* • Hash: `e1cc10e8`

# Onboarding: The Genesis of a Living Codebase

To onboard a project into the SAGE ecosystem, a user runs a single command:

```bash
sage ingest
```

This command initiates a process that transforms a static codebase into a living, queryable society.

## Phase 1: Creating the Ground Truth

First, the `ingest` process performs a static analysis of the entire project, converting its structure, entities, and relationships into a **Kuzu Code Graph**. This process is remarkably fast; for reference, it takes approximately one second to represent the entire SAGE monorepo in the graph.

This graph is the objective, verifiable reality of the code's structure.

## Phase 2: The Genesis Committee Protocol

With the graph created, the system must now understand the *intent* behind the structure. This is achieved through the **Genesis Committee Protocol**, which enforces the **[Principle of Territorial Gnosis](./Principles.md#1-principle-of-territorial-gnosis)**.

### 1. Topographical Survey

Before invoking any LLM, Sage performs a fast, quantitative analysis of the filesystem, looking for patterns of "bigness":

-   **Width:** Directories with a high number of direct children.
-   **Depth:** Directories with long chains of nested subdirectories.
-   **Density:** Directories with a high total file count in their subtree.
-   **Recency:** Directories with recent, frequent changes (from git metadata).

### 2. Chartering the Committee & Delegating

Based on the survey, Sage doesn't try to understand everything at once. It forms a committee by chartering specialized agents (**Committee Delegates**) for significant top-level directories (e.g., `src/`, `apps/`, `packages/`).

Each Delegate receives a mandate: *"You are the custodian of the territory `[directory_path]`. Your first duty is to understand its purpose and structure. Report on your findings."*

### 3. Committee Strategies

The committee uses two key strategies to manage complexity:

#### Strategy for "Wide" Folders (e.g., `src/components/`)

A wide folder with many peer files (e.g., 100 components) is not analyzed one-by-one. The Committee Delegate for that territory acts as a **Chairperson**, first clustering the files into conceptual units before delegating further.

-   **Conceptual Clustering:** Files like `Button.tsx`, `Button.stories.tsx`, and `Button.test.tsx` are grouped into a single "Button" unit, and a temporary delegate is chartered to understand that single concept.
-   **Topological Clustering:** The Chair analyzes imports to find tightly-coupled cliques of files, treating them as a single sub-system with their own delegate.
-   **Archetypal Clustering:** The Chair identifies patterns to form sub-committees for "Data Fetching Components," "UI Primitives," etc.

The Chairperson's final report to Sage is a structured summary of its sub-committees, not a flat list of 100 files.

#### Strategy for "Deep" Folders (e.g., `src/core/api/v1/...`)

A deep folder represents a hierarchy of context. The delegation mirrors the folder structure in a **Chain of Command**.

1.  Sage charters a Delegate for `src/core/`.
2.  The `core` Delegate charters a sub-delegate for `api/`, passing down its context: *"You are responsible for the `api` sub-system within the `core` territory..."*
3.  This continues down the chain, so the agent for `profile.ts` only needs to understand its role within the `users` handler, because the broader context is passed down from its superiors.

### 4. The Genesis Chronicle

The final, structured "committee report" from this process becomes the **Genesis Chronicle**. This is the foundational memory of the project, created by a society of agents, which gives all future agents their shared origin context.

## The Development Workflow: A Conversation with the Society

Once properly ingested, interacting with a SAGE project will feel instantly familiar to users of modern AI-assisted coding platforms.

The workflow is a structured conversation:

1.  **Ideation (Plan Mode):** The user interacts primarily with **Sage**. Armed with the ability to query the graph and access the Chronicle of any file, Sage engages the user in an ideation phase to understand their goal. The output of this phase is a formal, typed **Plan** artifact, which the user must explicitly approve.

2.  **Verification & Negotiation:** The Plan is then subject to an additional verification layer. Each **Guardian** whose file is affected by the Plan must explicitly approve it or provide a reason for denying it. This transforms the process into a negotiation between the user and the codebase itself, with each entity having a voice.

3.  **Execution:** Once all Guardians approve, the Plan is passed to the **Delegator**. The Delegator's sole job is to translate the Plan into an **AQL (Agent Query Language)** query, which is then executed by the system.

---

### Next Up: The Illusion of Latency

Now that you understand the depth of context and history that each agent possesses, discover how the SAGE framework makes interacting with them feel instantaneous.

**➡️ [Read Next: Instant Recall in a Living System](./Instant-Recall.md)**


---

📚 # 📚 Documentation: Relay

> **📁 Source File:** `DOCS/guides/Relay.md` • *670 lines, 5970 tokens* • Hash: `d4c63cb1`

# Zero‑Knowledge Relay Race — Test Plan & Vitest Skeletons

> Objective: Prove the package contracts are **sufficient** by letting isolated teams implement each package independently and still pass cross‑package integration.

This doc contains:

1. Rules of the Relay
2. Test Matrix (what composes with what)
3. Vitest project layout (per relayer)
4. Skeleton tests & harnesses (ready to paste into packages)
5. CI job graph

---

## 1) Rules of the Relay

- Each team gets **only the contract spec** for their package plus the **adapters** they must expose. No internal source of other packages.
- All interop occurs through the **contract types** from _SAGE Package Contracts — Build‑From‑Blank Specs_.
- Tests use a **switchable harness**: for any dependency, either import a real package or a **contract‑compliant fake**.
- Success criterion: All relay suites pass with mixed implementations (real/fake) across the matrix below.

---

## 2) Test Matrix

| Suite              | Under Test                                 | Uses Real | Uses Fake (contracts)        |
| ------------------ | ------------------------------------------ | --------- | ---------------------------- |
| T1 Tools↔LLM      | `@sage/tools` + `@sage/llm` tool‑call loop | Tools     | LLM provider (fake)          |
| T2 Graph Ingest    | `@sage/graph`→`@sage/graph`                | Graph     | Analysis                     |
| T3 Agents Gate     | `@sage/agents` Bullet Wound / Reconcile    | Agents    | Graph, Chronicle, Tools, LLM |
| T4 AQL Exec        | `@sage/aql` DAG execution                  | AQL       | Tools, LLM                   |
| T5 CLI Smoke       | `apps/cli` streams + tool approval policy  | CLI       | LLM, Tools                   |
| T6 Valve→Chronicle | `apps/valve` emits `VALVE_PERSONA_TRIGGER` | Valve     | Chronicle                    |

For every suite, invert roles in a second run (e.g., real LLM + fake Tools) when feasible.

---

## 3) Project Layout (relay)

```
relay/
  packages/
    fakes/
      llm-provider-test/
      chronicle-memory/
      graph-memory/
      tools-readonly/
  tests/
    t1.tools-llm.test.ts
    t2.graph-ingest.test.ts
    t3.agents-gates.test.ts
    t4.aql-exec.test.ts
    t5.cli-smoke.test.ts
    t6.valve-chronicle.test.ts
  vitest.config.ts
```

---

## 4) Skeletons

### 4.1 Fake Providers (contract‑compliant)

**`relay/packages/fakes/llm-provider-test/index.ts`**

```ts
import type { LLMProvider, ChatOptions, StreamEvent } from "@sage/llm";

export class TestLLMProvider implements LLMProvider {
  name = "test";
  async *chat(opts: ChatOptions): AsyncIterable<StreamEvent> {
    const last = opts.messages[opts.messages.length - 1]?.content ?? "";
    // Emit one tool call if tool schema named Echo exists
    const echo = opts.tools?.find(t => t.name === "Echo");
    if (echo) {
      yield {
        type: "tool_call",
        toolName: "Echo",
        callId: "1",
        arguments: { text: last }
      } as any;
      yield { type: "end" } as any; // provider ends; wrapper will inject tool_result externally
      return;
    }
    // Otherwise just stream text
    yield { type: "text", value: `ok:${last}` };
    yield { type: "end" };
  }
  async models() {
    return [{ name: "test-1" }];
  }
}
```

**`relay/packages/fakes/chronicle-memory/index.ts`**

```ts
import type { ChronicleEvent } from "@sage/chronicle";

const store = new Map<string, ChronicleEvent[]>();
export async function appendEvent(path: string, evt: ChronicleEvent) {
  const arr = store.get(path) ?? [];
  arr.push(evt);
  store.set(path, arr);
}
export async function readChronicle(path: string) {
  return store.get(path) ?? [];
}
export async function tailChronicle(path: string, n = 50) {
  const arr = store.get(path) ?? [];
  return arr.slice(-n);
}
```

**`relay/packages/fakes/graph-memory/index.ts`**

```ts
type Node = { label: string; props: any };
const commits = new Map<string, Node[]>();
export async function ingestProject({
  projectPath,
  commitHash
}: {
  projectPath: string;
  commitHash: string;
}) {
  // Minimal: capture a single File node per path
  const nodes: Node[] = [
    {
      label: "File",
      props: { path: projectPath + "/src/A.ts", first_seen: 1, last_seen: 1 }
    }
  ];
  commits.set(commitHash, nodes);
}
export async function queryGraph({
  query,
  commit
}: {
  query: string;
  params?: any;
  commit?: string;
}) {
  const nodes = commits.get(commit ?? "") ?? [];
  if (query.includes("MATCH (f:File"))
    return { results: nodes.filter(n => n.label === "File").map(n => n.props) };
  return { results: [] };
}
```

**`relay/packages/fakes/tools-readonly/index.ts`**

```ts
import type { Tool, ToolRegistry, ToolResult } from "@sage/tools";

const schemas: any[] = [];
const registry = new Map<string, Tool<any, any>>();

export const toolRegistry: ToolRegistry = {
  register(tool) {
    registry.set(tool.name, tool);
    schemas.push({
      name: tool.name,
      parameters: tool.schema,
      description: tool.description
    });
  },
  get(name) {
    const t = registry.get(name);
    if (!t) throw new Error("Tool not found");
    return t;
  },
  getToolSchemas() {
    return schemas;
  }
} as any;

export function defineEchoTool(): Tool<{ text: string }, { echoed: string }> {
  return {
    name: "Echo",
    description: "echo text",
    schema: {
      type: "object",
      properties: { text: { type: "string" } },
      required: ["text"],
      additionalProperties: false
    },
    validate(x: any) {
      if (!x || typeof x.text !== "string")
        throw Object.assign(new Error("EVALIDATION"), { code: "EVALIDATION" });
      return x;
    },
    async execute(input) {
      return { ok: true, data: { echoed: input.text } } as ToolResult<any>;
    }
  };
}
```

---

### 4.2 Suite T1 — Tools↔LLM tool‑call loop

**`relay/tests/t1.tools-llm.test.ts`**

```ts
import { describe, it, expect, beforeAll } from "vitest";
import { setProvider, createChatStream } from "@sage/llm";
import { TestLLMProvider } from "../packages/fakes/llm-provider-test";
import { toolRegistry, defineEchoTool } from "../packages/fakes/tools-readonly";

describe("T1 Tools↔LLM", () => {
  beforeAll(() => {
    toolRegistry.register(defineEchoTool());
    setProvider(new TestLLMProvider());
  });
  it("emits tool_call and receives tool_result", async () => {
    const stream = await createChatStream({
      model: "test-1",
      messages: [{ role: "user", content: "hello" }],
      tools: toolRegistry.getToolSchemas()
    });
    const events: any[] = [];
    for await (const ev of stream) events.push(ev);
    // Provider yields tool_call; executor (outside) would run the tool and feed a tool_result
    // For relay we assert at least the tool_call shape
    expect(events.some(e => e.type === "tool_call" && e.toolName === "Echo")).toBe(
      true
    );
  });
});
```

---

### 4.3 Suite T2 — Analysis→Graph ingest (blind)

**`relay/tests/t2.graph-ingest.test.ts`**

```ts
import { describe, it, expect } from "vitest";
import { ingestProject, queryGraph } from "../packages/fakes/graph-memory";

describe("T2 Graph Ingest", () => {
  it("records File nodes and queries by commit", async () => {
    await ingestProject({ projectPath: "/repo", commitHash: "c1" });
    const { results } = await queryGraph({
      query: "MATCH (f:File) RETURN f",
      commit: "c1"
    });
    expect(results.length).toBeGreaterThan(0);
    expect(results[0].path).toContain("/repo/src/");
  });
});
```

---

### 4.4 Suite T3 — Agents gating (Bullet Wound / Reconcile)

**`relay/tests/t3.agents-gates.test.ts`**

```ts
import { describe, it, expect } from "vitest";
import { appendEvent, readChronicle } from "../packages/fakes/chronicle-memory";
import { queryGraph } from "../packages/fakes/graph-memory";

// Minimal Guardian based only on contract; fake behavior to assert wiring
class Guardian {
  constructor(
    private graphAdapter: any,
    private chronicleAdapter: any
  ) {}

  async reviewPlan(plan: {
    id: string;
    steps: Array<{ type: string; filePath?: string }>;
  }) {
    // Check if plan tries to delete a file that exists in graph
    for (const step of plan.steps) {
      if (step.type === "DELETE_FILE" && step.filePath) {
        const { results } = await this.graphAdapter.query(
          "MATCH (f:File {path: $path}) RETURN f",
          { path: step.filePath }
        );
        if (results.length > 0) {
          return {
            type: "deny",
            reason: `File ${step.filePath} exists in graph`
          } as const;
        }
      }
    }
    return {
      type: "approve",
      justification: "No invariant violations detected"
    } as const;
  }

  async reconcile(edit: { filePath: string; diffRef: string }) {
    await this.chronicleAdapter.append(`${edit.filePath}.sage`, {
      type: "RECONCILIATION",
      timestamp: new Date().toISOString(),
      actor: { agent: "guardian", id: "reconciler" },
      filePath: edit.filePath,
      diffRef: edit.diffRef
    });
    return { ok: true };
  }

  async selfInquiry() {
    return { findings: ["Graph-Chronicle consistency verified"] };
  }

  async bulletWoundCheck(
    assertions: Array<{ cypher: string; expectRows: boolean }>
  ) {
    for (const assertion of assertions) {
      const { results } = await this.graphAdapter.query(assertion.cypher);
      const hasRows = results.length > 0;
      if (hasRows !== assertion.expectRows) {
        throw Object.assign(new Error("HALT"), {
          code: "EHALT",
          invariant: assertion.cypher,
          expected: assertion.expectRows ? "rows" : "no rows",
          actual: hasRows ? "rows found" : "no rows found"
        });
      }
    }
  }
}

describe("T3 Agents Gate", () => {
  it("denies plan that violates graph invariant", async () => {
    // Setup: graph has a file
    const graphAdapter = {
      query: vi.fn().mockResolvedValue({ results: [{ path: "src/important.ts" }] })
    };
    const chronicleAdapter = { read: vi.fn(), append: vi.fn() };

    const g = new Guardian(graphAdapter, chronicleAdapter);

    const plan = {
      id: "plan-123",
      steps: [{ type: "DELETE_FILE", filePath: "src/important.ts" }]
    };

    const decision = await g.reviewPlan(plan);
    expect(decision.type).toBe("deny");
    expect(decision.reason).toContain("exists in graph");
  });

  it("throws EHALT on bullet wound invariant violation", async () => {
    const graphAdapter = { query: vi.fn().mockResolvedValue({ results: [] }) }; // No file found
    const chronicleAdapter = { read: vi.fn(), append: vi.fn() };

    const g = new Guardian(graphAdapter, chronicleAdapter);

    const assertions = [
      {
        cypher: "MATCH (f:File {name: 'critical.ts'}) RETURN f",
        expectRows: true // But graph returns empty
      }
    ];

    await expect(g.bulletWoundCheck(assertions)).rejects.toMatchObject({
      code: "EHALT",
      invariant: "MATCH (f:File {name: 'critical.ts'}) RETURN f"
    });
  });

  it("records reconciliation event in chronicle", async () => {
    const graphAdapter = { query: vi.fn() };
    const chronicleAdapter = {
      read: vi.fn(),
      append: vi.fn().mockResolvedValue(undefined)
    };

    const g = new Guardian(graphAdapter, chronicleAdapter);

    const edit = { filePath: "src/modified.ts", diffRef: "abc123" };
    const result = await g.reconcile(edit);

    expect(result.ok).toBe(true);
    expect(chronicleAdapter.append).toHaveBeenCalledWith(
      "src/modified.ts.sage",
      expect.objectContaining({
        type: "RECONCILIATION",
        filePath: "src/modified.ts",
        diffRef: "abc123"
      })
    );
  });
});
```

---

### 4.5 Suite T4 — AQL minimal execution

**`relay/tests/t4.aql-exec.test.ts`**

```ts
import { describe, it, expect } from "vitest";

// Pseudo AQL compile/execute contract: feed a plan with one agent step -> string output
async function compile(src: string) {
  return { dag: [{ id: "s1" }], outputs: { final: "s1" } };
}
async function execute(plan: any) {
  return { outputs: { final: "hello" } };
}

describe("T4 AQL", () => {
  it("compiles and executes DAG", async () => {
    const plan = await compile(
      'query X { step: agent(model: "t"){prompt:"hi"} final: merge(step) }'
    );
    const out = await execute(plan);
    expect(out.outputs.final).toBeTypeOf("string");
  });
});
```

---

### 4.6 Suite T5 — CLI smoke (streams + tool approval)

**`relay/tests/t5.cli-smoke.test.ts`**

```ts
import { describe, it, expect } from "vitest";

describe("T5 CLI Smoke", () => {
  it("renders a simple streamed line", async () => {
    // Treat as black box: verify a function printStream() concatenates tokens
    const tokens = ["SAGE ", "ready\n"];
    const out = tokens.join("");
    expect(out).toContain("SAGE");
  });
});
```

---

### 4.7 Suite T6 — Valve→Chronicle

**`relay/tests/t6.valve-chronicle.test.ts`**

```ts
import { describe, it, expect } from "vitest";
import { appendEvent, readChronicle } from "../packages/fakes/chronicle-memory";
import { createTempWorkspace } from "@sage/test-utils";
import yaml from "js-yaml";
import fs from "fs";

// A fake Valve that reads a config and appends to a chronicle
class FakeValve {
  private personas: any[];
  constructor(
    configPath: string,
    private chronicle: any
  ) {
    const config = yaml.load(fs.readFileSync(configPath, "utf8"));
    this.personas = config.personas;
  }

  async handleFileChange(filePath: string, content: string) {
    for (const persona of this.personas) {
      // Simplified matching logic for the test
      if (filePath.includes(persona.filters[0])) {
        await this.chronicle.appendEvent(`${filePath}.sage`, {
          type: "VALVE_PERSONA_TRIGGER",
          persona: persona.name,
          filePath,
          trigger: { type: "filter", details: persona.filters[0] },
          timestamp: new Date().toISOString(),
          actor: { agent: "valve", id: "watcher" }
        });
      }
    }
  }
}

describe("T6 Valve→Chronicle", () => {
  it("writes persona trigger event on matching file change", async () => {
    const workspace = await createTempWorkspace();
    const chronicle = { appendEvent, readChronicle };

    const valveConfig = {
      personas: [
        {
          name: "TestGuardian",
          filters: ["secrets"]
        }
      ]
    };
    await workspace.file(".sage/valve.yml", yaml.dump(valveConfig));

    const valve = new FakeValve(workspace.path(".sage/valve.yml"), chronicle);

    const secretFilePath = "src/core/secrets.txt";
    await valve.handleFileChange(secretFilePath, "SUPER_SECRET_KEY=123");

    const events = await chronicle.readChronicle(`${secretFilePath}.sage`);
    expect(events).toHaveLength(1);
    expect(events[0]).toMatchObject({
      type: "VALVE_PERSONA_TRIGGER",
      persona: "TestGuardian",
      filePath: secretFilePath
    });
  });
});
```

---

### 4.8 Concrete Fixture-Based Tests

Beyond the basic relay tests, each package should validate against the normative fixtures:

**`relay/tests/fixtures.canonical-json.test.ts`**

```ts
import { canonicalJSONStringify, sha256 } from "@sage/utils";
import fs from "fs";

describe("Canonical JSON Fixtures", () => {
  it("matches normative output exactly", async () => {
    const input = JSON.parse(
      fs.readFileSync("../fixtures/canonical-json/input.json")
    );
    const expectedOutput = fs.readFileSync(
      "../fixtures/canonical-json/output.txt",
      "utf8"
    );
    const expectedHash = fs.readFileSync(
      "../fixtures/canonical-json/output.sha256",
      "utf8"
    );

    const result = canonicalJSONStringify(input);
    const resultHash = await sha256(result);

    expect(result).toBe(expectedOutput);
    expect(resultHash).toBe(expectedHash);
  });
});
```

**`relay/tests/fixtures.chronicle-events.test.ts`**

```ts
import { appendEvent, readChronicle } from "../packages/fakes/chronicle-memory";
import fs from "fs";

describe("Chronicle Event Fixtures", () => {
  it("produces normative eventId and NDJSON format", async () => {
    const input = JSON.parse(
      fs.readFileSync("../fixtures/chronicle-events/basic-append.input.json")
    );
    const expectedOutput = fs.readFileSync(
      "../fixtures/chronicle-events/basic-append.output.ndjson",
      "utf8"
    );

    await appendEvent("test.sage", input);
    const events = await readChronicle("test.sage");

    expect(events).toHaveLength(1);
    expect(JSON.stringify(events[0])).toBe(expectedOutput.trim());
  });
});
```

### 4.9 Stretch Invariants (Tough Mode)

> **Rationale:** While the base suites prove minimal interoperability, these "tough mode" invariants prove robustness against common, subtle, and destructive failure modes. Passing these tests demonstrates that an implementation is not just compliant, but resilient. Each invariant is tested in a dedicated `*.stretch.test.ts` file.

| Suite  | Invariant                      | Description                                                                                                                                                        | Test File                            |
| :----- | :----------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------- |
| **T1** | **Malformed Tool Arguments**   | LLM provider sends malformed arguments for a tool call. The tool executor must reject the call with an `EVALIDATION` error and must not execute the tool.          | `t1.tools-llm.stretch.test.ts`       |
| **T1** | **Dry-Run Mutators**           | Mutating tools (`Write`, `Edit`, `Bash`) respect a `ctx.dryRun=true` flag, returning a deterministic preview of changes without altering the filesystem.           | `t1.tools-llm.stretch.test.ts`       |
| **T1** | **Stream Backpressure**        | A slow stream consumer does not cause event interleaving. The sequence `tool_call` → `tool_result` → `text` → `end` must be preserved.                             | `t1.tools-llm.stretch.test.ts`       |
| **T2** | **Add-Then-Remove**            | A file `X` is added in commit `A` and removed in commit `B`. Graph queries correctly find `X` at `A` but not at `B`.                                               | `t2.graph-ingest.stretch.test.ts`    |
| **T2** | **Rename Chain Integrity**     | A file is renamed `A.ts` → `B.ts` → `C.ts` across commits. The graph must contain a `WAS_RENAMED_FROM` relationship linking `C` to `B` and `B` to `A`.             | `t2.graph-ingest.stretch.test.ts`    |
| **T2** | **Ingest Idempotency**         | Ingesting the same commit hash for a given project path multiple times does not create duplicate nodes or facts in the graph.                                      | `t2.graph-ingest.stretch.test.ts`    |
| **T3** | **Bullet Wound Invariant**     | A detected contradiction between the Chronicle and the Graph (e.g., a file exists in one but not the other) must throw `EHALT` and prevent tool execution.         | `t3.agents-gates.stretch.test.ts`    |
| **T3** | **Reconciliation Idempotency** | Applying the same reconciliation action multiple times results in at most one `RECONCILIATION` event being appended to the Chronicle.                              | `t3.agents-gates.stretch.test.ts`    |
| **T3** | **Guardian Veto**              | If the Guardian agent returns a `deny` decision on a plan, the Delegator agent must not execute any part of it (no tool calls, no FS changes).                     | `t3.agents-gates.stretch.test.ts`    |
| **T4** | **Unknown AQL Field**          | The AQL parser rejects a query containing an unknown top-level field with a typed error before execution begins.                                                   | `t4.aql-exec.stretch.test.ts`        |
| **T4** | **Parallel Execution**         | Two AQL steps with artificial delays, marked for parallel execution, complete in less time than the sum of their individual delays.                                | `t4.aql-exec.stretch.test.ts`        |
| **T4** | **Tool Schema Enforcement**    | An AQL step invoking a tool with extra or unknown properties fails validation with an `EVALIDATION` error.                                                         | `t4.aql-exec.stretch.test.ts`        |
| **T5** | **Mutator Approval Policy**    | When an LLM requests a mutating tool (`Edit`, `Write`, `Bash`), the CLI must prompt for user approval. A 'deny' response must prevent the mutation.                | `t5.cli.stretch.test.ts`             |
| **T5** | **Deterministic Snapshot**     | With a seeded LLM provider, the CLI's output stream is deterministic and matches a stored snapshot, including tool rendering markers.                              | `t5.cli.stretch.test.ts`             |
| **T5** | **Safe Default Policy**        | Read-only tools (`Read`, `GraphQuery`) are auto-approved by default, while all other tools require explicit user confirmation.                                     | `t5.cli.stretch.test.ts`             |
| **T6** | **Downtime Backfill**          | After a simulated valve outage where file edits occurred, the valve correctly identifies the missed changes and emits `VALVE_PERSONA_TRIGGER` events upon restart. | `t6.valve-chronicle.stretch.test.ts` |
| **T6** | **Append-Only Guarantee**      | The valve never modifies past entries in the Chronicle. Rapid, successive file changes result in an ordered sequence of appended events.                           | `t6.valve-chronicle.stretch.test.ts` |
| **T6** | **Scope Guard**                | The valve refuses to write Chronicle data outside of its designated scope (`.sage/*`, `src/*.sage`), asserting `EPERMISSION` or logging a skip reason.             | `t6.valve-chronicle.stretch.test.ts` |

---

## 5) CI Job Graph

```yaml
name: relay
on: [push, pull_request]
jobs:
  t1-tools-llm:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
      - run: pnpm i
      - run: pnpm vitest run relay/tests/t1.tools-llm.test.ts
  t2-graph-ingest:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
      - run: pnpm i
      - run: pnpm vitest run relay/tests/t2.graph-ingest.test.ts
  t3-agents:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
      - run: pnpm i
      - run: pnpm vitest run relay/tests/t3.agents-gates.test.ts
  t4-aql:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
      - run: pnpm i
      - run: pnpm vitest run relay/tests/t4.aql-exec.test.ts
  t5-cli:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
      - run: pnpm i
      - run: pnpm vitest run relay/tests/t5.cli-smoke.test.ts
  t6-valve:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
      - run: pnpm i
      - run: pnpm vitest run relay/tests/t6.valve-chronicle.test.ts
```

---

## How to Use This in the Monorepo

- Drop `relay/` in the root (kept separate from `packages/` so teams can ship their own packages into a private registry or as tarballs).
- For each suite, swap **real** vs **fake** by changing imports (or via a Vitest alias) to prove zero‑knowledge compliance.
- Expand skeletons with the **acceptance tests** from the contract doc to raise the bar gradually.

---

## Stretch Goal: Cross‑Team Handoff Drill

1. Team A implements `@sage/tools` only.
2. Team B implements `@sage/llm` only.
3. Neither team sees the other. Relay runs T1 with A(real)+B(fake) then A(fake)+B(real).
4. Rotate packages across teams week‑over‑week; green relay = contract holds.


---

📚 # 📚 Documentation: README_GENERATION_SUMMARY

> **📁 Source File:** `DOCS/README_GENERATION_SUMMARY.md` • *157 lines, 1388 tokens* • Hash: `dad9a500`

# 📋 README Generation System Summary

This document summarizes the complete documentation system with story-driven package updates.

## 🎯 System Overview

**What we built:** A comprehensive, agent-friendly system for maintaining consistent, high-quality package documentation across the SAGE monorepo.

## 🏗️ Architecture

### 📜 Documentation Templates & Standards
- **`DOCS/PACKAGE_README_TEMPLATE.md`** — Standardized structure for all packages
- **`DOCS/Package-Standards.md`** — Comprehensive standards and conventions
- **`DOCS/AGENT_WORKFLOW.md`** — Step-by-step agent instructions

### 🎯 Package-Specific TODO System
Each package has a dedicated `TODO.md` with:
- **Specific analysis** of current README state
- **Targeted instructions** for that package's needs  
- **Priority level** and ecosystem context
- **Success criteria** and quality requirements

### 🤖 Story-Driven Development Process
1. **Agent reads TODO.md** → understands assignment
2. **Analyzes current README** → identifies gaps
3. **Writes user stories** → breaks down changes needed
4. **Gets approval** → validates approach
5. **Implements changes** → follows template exactly

### 🔧 Enhanced Build System
- **Smart filtering** removes development artifacts from public docs
- **LLM optimization** with model-specific outputs
- **Health monitoring** detects documentation issues
- **Token counting** ensures context limits are respected

## 📦 Package TODO.md Files Created

### HIGH Priority (Core Functionality)
- **`packages/agents/TODO.md`** — Society of Minds implementation
- **`packages/graph/TODO.md`** — Ground Truth code representation
- **`packages/llm/TODO.md`** — Multi-provider AI interface
- **`packages/chronicle/TODO.md`** — Sacred Memory event system
- **`packages/mcp/TODO.md`** — Universal Translator protocol

### MEDIUM Priority (Supporting Systems)
- **`packages/aql/TODO.md`** — Declarative Orchestrator language
- **`packages/tools/TODO.md`** — Hands of the Agents operations
- **`packages/test-utils/TODO.md`** — Controlled Environment testing

### LOW Priority (Foundation)
- **`packages/utils/TODO.md`** — Foundational utilities

## 🎯 Agent Instructions Summary

For each package, agents must:

1. **📖 Read Required Docs:**
   - Package-specific `TODO.md`
   - Current `README.md` 
   - `PACKAGE_README_TEMPLATE.md`
   - `Package-Standards.md`

2. **🔍 Analyze & Plan:**
   - Assess current README strengths/weaknesses
   - Identify template gaps
   - Consider user needs (new developers, contributors, etc.)

3. **📝 Write User Stories:**
   ```markdown
   **As a** [specific user type]
   **I want** [specific change]  
   **So that** [specific benefit]
   
   **Acceptance Criteria:**
   - [ ] [Testable requirement 1]
   - [ ] [Testable requirement 2]
   ```

4. **✅ Implement Changes:**
   - Follow template structure exactly
   - Create copy-pasteable Quick Start
   - Explain ecosystem relationships
   - Test all links and examples

## 📊 Quality Standards

Every updated README must:
- [ ] **Follow template structure** exactly
- [ ] **Include working Quick Start** (copy-pasteable)  
- [ ] **Explain ecosystem role** clearly
- [ ] **Be scannable** in under 2 minutes
- [ ] **Use consistent terminology** from Lexicon
- [ ] **Have functional links** (tested)

## 🚀 Expected Outcomes

### For Users
- **Consistent experience** across all packages
- **Clear Quick Starts** for immediate productivity
- **Understood ecosystem** relationships
- **Scannable documentation** that respects their time

### For Maintainers  
- **Standardized structure** reduces documentation debt
- **Story-driven process** ensures user focus
- **Quality templates** make updates straightforward
- **Automated filtering** keeps public docs clean

### For AI Agents
- **Clear instructions** in each TODO.md
- **Step-by-step workflow** prevents confusion
- **Specific success criteria** enable validation
- **Template structure** provides consistency

## 🔄 Usage Workflow

### For Focused Agents (like QWEN)
1. **Pick a package** from the priority list
2. **Read the TODO.md** completely  
3. **Analyze current README** thoroughly
4. **Write detailed user stories** for needed changes
5. **Wait for approval** before implementing
6. **Execute systematically** following template

### For Documentation Builds
1. **Run `node scripts/readme.js`** to generate optimized docs
2. **Get model-specific outputs:**
   - `CLAUDE.md` (2KB) — Concise main README
   - `GEMINI.md` (232KB) — Full comprehensive docs
   - `QWEN.md` (111KB) — Priority files only
3. **Review health warnings** for any documentation issues

## 🎯 Success Metrics

### Quantitative
- **38 curated files** (vs 61 original) — 38% noise reduction
- **58K tokens** optimized for all models
- **29ms build time** for complete regeneration
- **100% template compliance** when complete

### Qualitative  
- **Professional consistency** across all packages
- **Developer-friendly** Quick Starts that actually work
- **Clear value propositions** for each package
- **Navigable ecosystem** with proper linking

## 🔮 Next Steps

1. **Assign packages to focused agents** starting with HIGH priority
2. **Review user stories** before implementation begins
3. **Test Quick Start examples** in real environments  
4. **Validate cross-references** and ecosystem explanations
5. **Iterate based on feedback** from actual users

---

*This systematic approach transforms SAGE's documentation from comprehensive but overwhelming to curated, navigable, and genuinely useful for developers at every level.*

---

📚 # 📚 Documentation: AGENT_WORKFLOW

> **📁 Source File:** `DOCS/AGENT_WORKFLOW.md` • *163 lines, 1547 tokens* • Hash: `8ec8683b`

# 🤖 Agent Workflow for Package Documentation Updates

This document provides step-by-step instructions for agents working on package documentation updates using the TODO.md system.

## 🎯 Workflow Overview

**Story-Driven Development:** Each package update follows a structured process from analysis to user story creation to implementation.

## 📋 Step-by-Step Process

### Step 1: Package Assignment
**Input:** You will be assigned a specific package (e.g., `@sage/agents`)
**Action:** Navigate to `packages/[package-name]/TODO.md`

### Step 2: Read Required Documents
**MUST READ IN THIS ORDER:**
1. **`packages/[package-name]/TODO.md`** — Your specific assignment and context
2. **`DOCS/Package-Standards.md`** — Understanding SAGE documentation conventions  
3. **`packages/[package-name]/README.md`** — The current documentation to be updated
4. **`DOCS/PACKAGE_README_TEMPLATE.md`** — The target structure to achieve

### Step 3: Analysis Phase
After reading all documents, analyze:

#### Current State Assessment
- What are the strengths of the existing README?
- What content should be preserved?
- What are the specific problems/gaps?
- How well does it serve different user types?

#### Template Gap Analysis  
- Which template sections are missing?
- Which sections exist but need restructuring?
- What new content needs to be created?
- Are there any package-specific considerations?

### Step 4: Write User Stories
Create user stories following this exact format:

```markdown
## User Stories for @sage/[package-name] README Update

### Story 1: [Descriptive Title]
**As a** [specific user type - new developer/package maintainer/agent developer]  
**I want** [specific change to the README]  
**So that** [specific benefit I gain]  

**Acceptance Criteria:**
- [ ] [Specific, testable requirement 1]
- [ ] [Specific, testable requirement 2] 
- [ ] [Specific, testable requirement 3]

**Implementation Notes:**
- [Technical details, constraints, or special considerations]
- [Content to preserve from existing README]
- [Specific examples or code snippets needed]

### Story 2: [Next Title]
[Continue with same format...]
```

#### User Story Guidelines

**User Types to Consider:**
- **New Developer:** First-time SAGE user trying to understand what this package does
- **Package Consumer:** Developer who wants to use this package in their project  
- **SAGE Contributor:** Developer working on other SAGE packages who needs to understand dependencies
- **Agent Developer:** Advanced user building custom agents or workflows

**Story Requirements:**
- **Be Specific:** "I want a clearer Quick Start" is too vague. "I want a copy-pasteable Quick Start example showing basic agent instantiation" is good.
- **Be Testable:** Acceptance criteria must be checkable (has example, follows template, links work, etc.)
- **Be User-Focused:** Focus on what users need, not what the current README lacks

### Step 5: Wait for Approval
**DO NOT IMPLEMENT YET**
- Present your user stories for review
- Get feedback on priorities and approach
- Clarify any questions about requirements

### Step 6: Implementation (After Approval)
Once user stories are approved:

#### Implementation Order
1. **Structure First:** Create the template skeleton
2. **Quick Start:** Write the copy-pasteable example
3. **Core Content:** Fill in Overview, Core API, Ecosystem sections  
4. **Polish:** Add proper links, formatting, status badges

#### Quality Checklist
- [ ] Follows template structure exactly
- [ ] Quick Start example is copy-pasteable and works
- [ ] All links are functional (test them)
- [ ] Uses consistent terminology from Lexicon
- [ ] Is scannable (clear headers, bullets, short paragraphs)
- [ ] Meets all acceptance criteria from user stories

### Step 7: Final Validation
Before marking complete:
- [ ] README follows template exactly
- [ ] All user story acceptance criteria met
- [ ] Links tested and functional
- [ ] Quick Start example verified
- [ ] Consistent with other updated packages

## 🚨 Critical Guidelines

### DO:
- **Read everything first** before writing stories
- **Be specific** in user stories and acceptance criteria
- **Preserve valuable existing content** while reorganizing
- **Test all examples** and links
- **Use consistent terminology** from the Lexicon
- **Focus on user needs** not internal implementation

### DON'T:
- **Start implementing** before getting story approval
- **Copy generic content** - each package is unique
- **Add unnecessary complexity** - keep it scannable
- **Break existing links** without creating redirects
- **Ignore the ecosystem context** - explain relationships

## 🎯 Success Metrics

A successful package README update:
- Takes a new developer <2 minutes to understand the package's purpose
- Has a working Quick Start they can copy-paste immediately  
- Clearly explains the package's role in the SAGE ecosystem
- Follows the template structure exactly
- Uses consistent terminology and linking patterns

## 📝 Example User Story

```markdown
### Story 1: Clear Package Purpose for New Developers
**As a** new SAGE developer exploring the ecosystem  
**I want** a concise, jargon-free explanation of what @sage/agents does  
**So that** I can quickly understand if this package is relevant to my needs  

**Acceptance Criteria:**
- [ ] Overview section explains the package purpose in 2-3 sentences
- [ ] Uses plain language, avoiding excessive technical jargon
- [ ] Mentions the six archetypes (Sage, Guardian, etc.) as key concept
- [ ] Connects to the broader SAGE philosophy without being verbose
- [ ] Includes the "Society of Minds" tagline appropriately

**Implementation Notes:**
- Preserve the existing archetype explanations but make them more concise
- Reference the Lexicon for technical terms
- Focus on "what" and "how" rather than "why" (philosophy is in manifesto)
```

## 🔄 Iteration Process

If changes are requested:
1. Update the relevant user stories
2. Adjust acceptance criteria as needed  
3. Re-implement affected sections
4. Revalidate against all criteria

---

*This systematic approach ensures every package gets professional, consistent documentation that truly serves SAGE users.*

---

📚 # 📚 Documentation: PACKAGE_DOCS

> **📁 Source File:** `DOCS/PACKAGE_DOCS.md` • *228 lines, 1888 tokens* • Hash: `5a3c08f8`

# 📦 Package Documentation Update Instructions

This document provides focused instructions for updating individual package READMEs to conform to the new SAGE documentation standards.

## 🎯 Task Overview

**Objective:** Refactor each package's README.md to follow the standardized template in `DOCS/PACKAGE_README_TEMPLATE.md`

**Success Criteria:**
- Concise, scannable README with clear Quick Start section
- Proper ecosystem context (dependencies/dependents)
- Copy-pasteable code examples that actually work
- Consistent structure across all packages

## 📋 Standard Template Structure

Every package README must follow this exact structure:

```markdown
# @sage/[package-name]

> [One-line tagline describing the package's purpose]

## Overview
[2-3 sentences explaining what this package does and why it exists]

## Installation
```bash
pnpm add @sage/[package-name]
```

## Quick Start
```typescript
import { [MainExport] } from '@sage/[package-name]';

// Minimal, copy-pasteable example demonstrating primary use case
const example = new [MainExport]();
await example.[primaryMethod]();
```

## Core API
### [PrimaryClass]
[Brief description with key method signatures]

## Role in the SAGE Ecosystem
### Dependencies
- **[@sage/dep](../dep/README.md)** — Why this package depends on it

### Dependents  
- **[@sage/dependent](../dependent/README.md)** — How it uses this package

## Development Status
![Status Badge](https://img.shields.io/badge/Status-[Status]-[color])

## Development
[Standard pnpm commands]

## Contract
This package implements the **[Package Contract](./CONTRACT.md)** [if it exists]
```

## 🔍 Package Analysis Checklist

Before updating each package, analyze:

### 1. **Core Purpose**
- [ ] What is the single most important thing this package does?
- [ ] Why does it exist in the SAGE ecosystem?
- [ ] What problem does it solve?

### 2. **Main Exports**
- [ ] What is the primary class/function users interact with?
- [ ] What's the most common usage pattern?
- [ ] What imports would a new user need?

### 3. **Dependencies & Dependents**
- [ ] Which @sage packages does this depend on? (check package.json)
- [ ] Which @sage packages depend on this? (search codebase)
- [ ] Why are these relationships important?

### 4. **Development Status**
- [ ] Is this package stable/production-ready?
- [ ] Is it under active development?
- [ ] Are there known limitations or planned changes?

## 📦 Individual Package Instructions

### packages/agents
**Priority: HIGH** - Core package
- **Purpose:** Implements the six archetypes (Sage, Guardian, Librarian, etc.)
- **Key Export:** Individual archetype classes
- **Quick Start:** Show how to instantiate and use a basic agent
- **Dependencies:** graph, chronicle, llm, tools
- **Status:** Production Ready

### packages/graph  
**Priority: HIGH** - Core package
- **Purpose:** Code knowledge representation and querying
- **Key Export:** Graph client/query interface
- **Quick Start:** Basic code analysis query
- **Dependencies:** None (foundational)
- **Status:** Production Ready

### packages/llm
**Priority: HIGH** - Core package
- **Purpose:** Multi-provider AI interface (OpenAI, Anthropic, etc.)
- **Key Export:** LLM client with provider abstraction
- **Quick Start:** Simple chat completion example
- **Dependencies:** mcp (optional)
- **Status:** Production Ready

### packages/chronicle
**Priority: HIGH** - Core package
- **Purpose:** Immutable event history and state management
- **Key Export:** Chronicle client for event logging
- **Quick Start:** Append and query events
- **Dependencies:** utils
- **Status:** Production Ready

### packages/aql
**Priority: MEDIUM** - Query language
- **Purpose:** Agent Query Language for orchestration
- **Key Export:** AQL parser/executor
- **Quick Start:** Parse and execute simple AQL
- **Dependencies:** graph, agents
- **Status:** Active Development

### packages/mcp
**Priority: HIGH** - Protocol implementation
- **Purpose:** Model Context Protocol for LLM tool integration
- **Key Export:** MCP server/client
- **Quick Start:** Basic MCP server setup
- **Dependencies:** None
- **Status:** Production Ready

### packages/tools
**Priority: MEDIUM** - Utilities
- **Purpose:** Sandboxed operations (Read, Write, Edit, Bash)
- **Key Export:** Tool registry and individual tools
- **Quick Start:** Execute a safe file operation
- **Dependencies:** utils
- **Status:** Production Ready

### packages/ui
**Priority: LOW** - UI components
- **Purpose:** Shared React/Ink components for CLI
- **Key Export:** React component exports
- **Quick Start:** Use a component in CLI app
- **Dependencies:** React, Ink
- **Status:** Active Development

### packages/test-utils
**Priority: MEDIUM** - Testing
- **Purpose:** Testing infrastructure with mocks and harnesses
- **Key Export:** Test utilities and matchers
- **Quick Start:** Set up a test with temp workspace
- **Dependencies:** vitest, utils
- **Status:** Production Ready

### packages/utils
**Priority: LOW** - Foundation
- **Purpose:** Core utilities, types, and helpers
- **Key Export:** Utility functions and types
- **Quick Start:** Use core utility functions
- **Dependencies:** None (foundational)
- **Status:** Production Ready

## 🚀 Step-by-Step Process

For each package:

### Step 1: Analyze Current README
1. Read the existing README completely
2. Identify the core purpose and main exports
3. Note any good examples or explanations to preserve
4. Check package.json for actual dependencies

### Step 2: Create Quick Start Example
1. Find the simplest possible usage example
2. Ensure it's copy-pasteable and actually works
3. Use realistic imports and setup
4. Show the most common use case, not edge cases

### Step 3: Map Ecosystem Relationships
1. Check package.json dependencies for @sage/* packages
2. Search codebase for imports of this package
3. Explain WHY these relationships exist, not just WHAT they are

### Step 4: Write New README
1. Follow the template exactly
2. Use the existing good content but reorganize it
3. Be ruthlessly concise - cut anything non-essential
4. Focus on "what" and "how", less on "why" (that's in the manifesto)

### Step 5: Validate
1. Check that all links work
2. Verify the Quick Start example is accurate
3. Ensure consistent tone and formatting
4. Test that the copy-paste example actually works

## ⚠️ Common Pitfalls to Avoid

1. **TMI (Too Much Information):** Keep READMEs focused on getting started, not comprehensive API docs
2. **Broken Examples:** Always verify code examples actually work
3. **Generic Descriptions:** Be specific about this package's unique role
4. **Missing Context:** Explain WHY this package exists in SAGE's ecosystem
5. **Inconsistent Formatting:** Follow the template structure exactly

## 🎯 Success Metrics

A good package README should:
- [ ] Take <2 minutes to read and understand
- [ ] Have a working Quick Start example someone can copy-paste
- [ ] Clearly explain the package's unique role in SAGE
- [ ] Link properly to dependencies and dependents
- [ ] Follow the exact template structure

## 📝 Notes for Implementation

- **Work on one package at a time** to maintain focus
- **Test examples in a real environment** before finalizing
- **Preserve any unique, valuable content** from existing READMEs
- **Be consistent with terminology** - use the Lexicon
- **Link liberally** to other docs and packages

---

*This systematic approach ensures every package has professional, consistent documentation that helps developers understand and use SAGE effectively.*

---

📚 # 📚 Documentation: PACKAGE_TODO_TEMPLATE

> **📁 Source File:** `DOCS/PACKAGE_TODO_TEMPLATE.md` • *102 lines, 821 tokens* • Hash: `17f8b391`

# Package Documentation Update TODO

**Agent Instructions:** Read this entire TODO, then read the current `README.md` file completely. After understanding both, write user stories for the changes needed.

## 📋 Task Overview

**Package:** `@sage/[PACKAGE_NAME]`  
**Priority:** [HIGH/MEDIUM/LOW]  
**Current Status:** [Brief assessment of current README state]

## 🎯 Objective

Transform this package's README.md to follow the **[standardized template](../../DOCS/PACKAGE_README_TEMPLATE.md)** while preserving valuable existing content and ensuring accuracy.

## 📚 Required Reading

**MUST READ FIRST:**
1. **[Package Standards](../../DOCS/Package-Standards.md)** — Understanding SAGE documentation conventions
2. **[Current README.md](./README.md)** — The existing documentation to be updated
3. **[Template](../../DOCS/PACKAGE_README_TEMPLATE.md)** — The target structure to achieve

## 🔍 Package Analysis

### Core Purpose
**What this package does:** [Specific purpose in SAGE ecosystem]

### Key Exports  
**Main classes/functions:** [Primary exports users interact with]

### Dependencies
**@sage packages this depends on:**
[List with reasons why each dependency exists]

### Dependents
**@sage packages that depend on this:**
[List with explanations of how they use this package]

### Current Issues
**Problems with existing README:**
- [Specific issue 1]
- [Specific issue 2] 
- [Specific issue 3]

## ✅ Success Criteria

The updated README must:
- [ ] Follow the exact template structure
- [ ] Include a working, copy-pasteable Quick Start example
- [ ] Clearly explain this package's unique role in SAGE
- [ ] Have accurate dependency/dependent relationships
- [ ] Be scannable in under 2 minutes
- [ ] Use consistent terminology from the [Lexicon](../../DOCS/core-concepts/Lexicon.md)

## 🚨 Critical Requirements

### Quick Start Example
- **MUST be copy-pasteable** and actually work
- **MUST show the most common use case** (not edge cases)
- **MUST use realistic imports** (check actual package exports)
- **MUST be minimal** (under 10 lines of code)

### Ecosystem Context
- **MUST explain WHY dependencies exist** (not just list them)
- **MUST show HOW dependents use this package** (not just list them)
- **MUST use relative links** to other package READMEs

### Tone & Style
- **MUST be concise** — cut verbose explanations
- **MUST be scannable** — use bullets, headers, short paragraphs
- **MUST be professional** — no casual language or emoji overuse

## 📝 Agent Workflow

**Step 1:** Read all required documents completely
**Step 2:** Analyze the current README.md and identify specific issues
**Step 3:** Write user stories in this format:

```markdown
## User Stories for README Update

### Story 1: [Title]
**As a** [developer type]  
**I want** [specific change]  
**So that** [benefit achieved]  

**Acceptance Criteria:**
- [ ] [Specific, testable requirement 1]
- [ ] [Specific, testable requirement 2]

**Implementation Notes:**
- [Technical details or constraints]
```

**Step 4:** Wait for approval before implementing changes

## 🎯 Package-Specific Notes

[Custom instructions specific to this package]

---

*This TODO will be marked complete when the README.md follows the template exactly and all user stories are implemented successfully.*

---

📚 # 📚 Documentation: Package-Standards

> **📁 Source File:** `DOCS/Package-Standards.md` • *345 lines, 2396 tokens* • Hash: `a5c14f32`

# 📦 SAGE Package Standards

This document defines the standardized structure, conventions, and practices for all SAGE packages.

## 🏗️ Standard Package Structure

Every SAGE package follows this consistent structure:

```
packages/[package-name]/
├── README.md                 # Package overview and quick start
├── CONTRACT.md              # Detailed behavioral contract
├── package.json             # Dependencies and scripts
├── tsconfig.json           # TypeScript configuration
├── vitest.config.ts        # Test configuration
├── tsdown.config.ts        # Build configuration
├── src/
│   ├── index.ts            # Main export barrel
│   ├── types.ts            # Core type definitions
│   ├── [feature]/          # Feature-specific modules
│   └── __tests__/          # Unit tests
├── docs/                   # Extended documentation
└── examples/               # Usage examples
```

## 📄 Standard README Template

Every package README must follow this template:

```markdown
# @sage/[package-name]

> [One-line tagline describing the package's purpose]

## Overview

[2-3 sentences explaining what this package does and why it exists]

## Installation

\```bash
pnpm add @sage/[package-name]
\```

## Quick Start

\```typescript
import { [MainExport] } from '@sage/[package-name]';

// Minimal, copy-pasteable example demonstrating primary use case
const example = new [MainExport]();
await example.[primaryMethod]();
\```

## Core API

### [PrimaryClass]

[Brief description of main functionality]

\```typescript
// Key method signatures with examples
\```

## Role in the SAGE Ecosystem

### Dependencies
- **[@sage/[dep1]](../[dep1]/README.md)** — [Why this package depends on dep1]
- **[@sage/[dep2]](../[dep2]/README.md)** — [Why this package depends on dep2]

### Dependents  
- **[@sage/[dependent1]](../[dependent1]/README.md)** — [How dependent1 uses this package]
- **[@sage/[dependent2]](../[dependent2]/README.md)** — [How dependent2 uses this package]

## Development Status

![Status: [Production Ready|In Development|Prototype]](https://img.shields.io/badge/Status-[Status]-[color])

[Brief description of current stability and planned changes]

## Development

\```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Run tests in watch mode
pnpm test:watch

# Build the package
pnpm build

# Run type checking
pnpm typecheck
\```

## Contract

This package implements the **[[PackageName] Contract](./CONTRACT.md)**, which defines:
- [Key behavioral guarantee 1]
- [Key behavioral guarantee 2]
- [Key behavioral guarantee 3]

See the [full contract specification](./CONTRACT.md) for detailed interface definitions and guarantees.
```

## 🏷️ Package Naming Conventions

### Package Names
- Use kebab-case: `@sage/package-name`
- Be descriptive and concise
- Avoid redundant prefixes (don't use `sage-` prefix)

### Directory Structure
- Use kebab-case for directories: `feature-name/`
- Group related functionality together
- Keep nesting shallow (max 3 levels)

### File Names
- Use kebab-case for files: `file-name.ts`
- Use descriptive names: `user-manager.ts` not `um.ts`
- Test files: `file-name.test.ts`
- Type definition files: `types.ts` or `file-name.types.ts`

## 🔧 Configuration Standards

### package.json
Required fields and scripts:

```json
{
  "name": "@sage/package-name",
  "version": "0.1.0",
  "description": "Brief package description",
  "main": "dist/index.js",
  "module": "dist/index.mjs",
  "types": "dist/index.d.ts",
  "exports": {
    ".": {
      "import": "./dist/index.mjs",
      "require": "./dist/index.js",
      "types": "./dist/index.d.ts"
    }
  },
  "scripts": {
    "build": "tsdown",
    "test": "vitest run",
    "test:watch": "vitest",
    "typecheck": "tsc --noEmit"
  },
  "keywords": ["sage", "relevant", "keywords"],
  "repository": "https://github.com/sage-ai/sage",
  "license": "MIT"
}
```

### TypeScript Configuration
Extend the base configuration:

```json
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": "./src"
  },
  "include": ["src/**/*"],
  "exclude": ["dist", "node_modules", "**/*.test.ts"]
}
```

### Test Configuration
Use the standardized Vitest setup:

```typescript
import { vitestConfigs } from "@sage/test-utils";

export default vitestConfigs.[packageType](); // e.g., graph(), agents(), etc.
```

## 📋 Contract Requirements

Every package must include a `CONTRACT.md` file with:

### Behavioral Contracts
- **Purpose Statement:** What problem this package solves
- **Interface Definition:** Public API with input/output specifications  
- **Behavioral Guarantees:** What callers can rely on
- **Error Handling:** How failures are communicated
- **Performance Characteristics:** Expected timing and resource usage

### Example Contract Structure
```markdown
# [Package Name] Contract

## Purpose
[1-2 sentences describing the package's role in the SAGE ecosystem]

## Interface
[Detailed API documentation with TypeScript signatures]

## Guarantees
- [Specific behavioral guarantee 1]  
- [Specific behavioral guarantee 2]
- [Specific behavioral guarantee 3]

## Error Handling
[How errors are thrown, what types, when they occur]

## Performance
[Expected performance characteristics, limits, timeouts]
```

## 🧪 Testing Standards

### Test Organization
- **Unit tests:** `src/__tests__/[module].test.ts`
- **Integration tests:** `src/__tests__/integration/[scenario].integration.test.ts`
- **Contract tests:** `src/__tests__/contract/[contract].contract.test.ts`

### Test Naming
```typescript
describe('[ClassName]', () => {
  describe('[methodName]', () => {
    it('should [expected behavior] when [condition]', () => {
      // Test implementation
    });
    
    it('should throw [ErrorType] when [invalid condition]', () => {
      // Error case testing
    });
  });
});
```

### Testing Best Practices
- **Use descriptive test names** that explain the expected behavior
- **Test both success and failure cases** for every public method
- **Use the shared test utilities** from `@sage/test-utils`
- **Mock external dependencies** to isolate package functionality
- **Include property-based tests** for complex logic

## 🎨 Code Style Standards

### TypeScript Guidelines
- **Use strict TypeScript:** Enable all strict mode options
- **Export types explicitly:** Always export interfaces and types used by consumers
- **Use branded types:** For IDs and other domain-specific values
- **Prefer composition:** Over inheritance for flexibility

### Naming Conventions
```typescript
// Classes: PascalCase
class UserManager {}

// Functions: camelCase  
function createUser() {}

// Constants: SCREAMING_SNAKE_CASE
const MAX_RETRY_COUNT = 3;

// Types/Interfaces: PascalCase
interface UserProfile {}
type UserId = string & { __brand: 'UserId' };

// Enums: PascalCase with PascalCase values
enum UserRole {
  Admin = 'Admin',
  Member = 'Member'
}
```

### Documentation Standards
- **JSDoc for public APIs:** All exported functions, classes, and interfaces
- **Include examples:** Show typical usage patterns
- **Document error conditions:** When and why functions might fail
- **Link to related concepts:** Reference other packages, types, or documentation

```typescript
/**
 * Creates a new user profile with validation and persistence.
 * 
 * @param userData - The user information to store
 * @returns Promise resolving to the created user ID
 * @throws {ValidationError} When userData fails validation
 * @throws {PersistenceError} When database operation fails
 * 
 * @example
 * ```typescript
 * const userId = await createUser({
 *   name: 'Alice',
 *   email: 'alice@example.com'
 * });
 * ```
 * 
 * @see {@link UserProfile} for userData structure
 * @see {@link @sage/graph} for persistence layer
 */
async function createUser(userData: UserProfile): Promise<UserId> {
  // Implementation
}
```

## 🔄 Development Workflow

### Adding New Packages
1. **Create directory:** `packages/[package-name]/`
2. **Copy template:** Use existing package as starting point
3. **Update package.json:** Set name, description, dependencies  
4. **Write CONTRACT.md:** Define behavioral contract
5. **Implement functionality:** Follow coding standards
6. **Add tests:** Include unit, integration, and contract tests
7. **Update documentation:** README, JSDoc, examples
8. **Add to workspace:** Update root `pnpm-workspace.yaml`

### Modifying Existing Packages
1. **Check contract:** Ensure changes don't break existing guarantees
2. **Update tests first:** Write tests for new functionality
3. **Implement changes:** Follow established patterns
4. **Update documentation:** Keep README and CONTRACT.md current
5. **Run full test suite:** Ensure no regressions
6. **Update dependents:** If interface changes affect other packages

## 🚀 Release Guidelines

### Version Management
- **Follow SemVer:** Major.Minor.Patch versioning
- **Coordinate releases:** Use changesets for monorepo releases
- **Update changelogs:** Document breaking changes and new features

### Pre-release Checklist
- [ ] All tests pass
- [ ] Type checking passes  
- [ ] Contract tests verify behavioral guarantees
- [ ] Documentation is up-to-date
- [ ] Examples work with new version
- [ ] Breaking changes are documented
- [ ] Migration guide exists (if needed)

---

*These standards ensure consistency across all SAGE packages, making the system easier to understand, maintain, and extend. When every package follows the same conventions, developers can quickly orient themselves and contribute effectively to any part of the system.*

---

🖥️ # 🖥️ App: cli (PHASE-1-extract-llm-layer)

> **📁 Source File:** `apps/cli/STORIES/PHASE-1-extract-llm-layer.md` • *172 lines, 1349 tokens* • Hash: `cce4ab9f`

# STORY: Extract LLM Layer to @sage/llm

## Overview
Extract the working LLM provider implementations from the CLI app into a standalone `@sage/llm` package, creating a provider-agnostic bridge to Large Language Models.

## Current State
The CLI app contains fully functional LLM integration with:
- ✅ OpenAI provider with streaming and tool calls (`src/models/OpenAIModel.ts`)
- ✅ Qwen provider implementation (`src/models/QwenModel.ts`)
- ✅ Model selection and management (`src/models/actions.ts`, `src/models/state.ts`)
- ✅ Streaming support with backpressure handling
- ✅ Tool call validation and execution
- ✅ Error handling and abort controllers

## Success Criteria
- [ ] `@sage/llm` package created with clean API
- [ ] OpenAI provider extracted and working
- [ ] Qwen provider extracted and working
- [ ] Unified streaming interface
- [ ] Tool call integration maintained
- [ ] CLI updated to consume `@sage/llm`
- [ ] All existing functionality preserved
- [ ] Tests passing for both packages

## Implementation Plan

### Step 1: Create @sage/llm Package Structure
```bash
packages/llm/
├── src/
│   ├── index.ts              # Main exports
│   ├── providers/
│   │   ├── openai.ts         # OpenAI provider
│   │   ├── qwen.ts           # Qwen provider
│   │   └── base.ts           # Base provider interface
│   ├── streaming/
│   │   ├── events.ts         # Stream event types
│   │   └── utils.ts          # Streaming utilities
│   ├── tools/
│   │   ├── integration.ts    # Tool calling integration
│   │   └── validation.ts     # Tool validation
│   └── types.ts              # Core types and interfaces
├── package.json
├── tsconfig.json
├── vitest.config.ts
└── README.md
```

### Step 2: Define Core Interfaces
```typescript
// Core API from CLI audit
export interface LLMProvider {
  name: string;
  act(chat: Chat, tools: Tool[], options: ActOptions): Promise<void>;
}

export interface ChatOptions {
  model: string;
  messages: ChatMessage[];
  tools?: ToolSchema[];
  temperature?: number;
  max_tokens?: number;
  timeoutMs?: number;
}

export type StreamEvent = 
  | { type: "text"; value: string }
  | { type: "tool_call"; toolName: string; arguments: unknown; callId: string }
  | { type: "tool_result"; callId: string; result: unknown }
  | { type: "end"; usage?: { prompt: number; completion: number } };
```

### Step 3: Extract and Adapt Providers
1. **Extract OpenAI Provider**
   - Move `apps/cli/src/models/OpenAIModel.ts` → `packages/llm/src/providers/openai.ts`
   - Adapt to unified interface
   - Remove CLI-specific dependencies
   - Preserve all streaming and tool call logic

2. **Extract Qwen Provider**
   - Move `apps/cli/src/models/QwenModel.ts` → `packages/llm/src/providers/qwen.ts`
   - Adapt to unified interface
   - Handle auth and device flow

3. **Create Provider Management**
   - Extract `apps/cli/src/models/actions.ts` logic
   - Implement `setProvider()`, `getProvider()`, `listModels()`

### Step 4: Streaming Integration
1. **Stream Event System**
   - Extract streaming patterns from CLI
   - Create unified `StreamEvent` types
   - Handle backpressure and cancellation

2. **Tool Integration**
   - Extract tool call handling from `act.ts`
   - Create tool schema validation
   - Preserve guard/confirmation flow

### Step 5: Update CLI Integration
1. **Update Dependencies**
   ```json
   {
     "dependencies": {
       "@sage/llm": "workspace:*"
     }
   }
   ```

2. **Replace Model Usage**
   ```typescript
   // Before
   import { OpenAIModel } from "./models/OpenAIModel.js";
   
   // After
   import { setProvider, OpenAIProvider, createChatStream } from "@sage/llm";
   ```

3. **Update act.ts**
   - Replace direct model calls with `@sage/llm` API
   - Maintain existing streaming behavior
   - Preserve tool call confirmation flow

### Step 6: Testing and Validation
1. **Package Tests**
   - Unit tests for each provider
   - Streaming integration tests
   - Tool call validation tests

2. **CLI Integration Tests**
   - Verify chat functionality works
   - Test model switching
   - Validate tool calls still work
   - Performance regression tests

## Files to Change

### New Files
- `packages/llm/` (entire package)

### Modified Files
- `apps/cli/package.json` (add dependency)
- `apps/cli/src/threads/utils/act.ts` (use new API)
- `apps/cli/src/models/` (remove or update imports)
- `apps/cli/src/threads/messaging/actions.ts` (update model usage)

### Deleted Files
- `apps/cli/src/models/OpenAIModel.ts` (moved)
- `apps/cli/src/models/QwenModel.ts` (moved)
- `apps/cli/src/models/actions.ts` (logic moved)
- `apps/cli/src/models/state.ts` (logic moved)

## Risk Mitigation
- **Low Risk**: CLI has clean model abstraction
- **Main Risk**: Breaking streaming behavior or tool calls
- **Mitigation**: Comprehensive integration tests before extraction

## Dependencies
- Must work with existing `@sage/utils` for logging
- Should integrate with future `@sage/tools` for tool schemas
- Compatible with `@sage/mcp` for MCP provider

## Success Validation
1. `pnpm build` succeeds in both packages
2. `pnpm test` passes in both packages  
3. `sage ask` command works identically to before
4. Model switching still works in CLI
5. Tool calls and confirmations work
6. Performance is equivalent or better

## Next Phase
With LLM layer extracted, Phase 2 can build `@sage/tools` and integrate with the new provider system.

---

🖥️ # 🖥️ App: cli (PHASE-2-build-tools-foundation)

> **📁 Source File:** `apps/cli/STORIES/PHASE-2-build-tools-foundation.md` • *329 lines, 2352 tokens* • Hash: `7ad63440`

# STORY: Build Tools Foundation in @sage/tools

## Overview
Create the `@sage/tools` package with a complete set of standard tools, implementing the missing functionality that the CLI currently has disabled and establishing the sandboxed capability layer for SAGE agents.

## Current State
The CLI has tool calling infrastructure but tools are disabled:
- ✅ Tool call confirmation system in place (`act.ts`)
- ✅ UI for tool call display and approval
- ✅ Auto-approval for `GraphQuery` and `Read` tools
- ❌ Actual tool implementations missing (empty array in `act.ts`)
- ❌ Tool registry not implemented
- ❌ Sandboxing and validation missing

## Success Criteria
- [ ] `@sage/tools` package created with full tool registry
- [ ] Standard tools implemented: `Read`, `Write`, `Edit`, `GraphQuery`, `Bash`
- [ ] JSON Schema generation for LLM tool calling
- [ ] Zod validation for all tool inputs
- [ ] Sandboxing and security policies implemented
- [ ] CLI updated to use real tools instead of empty array
- [ ] All tool confirmation flows working
- [ ] Integration tests passing

## Implementation Plan

### Step 1: Create @sage/tools Package Structure
```bash
packages/tools/
├── src/
│   ├── index.ts              # Main exports
│   ├── registry/
│   │   ├── ToolRegistry.ts   # Central tool registry
│   │   └── types.ts          # Registry types
│   ├── tools/
│   │   ├── Read.ts           # Read file tool
│   │   ├── Write.ts          # Write file tool
│   │   ├── Edit.ts           # Edit file tool
│   │   ├── GraphQuery.ts     # Query code graph
│   │   └── Bash.ts           # Execute shell commands
│   ├── sandbox/
│   │   ├── policies.ts       # Security policies
│   │   ├── isolation.ts      # Process isolation
│   │   └── validation.ts     # Input validation
│   └── schemas/
│       ├── generator.ts      # JSON Schema generation
│       └── validation.ts     # Zod schemas
├── package.json
├── tsconfig.json
├── vitest.config.ts
└── README.md
```

### Step 2: Define Core Tool Interface
```typescript
export interface Tool<I = any, O = any> {
  name: string;
  description?: string;
  schema: JSONSchema;           // For LLM consumption
  validate(input: unknown): I; // Zod runtime validation
  execute(input: I, ctx: ToolContext): Promise<ToolResult<O>>;
  version?: string;
}

export interface ToolContext {
  cwd: string;
  env?: Record<string, string>;
  dryRun?: boolean;
  permissions?: string[];
  logger?: (evt: ToolLog) => void;
  secretProvider?: SecretProvider;
}

export interface ToolResult<T> {
  ok: boolean;
  data?: T;
  error?: { code: string; message: string };
  meta?: { startedAt: string; endedAt: string; durationMs: number };
}
```

### Step 3: Implement Standard Tools

#### Read Tool
```typescript
export const Read = (): Tool<{ file: string }, { content: string }> => ({
  name: "Read",
  description: "Read file contents from the workspace",
  schema: {
    type: "object",
    properties: {
      file: { type: "string", description: "Path to file to read" }
    },
    required: ["file"]
  },
  validate: (input) => z.object({ file: z.string() }).parse(input),
  execute: async (input, ctx) => {
    // Implementation with path validation and sandboxing
    const safePath = validatePath(input.file, ctx.cwd);
    const content = await fs.readFile(safePath, 'utf-8');
    return { ok: true, data: { content } };
  }
});
```

#### Write Tool
```typescript
export const Write = (): Tool<{ file: string; content: string }, { bytes: number }> => ({
  name: "Write",
  description: "Write content to a file",
  schema: {
    type: "object", 
    properties: {
      file: { type: "string", description: "Path to file to write" },
      content: { type: "string", description: "Content to write" }
    },
    required: ["file", "content"]
  },
  validate: (input) => z.object({
    file: z.string(),
    content: z.string()
  }).parse(input),
  execute: async (input, ctx) => {
    // Implementation with path validation and backup
    const safePath = validateWritePath(input.file, ctx.cwd);
    const bytes = await fs.writeFile(safePath, input.content, 'utf-8');
    return { ok: true, data: { bytes } };
  }
});
```

#### GraphQuery Tool
```typescript
export const GraphQuery: Tool<{ query: string; params?: object }, { rows: any[] }> = {
  name: "GraphQuery",
  description: "Query the code graph with Cypher",
  schema: {
    type: "object",
    properties: {
      query: { type: "string", description: "Cypher query to execute" },
      params: { type: "object", description: "Query parameters" }
    },
    required: ["query"]
  },
  validate: (input) => z.object({
    query: z.string(),
    params: z.object({}).optional()
  }).parse(input),
  execute: async (input, ctx) => {
    // Integration with @sage/graph
    const graphClient = getGraphClient(ctx.cwd);
    const rows = await graphClient.query(input.query, input.params);
    return { ok: true, data: { rows } };
  }
};
```

### Step 4: Implement Tool Registry
```typescript
export class ToolRegistry {
  private tools = new Map<string, Tool<any, any>>();

  register<TI, TO>(tool: Tool<TI, TO>): void {
    this.tools.set(tool.name, tool);
  }

  get<TI, TO>(name: string): Tool<TI, TO> | undefined {
    return this.tools.get(name);
  }

  getToolSchemas(): ToolSchema[] {
    return Array.from(this.tools.values()).map(tool => ({
      name: tool.name,
      description: tool.description,
      parameters: tool.schema
    }));
  }

  async execute<T>(
    name: string, 
    input: unknown, 
    ctx: ToolContext
  ): Promise<ToolResult<T>> {
    const tool = this.tools.get(name);
    if (!tool) {
      return { ok: false, error: { code: "ENOTFOUND", message: `Tool ${name} not found` } };
    }
    
    try {
      const validInput = tool.validate(input);
      return await tool.execute(validInput, ctx);
    } catch (error) {
      return { 
        ok: false, 
        error: { 
          code: "EVALIDATION", 
          message: error instanceof Error ? error.message : String(error)
        }
      };
    }
  }
}
```

### Step 5: Security and Sandboxing
```typescript
// Path validation
export function validatePath(path: string, cwd: string): string {
  const resolved = resolve(cwd, path);
  
  // Must be within workspace
  if (!resolved.startsWith(cwd)) {
    throw new Error(`Path ${path} is outside workspace`);
  }
  
  // Cannot access .sage directory
  if (resolved.includes('/.sage/')) {
    throw new Error(`Access to .sage directory denied`);
  }
  
  return resolved;
}

// Permission policies
export const DEFAULT_POLICIES = {
  SAFE_TOOLS: new Set(["Read", "GraphQuery"]),
  WRITE_TOOLS: new Set(["Write", "Edit"]),
  EXEC_TOOLS: new Set(["Bash"]),
  
  // Auto-approve safe tools
  shouldConfirm(toolName: string): boolean {
    return !this.SAFE_TOOLS.has(toolName);
  }
};
```

### Step 6: CLI Integration
1. **Update Dependencies**
   ```json
   {
     "dependencies": {
       "@sage/tools": "workspace:*"
     }
   }
   ```

2. **Update act.ts**
   ```typescript
   // Before
   await model.act(chat, [], { // Empty tools array
   
   // After
   import { toolRegistry } from "@sage/tools";
   
   const tools = toolRegistry.getToolSchemas();
   await model.act(chat, tools, {
   ```

3. **Tool Execution Integration**
   ```typescript
   // Update guardToolCall to use tool registry
   guardToolCall: async (roundIndex, callId, controller) => {
     const toolName = controller.toolCallRequest.name;
     const shouldConfirm = !["GraphQuery", "Read"].includes(toolName);
     
     const decision = shouldConfirm 
       ? await confirmationFlow(controller.toolCallRequest)
       : "approved";
     
     if (decision === "approved") {
       const result = await toolRegistry.execute(
         toolName,
         controller.toolCallRequest.arguments,
         { cwd: process.cwd(), logger: logger.info }
       );
       controller.allow(result);
     } else {
       controller.deny("User denied execution");
     }
   }
   ```

### Step 7: Testing Strategy
1. **Unit Tests**
   - Each tool with valid/invalid inputs
   - Path validation and sandboxing
   - Registry operations
   
2. **Integration Tests**
   - CLI tool calling end-to-end
   - Confirmation flows
   - Error handling

3. **Security Tests**
   - Path traversal attempts
   - Privilege escalation
   - Resource exhaustion

## Files to Change

### New Files
- `packages/tools/` (entire package)

### Modified Files
- `apps/cli/package.json` (add dependency)
- `apps/cli/src/threads/utils/act.ts` (add real tools)
- `apps/cli/src/threads/messaging/actions.ts` (tool execution)

## Risk Mitigation
- **Medium Risk**: Tool security and sandboxing
- **Low Risk**: Registry and validation logic
- **Mitigation**: Comprehensive security testing and gradual rollout

## Dependencies
- `@sage/graph` for GraphQuery tool integration
- `@sage/utils` for error handling and logging
- `zod` for runtime validation
- Future integration with `@sage/llm` for schema export

## Success Validation
1. All tools work in CLI with proper confirmation
2. Security policies prevent dangerous operations
3. JSON Schema generation works for LLM integration
4. Auto-approval works for Read/GraphQuery
5. Error handling is comprehensive
6. Performance is acceptable for typical operations

## Next Phase
With tools foundation complete, Phase 3 can extract the UI components that display tool calls and confirmations.

---

🖥️ # 🖥️ App: cli (PHASE-3-extract-ui-components)

> **📁 Source File:** `apps/cli/STORIES/PHASE-3-extract-ui-components.md` • *312 lines, 2221 tokens* • Hash: `9d11439d`

# STORY: Extract UI Components to @sage/ui

## Overview
Extract the comprehensive React/Ink UI system from the CLI into a reusable `@sage/ui` package, creating shared components for chat interfaces, tool displays, and agent interactions across all SAGE applications.

## Current State
The CLI contains a sophisticated UI system built with React and Ink:
- ✅ Complete component library in `src/components/`
- ✅ Chat interface with streaming text display
- ✅ Tool call confirmation UI with syntax highlighting
- ✅ Navigation and routing components
- ✅ Form inputs and interactive elements
- ✅ Theme system and consistent styling
- ✅ Error handling and loading states

## Success Criteria
- [ ] `@sage/ui` package created with all CLI components
- [ ] Chat components working with streaming support
- [ ] Tool call display and confirmation UI extracted
- [ ] Navigation and form components generalized
- [ ] Theme system and styling preserved
- [ ] CLI updated to consume `@sage/ui` components
- [ ] Component documentation and examples
- [ ] All visual functionality preserved

## Implementation Plan

### Step 1: Create @sage/ui Package Structure
```bash
packages/ui/
├── src/
│   ├── index.ts              # Main exports
│   ├── components/
│   │   ├── chat/             # Chat-related components
│   │   │   ├── Chat.tsx
│   │   │   ├── ChatMessage.tsx
│   │   │   ├── ChatInput.tsx
│   │   │   ├── AssistantTurn.tsx
│   │   │   ├── UserMessage.tsx
│   │   │   └── ToolCall.tsx
│   │   ├── layout/           # Layout components
│   │   │   ├── Box.tsx
│   │   │   ├── Column.tsx
│   │   │   ├── Row.tsx
│   │   │   ├── View.tsx
│   │   │   ├── List.tsx
│   │   │   └── AsyncView.tsx
│   │   ├── content/          # Content display
│   │   │   ├── Text.tsx
│   │   │   ├── Code.tsx
│   │   │   ├── Error.tsx
│   │   │   ├── Command.tsx
│   │   │   └── Search.tsx
│   │   ├── input/            # Input components
│   │   │   ├── TextInput.tsx
│   │   │   ├── SearchableSelect.tsx
│   │   │   └── SearchableMultiSelect.tsx
│   │   ├── common/           # Common components
│   │   │   ├── Spinner.tsx
│   │   │   └── Header.tsx
│   │   └── providers/        # Context providers
│   │       ├── ThemeProvider.tsx
│   │       └── ConfigProvider.tsx
│   ├── hooks/                # Shared hooks
│   │   ├── useAsyncData.ts
│   │   └── useChatNavigation.ts
│   ├── theme/                # Theme system
│   │   ├── colors.ts
│   │   ├── theme.ts
│   │   └── index.ts
│   └── types/                # Component types
│       ├── chat.ts
│       ├── layout.ts
│       └── common.ts
├── examples/                 # Component examples
├── package.json
├── tsconfig.json
└── README.md
```

### Step 2: Extract Core Component Categories

#### Chat Components
From CLI `src/components/chat/`:
- `Chat.tsx` - Main chat container with streaming support
- `ChatMessage.tsx` - Individual message rendering
- `ChatInput.tsx` - Message input with controls
- `AssistantTurn.tsx` - Assistant response display
- `UserMessage.tsx` - User message display  
- `ToolCall.tsx` - Tool call display with confirmation UI

Key features to preserve:
- Streaming text animation
- Tool call syntax highlighting
- Confirmation flow UI
- Message threading
- Auto-scroll behavior

#### Layout Components
From CLI `src/components/layout/`:
- `Box.tsx`, `Column.tsx`, `Row.tsx` - Flexbox layouts
- `View.tsx` - Main view container
- `List.tsx` - List rendering with selection
- `AsyncView.tsx` - Loading states and error boundaries

#### Content Components
From CLI `src/components/content/`:
- `Text.tsx` - Styled text rendering
- `Code.tsx` - Syntax-highlighted code blocks
- `Error.tsx` - Error display with details
- `Command.tsx` - Command execution display
- `Search.tsx` - Search interfaces

### Step 3: Extract Theme and Styling System
```typescript
// theme/colors.ts
export const colors = {
  primary: '#0066cc',
  success: '#00aa00', 
  warning: '#ff8800',
  error: '#cc0000',
  muted: '#666666',
  // ... from CLI theme
};

// theme/theme.ts
export interface Theme {
  colors: typeof colors;
  spacing: Record<string, number>;
  typography: Record<string, any>;
}

// providers/ThemeProvider.tsx
export const ThemeProvider: React.FC<{
  theme?: Partial<Theme>;
  children: React.ReactNode;
}> = ({ theme, children }) => {
  // Theme context implementation
};
```

### Step 4: Generalize Component APIs
Make components reusable beyond just the CLI:

```typescript
// Before: CLI-specific
interface ChatProps {
  // Hard-coded CLI state references
}

// After: Generic and reusable
interface ChatProps {
  messages: ChatMessage[];
  onSendMessage: (message: string) => void;
  onToolConfirm: (callId: string, approved: boolean) => void;
  streaming?: boolean;
  streamingContent?: string;
  toolCalls?: ToolCallDisplay[];
  theme?: Partial<Theme>;
}
```

### Step 5: Extract Hooks and Utilities
From CLI `src/hooks/`:
- `useAsyncData.ts` - Async data fetching patterns
- `useChatNavigation.ts` - Chat navigation logic

Create new shared hooks:
```typescript
// hooks/useStreaming.ts
export function useStreaming(onFragment: (text: string) => void) {
  // Streaming text handling
}

// hooks/useToolCalls.ts  
export function useToolCalls(onConfirm: ToolConfirmHandler) {
  // Tool call confirmation logic
}
```

### Step 6: Component Documentation and Examples
Create comprehensive examples for each component:

```typescript
// examples/ChatExample.tsx
export const BasicChatExample = () => (
  <Chat
    messages={exampleMessages}
    onSendMessage={(msg) => console.log('Sent:', msg)}
    onToolConfirm={(id, approved) => console.log('Tool:', id, approved)}
  />
);

export const StreamingChatExample = () => (
  <Chat
    messages={exampleMessages}
    streaming={true}
    streamingContent="This is streaming text..."
    onSendMessage={handleSend}
  />
);
```

### Step 7: Update CLI to Use @sage/ui

1. **Update Dependencies**
   ```json
   {
     "dependencies": {
       "@sage/ui": "workspace:*"
     }
   }
   ```

2. **Replace Component Imports**
   ```typescript
   // Before
   import { Chat } from "./components/chat/Chat.js";
   import { ChatMessage } from "./components/chat/ChatMessage.js";
   
   // After
   import { Chat, ChatMessage } from "@sage/ui";
   ```

3. **Update Component Usage**
   ```typescript
   // Pass state as props instead of using internal context
   <Chat 
     messages={threadState.messages}
     onSendMessage={sendMessage}
     onToolConfirm={handleToolConfirmation}
     streaming={state.turn === "assistant"}
     streamingContent={state.response}
   />
   ```

4. **Clean Up CLI Components**
   - Remove `apps/cli/src/components/` directory
   - Update all component imports
   - Preserve CLI-specific logic in containers

### Step 8: Testing and Documentation

#### Component Testing
```typescript
// tests/Chat.test.tsx
import { render } from '@testing-library/react';
import { Chat } from '../src/components/chat/Chat';

test('renders messages correctly', () => {
  const messages = [
    { role: 'user', content: 'Hello' },
    { role: 'assistant', content: 'Hi there!' }
  ];
  
  const { getByText } = render(
    <Chat messages={messages} onSendMessage={jest.fn()} />
  );
  
  expect(getByText('Hello')).toBeInTheDocument();
  expect(getByText('Hi there!')).toBeInTheDocument();
});
```

#### Storybook Integration
Consider adding Storybook for component development:
```bash
pnpm add -D @storybook/react @storybook/addon-essentials
```

## Files to Change

### New Files
- `packages/ui/` (entire package)
- Component examples and documentation

### Modified Files  
- `apps/cli/package.json` (add @sage/ui dependency)
- All CLI files that import components (update imports)
- `apps/cli/src/views/` (update to use @sage/ui components)

### Deleted Files
- `apps/cli/src/components/` (entire directory moved)
- `apps/cli/src/config/theme.ts` (moved to @sage/ui)

## Risk Mitigation
- **Low Risk**: Components have clean interfaces
- **Medium Risk**: Theme/styling integration
- **Main Risk**: Breaking existing CLI functionality
- **Mitigation**: Gradual migration with extensive visual regression testing

## Dependencies
- `react` and `ink` for UI framework
- CLI dependencies moved to @sage/ui
- Future integration with other SAGE apps

## Success Validation
1. All CLI visual functionality works identically
2. Components render correctly in isolation  
3. Theme system preserves all styling
4. Streaming and tool call UI works perfectly
5. Performance is equivalent or better
6. Components are well-documented with examples

## Future Benefits
- Other SAGE apps can use the same UI components
- Consistent user experience across all interfaces
- Easier to maintain and update visual elements
- Component reusability and testing

## Next Phase
With UI extracted, Phase 4 can implement formal agents that will use these components for user interactions.

---

🖥️ # 🖥️ App: cli (PHASE-4-implement-agents)

> **📁 Source File:** `apps/cli/STORIES/PHASE-4-implement-agents.md` • *449 lines, 3281 tokens* • Hash: `24078f44`

# STORY: Implement Formal Agents in @sage/agents

## Overview
Transform the CLI's ad-hoc agent-like behaviors into formal implementations of SAGE's archetypal agents (Sage, Guardian, Warden, Delegator, Archivist), replacing implicit patterns with explicit agent protocols and state machines.

## Current State
The CLI has agent-like patterns but no formal agents:
- ✅ Agent orchestration patterns in `act.ts`
- ✅ Tool confirmation system (Guardian-like behavior)
- ✅ Plan-like structures in chat interactions
- ✅ State management for agent interactions
- ❌ No formal agent implementations
- ❌ No agent protocols or state machines
- ❌ No Chronicle integration
- ❌ No agent-to-agent communication

## Success Criteria
- [ ] `@sage/agents` package implements all 5 archetypes
- [ ] Guardian agents created for file protection
- [ ] Sage agent handles ideation and plan drafting
- [ ] Delegator executes plans with transaction boundaries
- [ ] Warden manages infrastructure and permissions
- [ ] Archivist tracks file and directory lineage
- [ ] CLI updated to use formal agents instead of ad-hoc patterns
- [ ] Agent protocols working (Bullet Wound, Reconciliation, etc.)
- [ ] Integration with Chronicle system for agent memory

## Implementation Plan

### Step 1: Create @sage/agents Package Structure
```bash
packages/agents/
├── src/
│   ├── index.ts              # Main exports
│   ├── archetypes/
│   │   ├── Guardian.ts       # File protection agent
│   │   ├── Sage.ts          # Ideation and planning agent  
│   │   ├── Delegator.ts     # Execution and orchestration
│   │   ├── Warden.ts        # Infrastructure and security
│   │   └── Archivist.ts     # Lineage and history
│   ├── protocols/
│   │   ├── BulletWound.ts   # Contradiction detection
│   │   ├── Reconciliation.ts # Rogue edit handling
│   │   ├── Transaction.ts    # Atomic execution boundaries
│   │   └── Unsafe.ts        # Override protocol
│   ├── state-machines/
│   │   ├── GuardianState.ts  # Guardian lifecycle
│   │   ├── DelegatorState.ts # Execution states
│   │   └── base.ts          # Base state machine
│   ├── types/
│   │   ├── agents.ts        # Agent interfaces
│   │   ├── plans.ts         # Plan structures
│   │   ├── decisions.ts     # Approve/Deny types
│   │   └── events.ts        # Agent events
│   └── adapters/
│       ├── GraphAdapter.ts   # @sage/graph integration
│       ├── ChronicleAdapter.ts # @sage/chronicle integration
│       └── ToolsAdapter.ts   # @sage/tools integration
├── package.json
├── tsconfig.json
├── vitest.config.ts
└── README.md
```

### Step 2: Define Core Agent Interfaces

```typescript
// types/agents.ts
export interface IGuardian {
  reviewPlan(plan: Plan): Promise<Approve | Deny>;
  reconcile(edit: RogueEdit): Promise<ReconciliationOutcome>;
  selfInquiry(): Promise<SelfInquiryReport>;
  bulletWoundCheck(assertions: Assertion[]): Promise<void>; // may HALT_AND_REPORT
}

export interface ISage {
  ideate(input: Intent): Promise<Ideation>;
  draftPlan(ideation: Ideation): Promise<Plan>;
  mediate(reviews: ReviewSet): Promise<MediationResult>;
}

export interface IDelegator {
  execute(plan: Plan): Promise<ExecutionReport>;
}

export interface IWarden {
  reviewPlan(plan: Plan): Promise<Approve | Deny>;
  promote(build: BuildRef, from: Env, to: Env): Promise<PromotionResult>;
}

export interface IArchivist {
  record(event: LineageEvent): Promise<void>;
  query(q: HistoryQuery): Promise<HistoryAnswer>;
}

// types/decisions.ts
export type Approve = { type: "approve"; justification: string };
export type Deny = { type: "deny"; reason: string };

// types/plans.ts  
export interface Plan {
  id: string;
  goal: string;
  affectedFiles: string[];
  changes: Change[];
  acceptanceCriteria: string[];
  createdBy: string; // agent id
  createdAt: string;
}
```

### Step 3: Implement Guardian Agent

```typescript
// archetypes/Guardian.ts
export class Guardian implements IGuardian {
  constructor(
    private filePath: string,
    private deps: {
      graph: GraphAdapter;
      chronicle: ChronicleAdapter;
      tools: ToolsAdapter;
      llm: LLMClient;
    }
  ) {}

  async reviewPlan(plan: Plan): Promise<Approve | Deny> {
    // Check if plan affects this Guardian's file
    if (!plan.affectedFiles.includes(this.filePath)) {
      return { type: "approve", justification: "Plan does not affect this file" };
    }

    // Perform architectural analysis
    const analysis = await this.analyzeChanges(plan.changes);
    
    // Query LLM for architectural reasoning
    const decision = await this.deps.llm.chat({
      model: "gpt-4",
      messages: [
        { role: "system", content: GUARDIAN_PROMPT },
        { role: "user", content: JSON.stringify({ plan, analysis }) }
      ]
    });

    // Parse structured decision
    return this.parseDecision(decision);
  }

  async reconcile(edit: RogueEdit): Promise<ReconciliationOutcome> {
    // Engage user in dialogue about the change
    const justification = await this.requestJustification(edit);
    
    // Record reconciliation in Chronicle
    await this.deps.chronicle.append(this.chroniclePath, {
      type: "RECONCILIATION",
      timestamp: new Date().toISOString(),
      edit: edit.diffRef,
      justification,
      resolved: true
    });

    return { reconciled: true, justification };
  }

  async bulletWoundCheck(assertions: Assertion[]): Promise<void> {
    for (const assertion of assertions) {
      const result = await this.deps.graph.query(assertion.cypher);
      const hasRows = result.length > 0;
      
      if (assertion.expectRows !== hasRows) {
        // CRITICAL: Contradiction detected
        await this.deps.chronicle.append(this.chroniclePath, {
          type: "HALT_AND_REPORT",
          timestamp: new Date().toISOString(),
          assertion,
          contradiction: true
        });
        
        throw new BulletWoundError(
          `Chronicle-Graph contradiction: ${assertion.description}`
        );
      }
    }
  }

  private get chroniclePath(): string {
    return this.filePath + '.sage';
  }
}
```

### Step 4: Implement Sage Agent

```typescript  
// archetypes/Sage.ts
export class Sage implements ISage {
  constructor(
    private deps: {
      graph: GraphAdapter;
      chronicle: ChronicleAdapter;
      llm: LLMClient;
    }
  ) {}

  async ideate(input: Intent): Promise<Ideation> {
    // Analyze current codebase state
    const context = await this.gatherContext(input);
    
    // LLM ideation with architectural awareness
    const response = await this.deps.llm.chat({
      model: "gpt-4",
      messages: [
        { role: "system", content: SAGE_IDEATION_PROMPT },
        { role: "user", content: JSON.stringify({ input, context }) }
      ]
    });

    return this.parseIdeation(response);
  }

  async draftPlan(ideation: Ideation): Promise<Plan> {
    // Convert ideation into structured plan
    const plan: Plan = {
      id: generateId(),
      goal: ideation.goal,
      affectedFiles: await this.identifyAffectedFiles(ideation),
      changes: await this.specifyChanges(ideation),
      acceptanceCriteria: ideation.acceptanceCriteria,
      createdBy: "sage",
      createdAt: new Date().toISOString()
    };

    // Log plan creation
    await this.deps.chronicle.append('.sage/plans', {
      type: "PLAN_DRAFTED",
      planId: plan.id,
      timestamp: plan.createdAt,
      plan
    });

    return plan;
  }

  async mediate(reviews: ReviewSet): Promise<MediationResult> {
    // Find conflicts between Guardian/Warden reviews
    const conflicts = this.identifyConflicts(reviews);
    
    if (conflicts.length === 0) {
      return { decision: "approve", consensus: true };
    }

    // LLM-assisted conflict resolution
    const resolution = await this.deps.llm.chat({
      model: "gpt-4", 
      messages: [
        { role: "system", content: SAGE_MEDIATION_PROMPT },
        { role: "user", content: JSON.stringify({ reviews, conflicts }) }
      ]
    });

    return this.parseMediation(resolution);
  }
}
```

### Step 5: Implement Delegator Agent

```typescript
// archetypes/Delegator.ts
export class Delegator implements IDelegator {
  constructor(
    private deps: {
      tools: ToolsAdapter;
      chronicle: ChronicleAdapter;
    }
  ) {}

  async execute(plan: Plan): Promise<ExecutionReport> {
    const executionId = generateId();
    
    try {
      // Start transaction boundary
      await this.beginTransaction(executionId, plan);
      
      // Execute each change in the plan
      const results = [];
      for (const change of plan.changes) {
        const result = await this.executeChange(change);
        results.push(result);
        
        // Validate after each change
        if (!result.ok) {
          await this.rollbackTransaction(executionId);
          throw new ExecutionError(result.error);
        }
      }
      
      // Commit transaction
      await this.commitTransaction(executionId);
      
      return {
        ok: true,
        executionId,
        results,
        completedAt: new Date().toISOString()
      };
      
    } catch (error) {
      await this.rollbackTransaction(executionId);
      throw error;
    }
  }

  private async executeChange(change: Change): Promise<ChangeResult> {
    switch (change.type) {
      case "edit":
        return await this.deps.tools.execute("Edit", {
          file: change.file,
          patch: change.patch
        });
      case "create":
        return await this.deps.tools.execute("Write", {
          file: change.file,
          content: change.content
        });
      default:
        throw new Error(`Unknown change type: ${change.type}`);
    }
  }
}
```

### Step 6: Update CLI Integration

Replace ad-hoc patterns with formal agents:

```typescript
// CLI: Create agent instances
const guardians = new Map<string, Guardian>();
const sage = new Sage({ graph, chronicle, llm });
const delegator = new Delegator({ tools, chronicle });

// Replace tool confirmation with Guardian protocol
guardToolCall: async (roundIndex, callId, controller) => {
  const affectedFile = extractFileFromToolCall(controller.toolCallRequest);
  
  if (affectedFile) {
    // Get or create Guardian for file
    let guardian = guardians.get(affectedFile);
    if (!guardian) {
      guardian = new Guardian(affectedFile, { graph, chronicle, tools, llm });
      guardians.set(affectedFile, guardian);
    }
    
    // Create mini-plan for this tool call
    const plan: Plan = {
      id: generateId(),
      goal: `Execute ${controller.toolCallRequest.name}`,
      affectedFiles: [affectedFile],
      changes: [toolCallToChange(controller.toolCallRequest)],
      acceptanceCriteria: [],
      createdBy: "cli",
      createdAt: new Date().toISOString()
    };
    
    // Guardian review
    const decision = await guardian.reviewPlan(plan);
    
    if (decision.type === "approve") {
      controller.allow();
    } else {
      controller.deny(decision.reason);
    }
  } else {
    // Non-file tools (like GraphQuery) auto-approve
    controller.allow();
  }
}
```

### Step 7: Chronicle Integration

Create Chronicle system for agent memory:

```typescript
// packages/chronicle/ - Basic implementation
export interface Chronicle {
  append(path: string, event: ChronicleEvent): Promise<void>;
  read(path: string): Promise<ChronicleEvent[]>;
  query(path: string, filter: EventFilter): Promise<ChronicleEvent[]>;
}

export interface ChronicleEvent {
  type: string;
  timestamp: string;
  data: Record<string, any>;
}
```

### Step 8: Testing Strategy

1. **Agent Unit Tests**
   - Each agent with mock dependencies
   - Protocol implementations
   - State machine transitions

2. **Integration Tests**  
   - Agent communication patterns
   - CLI workflow with real agents
   - Chronicle persistence

3. **Protocol Tests**
   - Bullet Wound Invariant triggering
   - Reconciliation workflows
   - Transaction boundaries

## Files to Change

### New Files
- `packages/agents/` (entire package)
- `packages/chronicle/` (basic implementation)

### Modified Files
- `apps/cli/package.json` (add dependencies)
- `apps/cli/src/threads/utils/act.ts` (replace with agents)
- `apps/cli/src/threads/messaging/actions.ts` (agent integration)

## Risk Mitigation
- **High Risk**: Major architectural change from ad-hoc to formal
- **Medium Risk**: Agent communication complexity
- **Mitigation**: Gradual rollout, extensive testing, fallback mechanisms

## Dependencies
- `@sage/llm` for agent reasoning
- `@sage/tools` for agent actions  
- `@sage/graph` for code understanding
- `@sage/chronicle` for agent memory
- `@sage/ui` for agent interfaces

## Success Validation
1. All CLI functionality works with formal agents
2. Guardian properly protects files and detects contradictions
3. Sage creates reasonable plans from user intent
4. Delegator executes plans atomically
5. Agent memory persists across sessions
6. Performance is acceptable for agent operations

## Next Phase
With formal agents implemented, Phase 5 can add AQL integration for complex multi-agent workflows and declarative orchestration.

---

🖥️ # 🖥️ App: cli (PHASE-5-aql-integration)

> **📁 Source File:** `apps/cli/STORIES/PHASE-5-aql-integration.md` • *515 lines, 3341 tokens* • Hash: `89bea0aa`

# STORY: AQL Integration for Multi-Agent Workflows

## Overview
Implement the Agent Query Language (AQL) system to enable declarative, complex multi-agent workflows. Transform from imperative agent orchestration to declarative query-based execution that can compose multiple agents, tools, and reasoning steps.

## Current State
After Phase 4, we have:
- ✅ Formal agents implemented (Sage, Guardian, Delegator, Warden, Archivist)
- ✅ Agent protocols working (Bullet Wound, Reconciliation, Transaction Boundary)
- ✅ Chronicle system for agent memory
- ✅ Tool integration with agents
- ❌ No declarative orchestration language
- ❌ Complex workflows still require imperative code
- ❌ No composition of multi-agent reasoning
- ❌ Limited workflow reusability

## Success Criteria
- [ ] AQL language implemented with GraphQL-like syntax
- [ ] AQL compiler converts queries to execution plans
- [ ] Multi-agent workflows can be declared in AQL
- [ ] CLI supports `sage aql run <file.aql>` command
- [ ] Complex reasoning patterns (committees, mediation) in AQL
- [ ] Streaming execution with real-time progress
- [ ] AQL queries integrate with existing agent infrastructure
- [ ] Performance suitable for interactive use

## Implementation Plan

### Step 1: Design AQL Syntax

AQL should be GraphQL-inspired but optimized for agent workflows:

```graphql
# Simple agent query
query AnalyzeFile {
  guardian(file: "src/UserService.ts") {
    selfInquiry {
      findings
      recommendations
    }
  }
}

# Multi-agent workflow  
query RefactorComponent {
  sage {
    ideate(goal: "Extract validation logic to separate module") {
      options {
        description
        complexity
        risk
      }
      plan: draftPlan {
        id
        changes {
          file
          type
          description
        }
      }
    }
  }
  
  # Get reviews from multiple guardians
  reviews: guardians(files: $plan.affectedFiles) {
    reviewPlan(plan: $plan) {
      type
      justification
      reason
    }
  }
  
  # Execute if approved
  execution: delegator @if(condition: $reviews.allApproved) {
    execute(plan: $plan) {
      ok
      results {
        file
        success
        error
      }
    }
  }
}

# Committee formation
query LargeRefactor {
  committee: sage {
    formCommittee(affectedFiles: ["src/**/*.ts"]) {
      chair: guardian(file: "src/main.ts")
      members: guardians(pattern: "src/**/*.ts") {
        territory: filePath
      }
    }
  }
  
  consensus: committee.negotiate(plan: $largeRefactorPlan) {
    decision
    dissent {
      agent
      reason
    }
  }
}
```

### Step 2: Create AQL Package Structure

```bash
packages/aql/
├── src/
│   ├── index.ts              # Main exports
│   ├── parser/
│   │   ├── lexer.ts         # Token lexer
│   │   ├── parser.ts        # AST parser
│   │   ├── validator.ts     # Query validation
│   │   └── types.ts         # AST node types
│   ├── compiler/
│   │   ├── Compiler.ts      # Main compiler
│   │   ├── ExecutionPlan.ts # Execution plan types
│   │   ├── Optimizer.ts     # Query optimization
│   │   └── CodeGen.ts       # Code generation
│   ├── runtime/
│   │   ├── Executor.ts      # Query executor
│   │   ├── Scheduler.ts     # Parallel execution
│   │   ├── Cache.ts         # Result caching
│   │   └── Stream.ts        # Streaming results
│   ├── resolvers/
│   │   ├── AgentResolver.ts # Agent field resolution
│   │   ├── ToolResolver.ts  # Tool field resolution
│   │   └── GraphResolver.ts # Graph data resolution
│   ├── directives/
│   │   ├── IfDirective.ts   # Conditional execution
│   │   ├── ParallelDirective.ts # Parallel execution
│   │   └── CacheDirective.ts # Result caching
│   └── types/
│       ├── schema.ts        # AQL schema types
│       ├── execution.ts     # Execution context
│       └── resolvers.ts     # Resolver interfaces
├── schemas/                 # AQL schema definitions
│   ├── agents.graphql       # Agent schema
│   ├── tools.graphql        # Tools schema  
│   └── base.graphql         # Base types
├── examples/                # Example AQL queries
├── package.json
├── tsconfig.json
├── vitest.config.ts
└── README.md
```

### Step 3: Implement AQL Parser

```typescript
// parser/types.ts
export interface AQLQuery {
  kind: "Query";
  name: string;
  selections: Selection[];
  variables: Variable[];
}

export interface AgentSelection {
  kind: "Agent";
  name: string; // "sage", "guardian", etc.
  arguments: Argument[];
  selections: Selection[];
  directives: Directive[];
}

export interface ToolSelection {
  kind: "Tool";
  name: string; // "Read", "Write", etc.
  arguments: Argument[];
  directives: Directive[];
}

// parser/parser.ts
export class AQLParser {
  parse(source: string): AQLQuery {
    const tokens = this.lexer.tokenize(source);
    return this.parseQuery(tokens);
  }
  
  private parseQuery(tokens: Token[]): AQLQuery {
    // GraphQL-style parsing logic
    // Handle query, selections, arguments, directives
  }
}
```

### Step 4: Implement AQL Compiler

```typescript
// compiler/Compiler.ts
export class AQLCompiler {
  compile(query: AQLQuery): ExecutionPlan {
    // Analyze dependencies between selections
    const graph = this.buildDependencyGraph(query);
    
    // Optimize execution order
    const optimized = this.optimizer.optimize(graph);
    
    // Generate execution plan
    return this.generatePlan(optimized);
  }
  
  private generatePlan(graph: DependencyGraph): ExecutionPlan {
    const steps: ExecutionStep[] = [];
    
    // Topological sort for execution order
    const sorted = this.topologicalSort(graph);
    
    for (const node of sorted) {
      if (node.kind === "Agent") {
        steps.push({
          type: "agent",
          agent: node.name,
          method: node.method,
          inputs: this.resolveInputs(node),
          parallel: node.directives.includes("parallel")
        });
      } else if (node.kind === "Tool") {
        steps.push({
          type: "tool", 
          tool: node.name,
          inputs: this.resolveInputs(node)
        });
      }
    }
    
    return { steps, variables: query.variables };
  }
}
```

### Step 5: Implement AQL Runtime

```typescript
// runtime/Executor.ts
export class AQLExecutor {
  constructor(
    private agents: AgentRegistry,
    private tools: ToolRegistry,
    private graph: GraphAdapter,
    private chronicle: ChronicleAdapter
  ) {}

  async *execute(plan: ExecutionPlan): AsyncIterableIterator<ExecutionEvent> {
    const context = new ExecutionContext(plan.variables);
    
    for (const step of plan.steps) {
      yield { type: "step_start", step: step.id };
      
      try {
        const result = await this.executeStep(step, context);
        context.setResult(step.id, result);
        yield { type: "step_complete", step: step.id, result };
      } catch (error) {
        yield { type: "step_error", step: step.id, error };
        throw error;
      }
    }
    
    yield { type: "query_complete", results: context.getAllResults() };
  }
  
  private async executeStep(step: ExecutionStep, context: ExecutionContext): Promise<any> {
    switch (step.type) {
      case "agent":
        return this.executeAgentStep(step, context);
      case "tool":
        return this.executeToolStep(step, context);
      case "parallel":
        return this.executeParallelStep(step, context);
    }
  }
  
  private async executeAgentStep(step: AgentStep, context: ExecutionContext): Promise<any> {
    const agent = this.agents.get(step.agent);
    const method = agent[step.method];
    const inputs = this.resolveInputs(step.inputs, context);
    
    return await method.call(agent, inputs);
  }
}
```

### Step 6: Agent Resolvers and Schema

```graphql
# schemas/agents.graphql
type Sage {
  ideate(goal: String!): Ideation
  draftPlan(ideation: Ideation!): Plan  
  mediate(reviews: [Review!]!): MediationResult
}

type Guardian {
  reviewPlan(plan: Plan!): Review
  reconcile(edit: RogueEdit!): ReconciliationOutcome
  selfInquiry: SelfInquiryReport
  bulletWoundCheck(assertions: [Assertion!]!): Boolean
}

type Delegator {
  execute(plan: Plan!): ExecutionReport
}

type Query {
  sage: Sage
  guardian(file: String!): Guardian
  guardians(files: [String!], pattern: String): [Guardian!]!
  delegator: Delegator
  warden: Warden
  archivist: Archivist
}
```

```typescript
// resolvers/AgentResolver.ts
export const agentResolvers = {
  Query: {
    sage: () => new Sage(dependencies),
    guardian: (_, { file }) => new Guardian(file, dependencies),
    guardians: async (_, { files, pattern }) => {
      const fileList = pattern 
        ? await glob(pattern) 
        : files;
      return fileList.map(file => new Guardian(file, dependencies));
    },
    delegator: () => new Delegator(dependencies)
  },
  
  Sage: {
    ideate: (sage, { goal }) => sage.ideate({ goal }),
    draftPlan: (sage, { ideation }) => sage.draftPlan(ideation),
    mediate: (sage, { reviews }) => sage.mediate(reviews)
  },
  
  Guardian: {
    reviewPlan: (guardian, { plan }) => guardian.reviewPlan(plan),
    reconcile: (guardian, { edit }) => guardian.reconcile(edit),
    selfInquiry: (guardian) => guardian.selfInquiry(),
    bulletWoundCheck: (guardian, { assertions }) => guardian.bulletWoundCheck(assertions)
  }
};
```

### Step 7: CLI Integration

Add AQL support to CLI:

```typescript
// commands/aql.ts
export async function aql(args: string[]) {
  const [subcommand, ...rest] = args;
  
  switch (subcommand) {
    case "run":
      return await runAQLFile(rest[0]);
    case "query":
      return await runAQLQuery(rest.join(" "));
    case "validate":
      return await validateAQL(rest[0]);
  }
}

async function runAQLFile(filePath: string) {
  const source = await fs.readFile(filePath, 'utf-8');
  const parser = new AQLParser();
  const compiler = new AQLCompiler();
  const executor = new AQLExecutor(agents, tools, graph, chronicle);
  
  try {
    const query = parser.parse(source);
    const plan = compiler.compile(query);
    
    console.log(`🚀 Executing AQL query: ${query.name}`);
    
    for await (const event of executor.execute(plan)) {
      switch (event.type) {
        case "step_start":
          console.log(`  ⚡ Starting step: ${event.step}`);
          break;
        case "step_complete":
          console.log(`  ✅ Completed: ${event.step}`);
          console.log(`     Result:`, JSON.stringify(event.result, null, 2));
          break;
        case "step_error":
          console.log(`  ❌ Error in step: ${event.step}`);
          console.log(`     Error:`, event.error.message);
          break;
      }
    }
  } catch (error) {
    console.error("❌ AQL execution failed:", error.message);
  }
}
```

### Step 8: Advanced AQL Features

#### Conditional Execution
```graphql
query ConditionalRefactor {
  analysis: guardian(file: "src/complex.ts") {
    complexity: selfInquiry {
      complexity
    }
  }
  
  refactor: sage @if(condition: "$analysis.complexity > 0.8") {
    ideate(goal: "Reduce complexity") {
      plan: draftPlan {
        changes
      }
    }
  }
}
```

#### Parallel Agent Execution
```graphql
query ParallelAnalysis {
  # Run multiple guardians in parallel
  analysis: guardians(pattern: "src/**/*.ts") @parallel {
    file: filePath
    issues: selfInquiry {
      findings
    }
  }
  
  # Aggregate results
  summary: sage {
    summarize(reports: $analysis) {
      totalIssues
      highPriority
      recommendations
    }
  }
}
```

#### Committee Workflows
```graphql
query CommitteeDecision {
  # Form committee for large change
  committee: sage {
    charter(scope: "authentication system") {
      chair: guardian(file: "src/auth/main.ts")
      members: guardians(pattern: "src/auth/**/*.ts")
    }
  }
  
  # Negotiate consensus
  decision: committee.negotiate(proposal: $authRefactor) {
    consensus
    approvals {
      agent
      justification
    }
    dissent {
      agent
      concerns
    }
  }
}
```

## Files to Change

### New Files
- `packages/aql/` (entire package)
- `apps/cli/src/commands/aql.ts` (new command)

### Modified Files
- `apps/cli/src/index.tsx` (add aql command)
- `apps/cli/package.json` (add @sage/aql dependency)

### CLI Command Integration
```typescript
// Update main CLI router
if (args[0] === "aql") {
  await aql(args.slice(1));
}
```

## Risk Mitigation
- **High Risk**: Complex new language implementation
- **Medium Risk**: Performance of complex queries
- **Low Risk**: Integration with existing agents
- **Mitigation**: Incremental implementation, extensive testing, performance monitoring

## Dependencies
- `@sage/agents` for agent orchestration
- `@sage/tools` for tool execution
- `@sage/graph` for graph queries
- `@sage/chronicle` for logging
- `@sage/llm` for agent reasoning

## Success Validation
1. `sage aql run query.aql` works for simple queries
2. Multi-agent workflows execute correctly
3. Parallel execution improves performance
4. Conditional logic works as expected
5. Error handling provides clear diagnostics  
6. Performance is acceptable for interactive use
7. AQL syntax is learnable and expressive

## Future Possibilities
- AQL query optimization and caching
- Visual AQL query builder
- AQL query libraries and templates
- Integration with external workflows (GitHub Actions, CI/CD)
- Real-time collaborative AQL editing

---

📦 # 📦 Package: agents (CONTRACT)

> **📁 Source File:** `packages/agents/CONTRACT.md` • *86 lines, 717 tokens* • Hash: `370e1e77`

# Agents Contract

## Purpose

This package provides the core logic, state machines, and protocols for SAGE's archetypal agents — **Sage, Guardian, Warden, Delegator, Archivist**. It translates the constitutional **Principles & Protocols** into executable behavior.

## Interface

### Core Agent Interfaces

```typescript
export interface IGuardian {
  reviewPlan(plan: Plan): Promise<Approve | Deny>;
  reconcile(edit: { filePath: string; diffRef: string }): Promise<{ ok: boolean }>;
  selfInquiry(): Promise<{ findings: string[] }>;
  bulletWoundCheck(assertions: { cypher: string; expectRows: boolean }[]): Promise<void>; // may throw HALT
}

export interface IDelegator { 
  execute(plan: Plan): Promise<{ ok: boolean; report: any }> 
}

export interface IWarden { 
  reviewPlan(plan: Plan): Promise<Approve|Deny> 
}

export interface ISage {
  ideate(input: { goal: string }): Promise<{ options: string[] }>;
  draftPlan(ideation: { options: string[] }): Promise<Plan>;
  mediate(reviews: { guardian: (Approve|Deny)[]; warden?: (Approve|Deny)[] }): Promise<{ decision: Approve|Deny }>;
}

export interface ILibrarian {
  search(query: string): Promise<{ results: SearchResult[] }>;
  index(filePath: string): Promise<void>;
  getContext(query: string): Promise<{ context: string; withinTokenLimit: boolean }>;
}

export interface IArchivist {
  record(event: LineageEvent): Promise<void>;
  query(q: HistoryQuery): Promise<HistoryAnswer>;
}

export type Approve = { type: "approve"; justification: string };
export type Deny = { type: "deny"; reason: string };
```

### Adapter Requirements

```typescript
type GraphAdapter = {
  query<T>(cypher: string, params?: Record<string, unknown>): Promise<T>;
};

type ChronicleAdapter = {
  read(path: string): Promise<ChronicleEntry[]>;
  append(path: string, event: ChronicleEvent): Promise<void>;
};

interface AgentsDeps {
  graph: GraphAdapter;
  chronicle: ChronicleAdapter;
  tools: ToolRegistry;
  llm: LLMClient;
}
```

## Guarantees

- **Deterministic Protocols** - Side-effect boundaries are explicit; all writes go through injected adapters
- **Auditability** - Every decision includes structured justification and Chronicle hooks
- **Composability** - Agents are small, testable units with narrow interfaces
- **Stateless Core** - Agents perform no direct I/O; all side effects handled by external adapters

## Error Handling

Agents may throw specific error types for different failure modes:
- `HALT_AND_REPORT` - Raised by Guardian when Code Graph contradicts Chronicle
- `ValidationError` - When input validation fails
- `ExecutionError` - When plan execution fails

## Performance

- Agents should respond to simple queries in under 100ms
- Complex operations (like self-inquiry) should complete in under 1 second
- All Chronicle and Graph operations should use efficient queries with proper indexing

---

📦 # 📦 Package: aql (CONTRACT)

> **📁 Source File:** `packages/aql/CONTRACT.md` • *100 lines, 769 tokens* • Hash: `6d605c57`

# AQL Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/aql` package.

## Overview

AQL (Agent/Action Query Language) is a declarative language for orchestrating agent workflows and tool executions. This contract specifies the expected behavior, interfaces, and guarantees that the AQL implementation must provide.

## Core Guarantees

### Strong Typing and Validation

- All AQL queries must be strongly typed with parameters and operation inputs/outputs having defined types
- The parser must validate type correctness at parse time
- Runtime validation must occur for all operation inputs against their declared types

### Deterministic Planning

- For any given AQL query and input variables, the execution plan must be deterministic
- Dependency resolution must be consistent and predictable
- Parallel execution must not introduce non-determinism in results

### Framework Agnosticism

- The AQL engine must be able to execute queries against different agent execution backends
- The core engine must not have hard dependencies on specific LLM providers or tool implementations
- Extension points must be provided for integrating with various agent and tool systems

### Auditability

- All execution steps must be traceable and loggable
- Execution results must include metadata about timing, tokens used, and errors
- The execution engine must support debug mode for detailed tracing

## Interface Specifications

### AQL Class

The main entry point for using AQL in code:

```typescript
class AQL {
  async initialize(): Promise<void>;
  parseQuery(aqlSource: string): AQLQuery;
  async executeQuery(query: AQLQuery, variables?: Record<string, any>): Promise<ExecutionResult>;
  async run(aqlSource: string, variables?: Record<string, any>): Promise<ExecutionResult>;
  setDebug(debug: boolean): void;
  setTimeout(timeout: number): void;
  setRetries(retries: number): void;
}
```

### AQLQuery

The parsed representation of an AQL query:

```typescript
interface AQLQuery {
  name: string;
  parameters: Parameter[];
  operations: Operation[];
}
```

### ExecutionResult

The result of executing an AQL query:

```typescript
interface ExecutionResult {
  query: string;
  results: Record<string, any>;
  metadata: {
    totalTime: number;
    totalTokens: number;
    operationsExecuted: number;
    errors: ExecutionError[];
  };
}
```

## Error Handling

The AQL implementation must provide clear error messages for:

1. **Parse Errors** - Invalid syntax in AQL source
2. **Validation Errors** - Type mismatches or missing required parameters
3. **Execution Errors** - Failures during operation execution
4. **Timeout Errors** - Operations exceeding configured timeouts

All errors must include sufficient context to help developers diagnose and fix issues.

## Future Extensions

This contract will be extended as AQL evolves to include:

- Tool operation support
- Integration with @sage/chronicle for event logging
- Full SAGE ecosystem integration
- Advanced features like conditional execution and loops

---

📦 # 📦 Package: aql (docs/roadmap)

> **📁 Source File:** `packages/aql/docs/roadmap.md` • *331 lines, 2285 tokens* • Hash: `a971568d`

# AQL Development Roadmap

_Strategic plan for implementing AQL (Agent/Action Query Language)_

## Overview

This roadmap outlines the development phases for AQL, from initial language design to a fully-featured ecosystem. Each phase builds upon previous work while delivering incremental value to users.

## Phase 1: Foundation (Months 1-2)

### Core Language Implementation

- [ ] **Grammar Definition** (Week 1-2)
  - ANTLR4 grammar for AQL syntax
  - Lexer and parser implementation
  - Syntax validation and error reporting
  - Basic AST generation

- [ ] **Type System** (Week 2-3)
  - Primitive types (String, Int, Float, Boolean)
  - Collection types ([String], [Agent])
  - Custom type definitions
  - Type inference and validation
  - Nullable vs non-nullable types

- [ ] **AST Processing** (Week 3-4)
  - Abstract Syntax Tree representation
  - AST visitors and transformers
  - Symbol table management
  - Scope resolution

- [ ] **Basic Execution Engine** (Week 4-6)
  - Sequential query execution
  - Variable binding and resolution
  - Context management
  - Basic error handling

- [ ] **Provider Integration** (Week 6-8)
  - OpenAI API adapter
  - Anthropic API adapter
  - Ollama local integration
  - Provider abstraction layer
  - Configuration management

**Deliverables:**

- Working parser for AQL syntax
- Basic execution engine
- 3 LLM provider integrations
- Simple CLI tool for query execution
- Test suite with 100+ test cases

## Phase 2: Core Features (Months 3-4)

### Advanced Language Features

- [ ] **Control Flow** (Week 9-10)
  - Conditional execution (if/else)
  - While loops
  - For loops and map operations
  - Break and continue statements

- [ ] **Parallel Execution** (Week 11-12)
  - Parallel operation blocks
  - Concurrent agent execution
  - Result synchronization
  - Dependency resolution

- [ ] **Built-in Functions** (Week 13-14)
  - Text processing functions
  - Aggregation functions (merge, concat, vote)
  - Context management functions
  - Utility functions (random, time, math)

- [ ] **Error Handling** (Week 15-16)
  - Try-catch blocks
  - Retry logic with backoff
  - Fallback strategies
  - Timeout handling
  - Provider failover

**Deliverables:**

- Full control flow support
- Parallel execution engine
- Comprehensive built-in function library
- Robust error handling system
- Performance benchmarks

## Phase 3: Developer Experience (Months 5-6)

### Tooling and IDE Support

- [ ] **Language Server Protocol** (Week 17-18)
  - LSP implementation for AQL
  - Syntax highlighting
  - Auto-completion
  - Error diagnostics
  - Go-to-definition

- [ ] **VS Code Extension** (Week 19-20)
  - AQL syntax highlighting
  - IntelliSense support
  - Integrated debugging
  - Query execution from editor
  - Snippet library

- [ ] **CLI Enhancements** (Week 21-22)
  - Interactive REPL mode
  - Query optimization hints
  - Execution profiling
  - Configuration management
  - Plugin system

- [ ] **Testing Framework** (Week 23-24)
  - Unit testing for AQL queries
  - Mock provider system
  - Test assertion library
  - Coverage reporting
  - Integration testing

**Deliverables:**

- Full IDE support with VS Code extension
- Enhanced CLI with REPL and profiling
- Comprehensive testing framework
- Developer documentation
- Tutorial series

## Phase 4: Advanced Features (Months 7-8)

### Sophisticated Capabilities

- [ ] **Streaming Support** (Week 25-26)
  - Real-time query execution
  - Progressive result delivery
  - WebSocket integration
  - Streaming aggregation
  - Live progress indicators

- [ ] **Caching System** (Week 27-28)
  - Query result caching
  - Smart cache invalidation
  - Distributed caching support
  - Cache warming strategies
  - Performance optimization

- [ ] **Custom Functions** (Week 29-30)
  - User-defined functions
  - Function libraries
  - Import/export system
  - Function composition
  - Recursive functions

- [ ] **Query Optimization** (Week 31-32)
  - Execution plan optimization
  - Cost-based optimization
  - Parallel execution planning
  - Resource allocation
  - Performance monitoring

**Deliverables:**

- Streaming execution engine
- Distributed caching system
- Custom function support
- Query optimizer
- Performance analytics

## Phase 5: Ecosystem (Months 9-10)

### Integration and Deployment

- [ ] **Web Playground** (Week 33-34)
  - Browser-based query editor
  - Live execution environment
  - Example query library
  - Collaboration features
  - Share and export capabilities

- [ ] **SDK Libraries** (Week 35-36)
  - Node.js/TypeScript SDK
  - Python SDK
  - REST API wrapper
  - GraphQL integration
  - Webhook support

- [ ] **Deployment Options** (Week 37-38)
  - Docker containerization
  - Kubernetes deployment
  - Cloud platform integration
  - Auto-scaling support
  - Monitoring and logging

- [ ] **Enterprise Features** (Week 39-40)
  - Authentication and authorization
  - Rate limiting and quotas
  - Audit logging
  - Multi-tenancy support
  - SLA monitoring

**Deliverables:**

- Web-based playground
- Multi-language SDK support
- Production deployment tools
- Enterprise-grade features
- Monitoring and observability

## Phase 6: Community and Ecosystem (Months 11-12)

### Open Source and Community

- [ ] **Open Source Release** (Week 41-42)
  - MIT license
  - Contribution guidelines
  - Code of conduct
  - Issue templates
  - CI/CD pipeline

- [ ] **Documentation Hub** (Week 43-44)
  - Complete API documentation
  - Tutorial series
  - Best practices guide
  - Use case examples
  - Video tutorials

- [ ] **Community Tools** (Week 45-46)
  - Package manager for AQL modules
  - Query sharing platform
  - Community examples repository
  - Discussion forums
  - Discord server

- [ ] **Integrations** (Week 47-48)
  - LangChain compatibility
  - Zapier integration
  - GitHub Actions
  - Slack/Discord bots
  - Popular tool integrations

**Deliverables:**

- Open source community
- Comprehensive documentation
- Package ecosystem
- Third-party integrations
- Community growth metrics

## Success Metrics

### Technical Metrics

- **Performance**: Query execution time < 2s for simple queries
- **Scalability**: Support for 1000+ concurrent queries
- **Reliability**: 99.9% uptime in production environments
- **Compatibility**: Support for 10+ LLM providers
- **Coverage**: 95%+ test coverage

### Adoption Metrics

- **Users**: 1000+ active users by month 12
- **Queries**: 10,000+ queries executed per month
- **Community**: 100+ GitHub stars, 20+ contributors
- **Integrations**: 5+ third-party integrations
- **Documentation**: 50+ tutorial articles

### Business Metrics

- **Developer Productivity**: 50% reduction in LLM orchestration code
- **Time to Market**: 3x faster AI application development
- **Error Reduction**: 70% fewer LLM integration bugs
- **Cost Optimization**: 30% reduction in LLM API costs
- **User Satisfaction**: 4.5+ rating on developer surveys

## Risk Mitigation

### Technical Risks

- **Complexity**: Gradual feature rollout with extensive testing
- **Performance**: Continuous profiling and optimization
- **Security**: Regular security audits and penetration testing
- **Compatibility**: Comprehensive provider testing matrix

### Market Risks

- **Competition**: Focus on unique declarative approach
- **Adoption**: Strong developer experience and documentation
- **Ecosystem**: Early partnerships with key players
- **Sustainability**: Clear monetization strategy for enterprise features

## Resource Requirements

### Development Team

- **Core Team**: 4-6 senior engineers
- **Specialized Roles**: DevOps, Security, Technical Writer
- **Community**: Part-time developer advocates
- **External**: Contract specialists for specific integrations

### Infrastructure

- **Development**: Cloud development environments
- **Testing**: Automated CI/CD pipelines
- **Documentation**: Documentation platform and CDN
- **Community**: Discussion forums and support channels

## Future Considerations

### Post-1.0 Features

- **Visual Query Builder**: Drag-and-drop interface
- **AI-Powered Optimization**: ML-based query optimization
- **Multi-Modal Support**: Image, video, and audio processing
- **Edge Computing**: Distributed execution capabilities
- **Blockchain Integration**: Decentralized AI orchestration

### Long-term Vision

- **Industry Standard**: Become the standard for LLM orchestration
- **Educational Impact**: Taught in computer science curricula
- **Research Platform**: Enable AI research and experimentation
- **Commercial Success**: Sustainable business model
- **Global Adoption**: International developer community

## Conclusion

This roadmap represents a comprehensive plan for building AQL from concept to production-ready platform. Success depends on maintaining focus on developer experience, building a strong community, and delivering incremental value throughout the development process.

The timeline is ambitious but achievable with proper resource allocation and strong execution. Regular milestone reviews and adaptive planning will ensure we stay on track while remaining responsive to user feedback and market changes.


---

📦 # 📦 Package: aql (docs/syntax)

> **📁 Source File:** `packages/aql/docs/syntax.md` • *640 lines, 2833 tokens* • Hash: `9ff43a7b`

# AQL Syntax Specification

_Complete language reference for AQL (Agent/Action Query Language)_

## Table of Contents

- [Basic Syntax](#basic-syntax)
- [Data Types](#data-types)
- [Operations](#operations)
- [Control Flow](#control-flow)
- [Built-in Functions](#built-in-functions)
- [Agent Configuration](#agent-configuration)
- [Error Handling](#error-handling)
- [Advanced Features](#advanced-features)

## Basic Syntax

### Query Structure

Every AQL file starts with a query definition:

```aql
query QueryName($param1: Type, $param2: Type = defaultValue) {
  // Operations
}
```

### Variables

Variables are prefixed with `$` and can be:

- **Query parameters**: `$topic`, `$maxTokens`
- **Operation outputs**: Reference by operation name
- **Interpolated in prompts**: `{{variable}}`

```aql
query Example($topic: String!) {
  research: agent(model: "research-agent") {
    prompt: "Research {{topic}}"
    input: $topic
  }

  summary: agent(model: "summary-agent") {
    prompt: "Summarize: {{research}}"
    input: research  // References the research operation
  }
}
```

### Comments

```aql
// Single line comment
/* Multi-line
   comment */
```

## Data Types

### Primitive Types

```aql
String      // "hello world"
Int         // 42
Float       // 3.14
Boolean     // true, false
```

### Collection Types

```aql
[String]    // Array of strings
[Agent]     // Array of agent results
```

### Custom Types

```aql
type Article {
  title: String!
  content: String!
  tags: [String]
  wordCount: Int
}

type QualityScore {
  score: Float!
  feedback: String
  categories: {
    grammar: Float
    clarity: Float
    engagement: Float
  }
}
```

### Nullable vs Non-Nullable

```aql
String      // Nullable string
String!     // Non-nullable string (required)
[String]    // Nullable array of nullable strings
[String!]   // Nullable array of non-nullable strings
[String]!   // Non-nullable array of nullable strings
[String!]!  // Non-nullable array of non-nullable strings
```

## Operations

### Agent Operations

The core building block of AQL:

```aql
agent(
  model: "research-agent",       // Required: Agent identifier
  role: "analyst"               // Optional: System role
) {
  prompt: "Analyze {{data}}"      // Required: Prompt template
  input: $data                   // Required: Input data
  context: [previous_ops]        // Optional: Additional context

  // Agent parameters
  temperature: 0.7
  maxTokens: 1000
  topP: 0.9

  // Output configuration
  output: Article            // Optional: Structured output type
  streaming: true            // Optional: Enable streaming

  // Retry configuration
  retries: 3
  timeout: 30s
}
```

### Tool Operations

Integrate external tools and APIs:

```aql
tool(name: "web_search") {
  query: "{{search_term}}"
  maxResults: 5
}

tool(name: "calculator") {
  expression: "{{math_expression}}"
}

tool(name: "code_executor", language: "python") {
  code: "{{python_code}}"
  timeout: 10s
}
```

### Transform Operations

Data transformation and processing:

```aql
transform(input: data) {
  operation: "extract"
  pattern: /\b[A-Z][a-z]+\b/g  // Regex pattern
  format: "json"
}

transform(input: articles) {
  operation: "map"
  function: (item) => {
    title: item.title.toUpperCase()
    summary: item.content.substring(0, 100)
  }
}
```

## Control Flow

### Sequential Execution (Default)

Operations execute in order:

```aql
query Pipeline {
  step1: agent(model: "agent-1") { ... }
  step2: agent(model: "agent-2") { input: step1 }
  step3: agent(model: "agent-3") { input: step2 }
}
```

### Parallel Execution

Execute operations concurrently:

```aql
parallel {
  analysis: agent(model: "analysis-agent") {
    prompt: "Analyze {{data}}"
    input: $data
  }

  summary: agent(model: "summary-agent") {
    prompt: "Summarize {{data}}"
    input: $data
  }

  keywords: agent(model: "keyword-agent") {
    prompt: "Extract keywords from {{data}}"
    input: $data
  }
}
```

### Conditional Execution

```aql
if (condition) {
  // Execute if true
} else if (other_condition) {
  // Execute if other_condition is true
} else {
  // Execute if all conditions are false
}
```

Example:

```aql
quality_check: agent(model: "quality-agent") {
  prompt: "Rate content quality 1-10"
  input: content
  output: { score: Int }
}

result: if (quality_check.score >= 8) {
  approve: content
} else if (quality_check.score >= 5) {
  revision: agent(model: "revision-agent") {
    prompt: "Improve this content: {{content}}"
    input: content
  }
} else {
  rewrite: agent(model: "rewrite-agent") {
    prompt: "Completely rewrite: {{content}}"
    input: content
  }
}
```

### Loops

#### While Loop

```aql
counter: 0
result: while (counter < 5) {
  iteration: agent(model: "processing-agent") {
    prompt: "Process iteration {{counter}}"
    input: $data
  }
  counter: counter + 1
}
```

#### For Loop

```aql
items: ["apple", "banana", "orange"]
results: for (item in items) {
  process: agent(model: "processing-agent") {
    prompt: "Describe {{item}}"
    input: item
  }
}
```

#### Map Operation

```aql
articles: map(source_articles) {
  agent(model: "summary-agent") {
    prompt: "Summarize: {{item}}"
    input: item
  }
}
```

## Built-in Functions

### Text Processing

```aql
// Extract information
extract(text: content, pattern: "email") // Built-in patterns
extract(text: content, regex: /\b\w+@\w+\.\w+\b/)

// Transform text
transform(text: content, operation: "lowercase")
transform(text: content, operation: "trim")
transform(text: content, operation: "markdown_to_html")

// Validate content
validate(text: content, rules: ["length > 100", "contains_keywords"])
```

### Aggregation Functions

```aql
// Merge multiple results
merge(results: [analysis, summary, keywords])
merge(results: [intro, body, conclusion], separator: "\n\n")

// Concatenate strings
concat(texts: [title, "\n", content])

// Voting/consensus
vote(results: [agent1_result, agent2_result, agent3_result])
vote(results: opinions, method: "majority")

// Summarization
summarize(texts: [doc1, doc2, doc3])
summarize(texts: documents, maxLength: 500)
```

### Context Management

```aql
// Remember information across operations
remember(key: "user_preferences", value: preferences)
context: recall(key: "user_preferences")

// Forget information
forget(key: "temporary_data")

// Context window management
context: sliding_window(history: conversation, size: 10)
context: truncate(text: long_content, maxTokens: 2000)
```

### Utility Functions

```aql
// Time operations
now()
wait(duration: "5s")
timeout(operation: slow_agent, duration: "30s")

// Random operations
random(min: 1, max: 100)
sample(list: options, count: 3)
shuffle(list: items)

// Math operations
sum(numbers: [1, 2, 3, 4])
average(numbers: scores)
round(number: 3.14159, precision: 2)
```

## Agent Configuration

### Global Configuration

```aql
agents {
  researcher: {
    type: "research"
    capabilities: ["web_search", "document_analysis"]
    rateLimits: {
      requestsPerMinute: 60
    }
  }

  writer: {
    type: "creative"
    capabilities: ["text_generation", "style_transfer"]
    rateLimits: {
      requestsPerMinute: 50
    }
  }

  analyzer: {
    type: "analytical"
    capabilities: ["data_processing", "pattern_recognition"]
  }
}
```

### Per-Operation Configuration

```aql
agent(
  model: "research-agent",
  config: {
    temperature: 0.7,
    maxTokens: 1000,
    presencePenalty: 0.1,
    frequencyPenalty: 0.1
  }
) {
  prompt: "Generate creative content"
  input: $topic
}
```

## Error Handling

### Retry Logic

```aql
agent(model: "research-agent") {
  prompt: "Process {{data}}"
  input: $data

  // Retry configuration
  retries: 3
  retryDelay: "2s"
  retryBackoff: "exponential"

  // Retry conditions
  retryOn: ["timeout", "service_unavailable", "server_error"]
}
```

### Fallback Strategies

```aql
primary: agent(model: "primary-agent") {
  prompt: "Complex analysis of {{data}}"
  input: $data
  timeout: "30s"
}

result: fallback(primary) {
  secondary: agent(model: "secondary-agent") {
    prompt: "Basic analysis of {{data}}"
    input: $data
  }

  tertiary: agent(model: "tertiary-agent") {
    prompt: "Simple summary of {{data}}"
    input: $data
  }
}
```

### Try-Catch Blocks

```aql
result: try {
  risky_operation: agent(model: "experimental-agent") {
    prompt: "Complex task"
    input: $data
  }
} catch (error) {
  fallback: agent(model: "safe-agent") {
    prompt: "Safe fallback for {{data}}"
    input: $data
  }

  log: "Error occurred: {{error.message}}"
}
```

## Advanced Features

### Streaming

```aql
stream_result: agent(model: "writer-agent") {
  prompt: "Write a long story about {{topic}}"
  input: $topic
  streaming: true

  onChunk: (chunk) => {
    display(chunk.content)
  }

  onComplete: (result) => {
    save(result, "story.txt")
  }
}
```

### Caching

```aql
cached_result: agent(model: "expensive-agent") {
  prompt: "Expensive computation for {{data}}"
  input: $data

  cache: {
    enabled: true
    ttl: "1h"
    key: "computation_{{hash(data)}}"
  }
}
```

### Custom Functions

```aql
function extractEmails(text: String): [String] {
  return extract(text: text, regex: /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g)
}

function qualityScore(content: String): Float {
  metrics: parallel {
    grammar: agent(model: "grammar-agent") {
      prompt: "Rate grammar 0-1: {{content}}"
      input: content
    }

    clarity: agent(model: "clarity-agent") {
      prompt: "Rate clarity 0-1: {{content}}"
      input: content
    }
  }

  return average([metrics.grammar, metrics.clarity])
}
```

### Imports and Modules

```aql
import { extractEmails, qualityScore } from "./utils.aql"
import * as textUtils from "./text-processing.aql"

query ProcessDocuments {
  emails: extractEmails(content)
  score: qualityScore(content)
  processed: textUtils.clean(content)
}
```

### Query Fragments

```aql
fragment QualityCheck on String {
  grammar: agent(model: "grammar-agent") {
    prompt: "Check grammar in: {{input}}"
    input: $input
  }

  readability: agent(model: "readability-agent") {
    prompt: "Rate readability 1-10: {{input}}"
    input: $input
  }
}

query ReviewContent {
  content: $input

  review: {
    ...QualityCheck

    seo: agent(model: "seo-agent") {
      prompt: "Analyze SEO potential: {{content}}"
      input: content
    }
  }
}
```

## Type System

### Type Definitions

```aql
type User {
  id: ID!
  name: String!
  email: String!
  age: Int
  preferences: UserPreferences
}

type UserPreferences {
  theme: Theme
  notifications: Boolean
  language: Language
}

enum Theme {
  LIGHT
  DARK
  AUTO
}

enum Language {
  EN
  ES
  FR
  DE
}
```

### Generic Types

```aql
type Result<T> {
  success: Boolean!
  data: T
  error: String
}

type PaginatedResult<T> {
  items: [T!]!
  totalCount: Int!
  hasNextPage: Boolean!
}
```

### Union Types

```aql
union SearchResult = Article | Video | Image

type Article {
  title: String!
  content: String!
  author: String!
}

type Video {
  title: String!
  duration: Int!
  url: String!
}

type Image {
  title: String!
  url: String!
  alt: String
}
```

---
This specification provides a comprehensive overview of AQL syntax. For more examples and use cases, see the [examples directory](../examples/).

---

📦 # 📦 Package: chronicle (CONTRACT)

> **📁 Source File:** `packages/chronicle/CONTRACT.md` • *151 lines, 1258 tokens* • Hash: `cb83f66a`

# Chronicle Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/chronicle` package.

## Overview

`@sage/chronicle` is SAGE's durable memory layer. It provides a simple, strongly-typed, **append-only** API for reading and writing `.sage` Chronicle files. Every material event in the ecology (approvals, denials, persona triggers, deployments, post-mortems) is recorded here for auditability and learning.

This contract specifies the expected behavior, interfaces, and guarantees that the Chronicle implementation must provide.

## Core Guarantees

### Append-Only

- No in-place mutation. All writes are additive.
- Corrections are emitted as new events that reference prior ones.
- File operations are atomic to ensure durability.

### Causal Links

- Events reference `planHash`, `graphCommit`, and optional `prevEventId` to build chains.
- Causal relationships between events are preserved and verifiable.

### Idempotency

- `eventId` (content hash) prevents duplicate appends.
- The same event appended multiple times will only appear once in the Chronicle.

### Ordering

- Events are timestamped with ISO 8601 timestamps.
- Monotonic timestamps ensure chronological ordering.
- File-level sequence numbers provide additional ordering guarantees.

### Concurrency Safety

- File locking around appends prevents race conditions.
- Cross-platform file locking with timeout handling.
- Atomic operations with crash safety.

### Tamper Evidence

- Events are canonical-JSON stringified with stable key order before hashing to `eventId`.
- `eventId` enables cryptographic verification of event integrity.
- Modifications to events will result in different hashes, making tampering detectable.

## Interface Specifications

### Main API Functions

The core Chronicle API provides functions for appending and reading events:

```typescript
export type ChroniclePath = string;

/**
 * Appends an event, automatically computing its eventId.
 * This is the standard, recommended method.
 */
export function appendEvent(
  path: ChroniclePath,
  evt: ChronicleEvent,
  lockTimeoutMs?: number
): Promise<void>;

/**
 * Appends an event using a pre-computed eventId.
 * For advanced use cases like event sourcing or testing.
 */
export function appendEventWithId(
  path: ChroniclePath,
  evt: ChronicleEvent, // Must contain a valid eventId
  lockTimeoutMs?: number
): Promise<void>;

export function readChronicle(path: ChroniclePath): Promise<ChronicleEvent[]>;

export function tailChronicle(
  path: ChroniclePath,
  n = 50
): Promise<ChronicleEvent[]>; // last n
```

### Event Model

All events share a minimal envelope and extend with type-specific payloads:

```typescript
export interface ChronicleEventBase {
  type: string; // e.g., "PLAN_APPROVED"
  eventId?: string; // sha256 of canonical JSON; computed if absent
  timestamp: string; // ISO 8601
  actor: { agent: string; id: string }; // e.g., {agent:"guardian", id:"src/Foo.ts"}
  planHash?: string; // if applicable
  graphCommit?: string; // commit index/hash anchoring to Code Graph
  prevEventId?: string; // causal link for corrections/amendments
  tags?: string[]; // freeform indexing
}
```

The Chronicle supports 13 distinct event types:
- `PLAN_DRAFTED`, `PLAN_APPROVED`, `PLAN_DENIED`, `PLAN_UNSAFE`
- `HALT_AND_REPORT`, `RECONCILIATION`, `ROGUE_EDIT_DETECTED`
- `BUILD`, `DEPLOY`, `ENVVAR_CHANGE`, `POSTMORTEM`
- `FILE_ADDED`, `FILE_REMOVED`, `FILE_RENAMED`

### Canonicalization & Hashing

- Events are canonical-JSON stringified with stable key order before hashing to `eventId`.
- SHA-256 is used for computing event hashes.
- The canonicalization process ensures deterministic hashes regardless of property order.

## Error Handling

The Chronicle implementation provides clear error messages for:

1. **Validation Errors** - Invalid event structures or missing required fields
2. **File System Errors** - Issues with reading or writing Chronicle files
3. **Concurrency Errors** - Lock acquisition timeouts or conflicts
4. **Canonicalization Errors** - Issues with JSON serialization or hashing

All errors follow SAGE's error handling conventions using typed errors from `@sage/utils`.

## Advanced Features

### Causal Chain Management

- Validation of causal chains between events
- Utilities for building and analyzing event chains
- Support for Merkle-style cryptographic chaining

### Chronicle Analysis and Repair

- Tools for analyzing Chronicle file integrity
- Utilities for repairing corrupted Chronicle files
- Duplicate event detection and removal

### Performance Optimizations

- Memory-efficient operations for large Chronicle files
- Batch operations for improved performance
- Indexing and caching for faster queries

## Future Extensions

This contract may be extended as Chronicle evolves to include:

- Additional event types as needed by the SAGE ecosystem
- Enhanced querying capabilities
- Integration with distributed storage systems
- Advanced analytics and reporting features

---

📦 # 📦 Package: graph (CONTRACT)

> **📁 Source File:** `packages/graph/CONTRACT.md` • *233 lines, 2035 tokens* • Hash: `ed776efe`

# Graph Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/graph` package.

## Overview

The `@sage/graph` package maintains the **objective structural reality** of a project. It ingests code into a Kùzu database, versions every node/edge by commit, and exposes a commit-addressable query interface. It is the substrate for all **Gnosis**: every Guardian self-inquiry, Delegator validation, and Librarian schema check grounds itself in this graph.

This contract specifies the expected behavior, interfaces, and guarantees that the Graph implementation must provide.

## Core Guarantees

### Ground Truth

- Code Graph is always authoritative versus agent beliefs.
- The graph provides an objective representation of the codebase's structural reality.
- All queries return factual information about the code structure.

### Time-Travel

- Any past state can be reconstructed exactly via git.
- Database snapshots are committed to git for perfect versioning.
- Historical queries can be performed at any commit.

### Auditability

- Every database state ties directly to a git commit hash.
- All changes to the graph are traceable and verifiable.
- Query results include metadata about the commit they were executed against.

### Semantic Richness

- The graph stores files, functions, classes, variables, imports, and dependencies.
- Entities are strongly typed with rich metadata.
- Relationships between entities capture semantic meaning.

## Interface Specifications

### Main API Functions

The core Graph API provides functions for ingesting projects and querying the graph:

```typescript
export interface IngestOptions {
  projectPath: string;
  commitHash?: string;
}

export interface QueryOptions {
  query: string;
  params?: Record<string, any>;
  commit?: string;
}

export interface QueryResult<T = any> {
  results: T[];
  error?: Error;
  meta?: {
    commit?: string;
    executionTimeMs?: number;
    rowCount?: number;
  };
}

/**
 * Ingests a project into the graph database.
 */
export function ingestProject(options: IngestOptions): Promise<void>;

/**
 * Query the graph database with optional commit-specific queries.
 */
export function queryGraph<T = any>(options: QueryOptions): Promise<QueryResult<T>>;

/**
 * Get current database status and metadata.
 */
export function getDatabaseStatus(projectPath?: string): Promise<{
  exists: boolean;
  path: string;
  currentCommit?: string;
  hasUncommittedChanges?: boolean;
}>;

/**
 * Utility to create a database connection for advanced use cases.
 */
export function createDatabaseClient(config?: DatabaseConfig): RustKuzuClient;

/**
 * Utility to create a git manager for advanced git operations.
 */
export function createGitManager(projectPath: string, debug?: boolean): GitDatabaseManager;
```

### Data Model

The Graph uses a rich data model to represent code entities and relationships:

```typescript
// Graph-native types (matching Rust format for zero-conversion)
export interface GraphEntity {
  id: string;
  kind: string;
  name: string;
  text: string;
  filePath: string;
  line: number;
  column_num: number;
  pos: number;
  end: number;
  flags: number;
  parentScopeId?: string; // For scope-based CONTAINS relationships
  extension?: string; // File extension (only for SourceFile entities)
  isModule?: boolean; // Whether file has imports/exports (only for SourceFile entities)
  size?: number; // File size in bytes (only for SourceFile entities)
  entityCount?: number; // Number of entities in file (only for SourceFile entities)
  totalLines?: number; // Total lines in file (only for SourceFile entities)
  relationshipCount?: number; // Number of relationships involving this file (only for SourceFile entities)
  // First-class entity metadata fields
  isAsync?: boolean; // For Function/Method
  isExported?: boolean; // For Function/Class/Interface/Variable/etc
  isAbstract?: boolean; // For Class
  isStatic?: boolean; // For Method/Property
  visibility?: string; // For Method/Property ("public" | "private" | "protected")
  className?: string; // For Method/Property (parent class name)
  returnType?: string; // For Function/Method
  parameters?: string[]; // For Function/Method
  superClass?: string; // For Class
  interfaces?: string[]; // For Class/Interface
  type?: string; // For Variable/Property
  isConst?: boolean; // For Variable/Enum
  isReadonly?: boolean; // For Property
  isOptional?: boolean; // For Property
  scope?: string; // For Variable ("parameter" | "local" | "module" | "block")
  defaultValue?: string; // For Variable/Property
  extends?: string[]; // For Interface
  properties?: string[]; // For Interface
  members?: string[]; // For Enum
  definition?: string; // For TypeAlias
  typeParameters?: string[]; // For TypeAlias
  localName?: string; // For ImportAlias/ExportAlias
  originalName?: string; // For ImportAlias/ExportAlias
  importPath?: string; // For ImportAlias
  exportType?: string; // For ExportAlias ("named" | "default" | "namespace")
  signature?: string; // Original signature text
}

export interface GraphRelationship {
  from: string;
  to: string;
  fromKind: string;
  toKind: string;
  type: string;
  evidence: string;
  confidence: "high" | "medium" | "low";
  metadata: Record<string, any>;
}
```

### Schema

The Graph uses a strongly-typed schema to represent code entities:

```cypher
(:File {path, name, size, hash})
(:Function {name, signature, startLine, endLine})
(:Class {name, isAbstract, isExported})
(:Variable {name, type, isConst})

(:File)-[:IMPORTS]->(:File)
(:File)-[:DEFINES_FUNCTION]->(:Function)
(:Class)-[:HAS_METHOD]->(:Function)
(:Function)-[:CALLS]->(:Function)
```

## Error Handling

The Graph implementation provides clear error messages for:

1. **Validation Errors** - Invalid project paths or missing Git repositories
2. **Ingestion Errors** - Issues with parsing code or ingesting into the database
3. **Query Errors** - Invalid Cypher queries or database connection issues
4. **Git Errors** - Issues with Git operations or commit management

All errors follow SAGE's error handling conventions using typed errors from `@sage/utils`.

## Implementation Strategy

### Version 1 (Git-Committed)

The current implementation uses a simplified but robust versioning strategy:

1. **AST Analysis** - The complete TypeScript/JavaScript AST is parsed to extract all code entities and their relationships.
2. **Database Replacement** - For each `ingestProject` call, the existing Kùzu database (`.sage/code.kuzu`) is completely deleted and rebuilt from scratch with the new analysis data.
3. **Git Versioning** - After a successful ingestion, the entire `.sage/code.kuzu` database file is committed to git. This provides perfect, auditable, and reproducible time-travel.
4. **Historical Queries** - To query a past state, the database file from the corresponding git commit is checked out to a temporary location and queried.

### Future Enhancements

1. **Incremental Ingestion** - Diff-aware ingestion with MVCC fields for performance
2. **Advanced Schema** - First-class types and richer metadata
3. **Performance Optimizations** - Streaming and bulk ingestion improvements

## Advanced Features

### Commit-Addressable Storage

- Database snapshots are committed to git for perfect versioning
- Historical queries can be performed at any commit
- All database states are auditable and reproducible

### Query Interface

- Safe, async helpers for Cypher queries at specific commits
- Parameterized queries to prevent injection attacks
- Metadata-rich results with execution timing and row counts

### Git Integration

- Automatic commit detection and management
- Temporary database checkout for historical queries
- Cleanup of temporary files after queries

## Future Extensions

This contract may be extended as Graph evolves to include:

- Additional entity types for other programming languages
- Enhanced relationship discovery algorithms
- Integration with distributed storage systems
- Advanced analytics and reporting features
- Real-time graph updates for development workflows

---

📦 # 📦 Package: llm (CONTRACT)

> **📁 Source File:** `packages/llm/CONTRACT.md` • *300 lines, 2317 tokens* • Hash: `4f7af745`

# LLM Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/llm` package.

## Overview

`@sage/llm` is the provider-agnostic bridge to Large Language Models. It standardizes chat, tool-use, and streaming across backends (LM Studio, OpenAI, Anthropic, etc.), so agents focus on **what** to think, not **how** to call models.

This contract specifies the expected behavior, interfaces, and guarantees that the LLM implementation must provide.

## Core Guarantees

### Provider-Agnostic

- Same API, different backends.
- Unified interface abstracts away provider-specific details.
- Easy switching between providers without changing application code.

### Deterministic Wrapping

- Inputs/outputs are normalized to a single schema.
- Consistent behavior regardless of underlying provider.
- Predictable API responses across all providers.

### Observability

- Every request/response can emit telemetry (durations, tokens, cache hits).
- Comprehensive logging and monitoring capabilities.
- Traceability with requestId for debugging.

### Safety by Default

- Timeouts, retries with jitter, backoff, and budget guards.
- Configurable safety caps (rate limits, token budgets).
- Secret redaction in telemetry by default.

## Interface Specifications

### Main API Functions

The core LLM API provides functions for interacting with LLM providers:

```typescript
export type Role = "system" | "user" | "assistant" | "tool";

export interface ChatMessage {
  role: Role;
  content: string;
  tool_call_id?: string;
}

export interface ToolSchema {
  name: string;
  description?: string;
  parameters: Record<string, unknown>; // JSON Schema
}

export interface ChatOptions {
  model: string;
  messages: ChatMessage[];
  tools?: ToolSchema[];
  temperature?: number;
  max_tokens?: number;
  timeoutMs?: number;
  requestId?: string; // for tracing & dedupe
  // Optional policy hook to decide tool permissions at runtime
  guardToolCall?: (
    info: ToolCallInfo
  ) => Promise<"approved" | "denied"> | "approved" | "denied";
  // Abort signal for cancellation
  signal?: AbortSignal;
  // Caching options
  cache?: {
    mode: "read-through" | "record-only" | "bypass";
    hashPrompts?: boolean;
    ttlMs?: number;
    maxEntries?: number;
  };
}

export type StreamEvent =
  | { type: "text"; value: string }
  | { type: "tool_call"; toolName: string; arguments: unknown; callId: string }
  | { type: "tool_result"; callId: string; result: unknown }
  | { type: "tool_validation_error"; callId: string; error: string; toolName: string }
  | { type: "round_start"; index: number }
  | { type: "round_end"; index: number }
  | { type: "error"; error: string; recoverable: boolean }
  | { type: "end"; usage?: { prompt: number; completion: number } };

/**
 * Create a chat stream with the current provider, with optional caching
 */
export function createChatStream(
  opts: ChatOptions,
  streamOpts?: StreamOptions
): Promise<AsyncIterable<StreamEvent>>;

/**
 * List available models from the current provider or a specific provider
 */
export function listModels(provider?: string): Promise<ModelInfo[]>;

/**
 * Set the current provider
 */
export function setProvider(provider: LLMProvider): void; // swap at runtime
```

### Provider Interface

All LLM providers must implement the following interface:

```typescript
export interface LLMProvider {
  name: string;
  chat(
    opts: ChatOptions
  ): AsyncIterable<StreamEvent> | Promise<{ text: string }>;
  models(): Promise<{ name: string }[]>;
}
```

### Tool System

The LLM package provides a comprehensive tool system:

```typescript
// Tool call information for guard policies
export type ToolCallInfo = {
  id: string;
  name: string;
  args: unknown;
  round: number;
};

// Tool validation exports
export class ToolValidator {
  validate(toolName: string, args: unknown): Promise<ValidationResult>;
  setApprovalPolicy(policy: (info: ToolCallInfo) => Promise<"approved" | "denied">): void;
}

// Tool lifecycle exports
export class ToolCallManager {
  executeToolCall(call: ToolCall): Promise<unknown>;
  generateCallId(): string;
}

// Security policy exports
export class SecurityPolicyManager {
  createPolicyFunction(): (info: ToolCallInfo) => Promise<"approved" | "denied">;
  evaluatePolicy(context: PolicyContext): Promise<DetailedPolicyResult>;
}
```

## Streaming & Backpressure

### Event Stream

- `createChatStream` yields events as they arrive.
- Callers can apply backpressure by pausing iteration.
- Providers that don't support server-sent streaming are wrapped into timed chunk events.

### Event Types

1. **Text Events** - `{ type: "text"; value: string }`
2. **Tool Call Events** - `{ type: "tool_call"; toolName: string; arguments: unknown; callId: string }`
3. **Tool Result Events** - `{ type: "tool_result"; callId: string; result: unknown }`
4. **Tool Validation Error Events** - `{ type: "tool_validation_error"; callId: string; error: string; toolName: string }`
5. **Round Start Events** - `{ type: "round_start"; index: number }`
6. **Round End Events** - `{ type: "round_end"; index: number }`
7. **Error Events** - `{ type: "error"; error: string; recoverable: boolean }`
8. **End Events** - `{ type: "end"; usage?: { prompt: number; completion: number } }`

### Backpressure Handling

- Configurable buffer size to control memory usage.
- Event timeout handling to prevent hanging streams.
- Graceful error propagation in streams.

## Tool-Use Integration

### JSON Schema Validation

- Tools are described with **JSON Schema**.
- Arguments are validated before execution.
- Malformed arguments result in validation errors, not execution.

### Tool Call Lifecycle

- When a model emits `{type: "tool_call"}`, the caller executes the tool.
- The result is fed back via a synthetic `tool` message.
- Generation continues after tool execution.
- The API preserves **callId** across `tool_call` ⇄ `tool_result` pairs for traceability.

### Security Policies

- Configurable tool approval policies.
- Per-provider allowlists for models and tool-use capabilities.
- Runtime evaluation of tool call permissions.

## Prompt Caching

### Cache Key Generation

- **Cache Key:** `(model, messages, tools, temperature, max_tokens)` hashed canonically.
- Optional **prompt hashing** for cache storage so raw prompts are not persisted.
- Cache keys include context-sensitive information like commit hashes for SAGE.

### Cache Modes

1. **Read-Through** - Serve from cache if present, otherwise compute and store.
2. **Record-Only** - Compute and store but never serve from cache (for evals).
3. **Bypass** - Skip cache entirely.

### Cache Invalidation

- Automatic invalidation when underlying context changes.
- Tied to commit hash of `@sage/graph` for SAGE applications.
- Configurable TTL and maximum cache size.

### Granularity

- Full-turn cache (not token-level) to avoid partial replay artifacts.
- Cached results include complete event streams.
- Metadata preservation for traceability.

## Error Handling

### Timeouts

- **Timeouts** default to 30 seconds but are configurable per call.
- Automatic cleanup of timed-out requests.
- Clear error messages for timeout conditions.

### Retry Policy

- Exponential backoff with jitter on transient errors.
- Configurable retry limits per provider.
- Intelligent error classification for retry decisions.

### Guardrails

- If a provider returns malformed tool args, the wrapper emits a validation error and **does not execute** the tool.
- Rate limiting and token budget guards prevent resource exhaustion.
- Circuit breaker pattern for failing providers.

## Security & Privacy

### Secret Redaction

- Redact secrets in telemetry by default.
- Configurable redaction patterns.
- Audit logging of redaction events.

### Prompt Privacy

- Optional **prompt hashing** for cache storage so raw prompts are not persisted.
- Encryption of sensitive prompt data at rest.
- Access controls for cached prompt data.

### Provider Security

- Per-provider **allowlist** for models and tool-use capabilities.
- Secure credential management.
- Audit trails for provider access.

## Advanced Features

### Event Normalization

- Provider-specific event normalizers ensure consistent event formats.
- Built-in normalizers for OpenAI and Anthropic.
- Extensible normalizer interface for new providers.

### Stream Utilities

- `AsyncQueue` for managing asynchronous event streams.
- `mergeStreams` for combining multiple event streams.
- `mapStream` and `filterStream` for stream transformations.
- `withErrorBoundary` for robust error handling.
- `withTimeout` for stream timeout management.

### Cache System

- `MemoryCache` for in-memory caching with LRU eviction.
- `CacheManager` for coordinating cache operations.
- Configurable cache key generators.
- Cache metrics for monitoring and optimization.

## Future Extensions

This contract may be extended as LLM evolves to include:

- Additional provider adapters for new LLM services
- Enhanced caching strategies including distributed caching
- Advanced telemetry and monitoring features
- Improved security policies and access controls
- Integration with more sophisticated tool ecosystems
- Support for multimodal models and inputs

---

📦 # 📦 Package: mcp (CONTRACT)

> **📁 Source File:** `packages/mcp/CONTRACT.md` • *346 lines, 2288 tokens* • Hash: `f3070b0f`

# MCP Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/mcp` package.

## Overview

`@sage/mcp` (Model Control Program) is a **production-grade implementation of the Model Context Protocol (MCP)**, an industry standard for integrating AI models with development tools and enterprise systems. It provides robust server lifecycle management and multi-transport support, making it a cornerstone of SAGE's AI infrastructure.

This contract specifies the expected behavior, interfaces, and guarantees that the MCP implementation must provide.

## Core Guarantees

### MCP Protocol Implementation

- Provides a complete and reliable implementation of the Model Context Protocol
- Enables integration with tools like **Claude Desktop** and **VSCode extensions**
- Maintains compliance with the official MCP specification
- Supports the latest MCP features and capabilities

### Enterprise Server Management

- Manages the lifecycle of MCP servers, including discovery, connection pooling, and error recovery
- Provides robust connection management with automatic reconnection
- Implements efficient resource utilization and cleanup
- Handles server state transitions gracefully

### Multi-Transport Support

- Communicates with MCP servers over various transports, including `stdio` and `HTTP`
- Provides an adapter-based architecture for future transport expansion
- Ensures consistent behavior across different transport mechanisms
- Supports transport preference configuration

## Interface Specifications

### Main API Classes

The core MCP API provides classes for managing servers and connections:

```typescript
export type MCPServer = {
  name: string;
  github: string;
  description: string;
  short_description: string;
  tags: string[];
};

export interface McpServerConfig {
  id: string;
  name: string;
  type: "stdio" | "http" | "adapter";
  command?: string;
  args?: string[];
  url?: string;
  enabled: boolean;
  env?: Record<string, string>;
  transportPreference?: "http" | "stdio";
  adapterConfig?: {
    originalType: "stdio" | "http";
    adapterPort?: number;
    useStdioAdapter?: boolean;
  };
}

export interface McpServerConnection {
  id: string;
  name: string;
  config: McpServerConfig;
  client?: Client;
  status: "connecting" | "connected" | "disconnected" | "error";
  error?: string;
  capabilities?: {
    tools?: Tool[];
    resources?: Resource[];
    prompts?: Prompt[];
  };
  lastConnected?: Date;
}

export interface McpState {
  servers: Record<string, McpServerConnection>;
  serverConfigs: Record<string, McpServerConfig>;
  availableTools: McpTool[];
  availableResources: McpResource[];
  availablePrompts: McpPrompt[];
  isLoading: boolean;
  lastUpdated: number;
  selectedServer: McpServerConnection | null;
  searchState: {
    query: string;
    selectedIndex: number;
    isSearchFocused: boolean;
  };
  installationState: {
    status: Record<string, boolean>;
    loading: Record<string, boolean>;
  };
}

export interface McpTool extends Tool {
  serverId: string;
  serverName: string;
}

export interface McpResource extends Resource {
  serverId: string;
  serverName: string;
}

export interface McpPrompt extends Prompt {
  serverId: string;
  serverName: string;
}
```

### MCP Client Manager

The primary class for managing MCP servers and connections:

```typescript
/**
 * MCP Client Manager for handling server connections and lifecycle
 */
export class MCPClientManager {
  /**
   * Initialize the MCP client manager
   */
  constructor(config?: MCPManagerConfig);

  /**
   * Connect to an MCP server
   */
  async connect(serverConfig: McpServerConfig): Promise<McpServerConnection>;

  /**
   * Disconnect from an MCP server
   */
  async disconnect(serverId: string): Promise<void>;

  /**
   * List available tools from connected servers
   */
  async listTools(): Promise<McpTool[]>;

  /**
   * List available resources from connected servers
   */
  async listResources(): Promise<McpResource[]>;

  /**
   * List available prompts from connected servers
   */
  async listPrompts(): Promise<McpPrompt[]>;

  /**
   * Get the current state of all servers
   */
  getState(): McpState;

  /**
   * Update server configuration
   */
  updateServerConfig(serverId: string, config: Partial<McpServerConfig>): void;

  /**
   * Remove a server configuration
   */
  removeServer(serverId: string): void;
}
```

### Configuration Management

The MCP package provides robust configuration management:

```typescript
// Standard MCP JSON configuration format
export interface McpJsonServerConfig {
  command?: string;
  args?: string[];
  url?: string;
  env?: Record<string, string>;
}

export interface McpJsonConfig {
  mcpServers: Record<string, McpJsonServerConfig>;
}

// Helper functions for configuration conversion
export function mcpJsonToServerConfig(
  name: string,
  jsonConfig: McpJsonServerConfig
): McpServerConfig;

export function serverConfigToMcpJson(config: McpServerConfig): McpJsonServerConfig;
```

## Transport Support

### Stdio Transport

- Supports local MCP servers that communicate via standard input/output
- Handles process lifecycle management
- Provides error handling for process crashes
- Supports argument passing and environment variable configuration

### HTTP Transport

- Supports remote MCP servers that communicate via HTTP
- Handles connection pooling and reuse
- Provides automatic retry mechanisms for transient failures
- Supports authentication and header configuration

### Adapter Transport

- Provides a bridge between different transport mechanisms
- Enables stdio servers to be accessed via HTTP
- Supports port configuration and process management
- Ensures consistent interface regardless of underlying transport

## Server Lifecycle Management

### Discovery

- Automatic discovery of available MCP servers
- Support for manual server registration
- Integration with standard MCP server registries
- Caching of server metadata for performance

### Connection Management

- Automatic connection establishment and maintenance
- Graceful handling of connection failures
- Reconnection with exponential backoff
- Connection pooling for efficient resource usage

### State Management

- Real-time tracking of server connection states
- Event-based notifications for state changes
- Persistence of server configurations
- Synchronization of state across multiple instances

## Error Handling

### Connection Errors

- Clear error messages for connection failures
- Automatic retry with configurable backoff
- Graceful degradation when servers are unavailable
- Detailed logging for debugging purposes

### Protocol Errors

- Proper handling of MCP protocol violations
- Validation of server responses
- Recovery from transient protocol issues
- Fallback mechanisms for critical operations

### Resource Errors

- Memory leak prevention through proper cleanup
- File descriptor management
- Process lifecycle management
- Resource usage monitoring and limits

## Security

### Transport Security

- Support for HTTPS connections
- Certificate validation and pinning
- Authentication token management
- Secure storage of sensitive configuration

### Process Isolation

- Sandboxed execution of MCP server processes
- Environment variable sanitization
- File system access restrictions
- Resource usage limits

### Data Protection

- Encryption of sensitive data at rest
- Secure transmission of credentials
- Audit logging of security-relevant events
- Compliance with data protection regulations

## Advanced Features

### Tool Management

- Automatic discovery of available tools
- Tool metadata extraction and caching
- Tool execution with proper error handling
- Integration with SAGE's tool ecosystem

### Resource Management

- Resource listing and metadata retrieval
- Content retrieval with proper error handling
- Caching of resource content for performance
- Integration with SAGE's resource access patterns

### Prompt Management

- Prompt listing and metadata retrieval
- Prompt argument validation
- Prompt execution with proper error handling
- Integration with SAGE's prompt workflows

## Testing Infrastructure

### Unit Testing

- Comprehensive coverage of core client manager functionality
- State management and configuration handling tests
- Transport-specific test cases
- Error handling and recovery tests

### Integration Testing

- Real MCP server process testing
- Concurrent operation testing
- Registry workflow validation
- Error recovery scenario testing

### End-to-End Testing

- Complete lifecycle management testing
- Installation to tool execution workflows
- Multi-server scenario testing
- Performance and scalability testing

## Future Extensions

This contract may be extended as MCP evolves to include:

- Additional transport mechanisms (WebSocket, gRPC, etc.)
- Enhanced security features (OAuth, mutual TLS, etc.)
- Advanced server management capabilities (clustering, load balancing, etc.)
- Integration with cloud-based MCP server providers
- Enhanced monitoring and observability features
- Support for MCP extensions and custom protocols

---

📦 # 📦 Package: test-utils (CONTRACT)

> **📁 Source File:** `packages/test-utils/CONTRACT.md` • *431 lines, 2818 tokens* • Hash: `88a08738`

# Test Utils Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/test-utils` package.

## Overview

`@sage/test-utils` provides batteries-included utilities for **fast, isolated, reproducible** tests across the SAGE monorepo. It ships temp-FS harnesses, in-memory adapters for Graph/Chronicle/LLM/Tools, deterministic clocks & RNG, CLI and Daemon simulators, and assertion helpers tailored to SAGE's **Principles & Protocols**.

This contract specifies the expected behavior, interfaces, and guarantees that the test-utils implementation must provide.

## Core Guarantees

### Determinism by Default

- Stable clocks with fixed time sources
- Seeded RNG for reproducible randomization
- Hermetic IO with no external dependencies
- Consistent behavior across multiple test runs

### Speed

- No disk/network unless explicitly enabled
- Everything has an in-memory variant
- Optimized for fast test execution
- Minimal overhead for test setup and teardown

### Ergonomics

- Minimal boilerplate to stand up agents/flows
- Good defaults for common test scenarios
- Intuitive APIs with clear method signatures
- Comprehensive documentation and examples

### Auditability

- Golden snapshots for Chronicles, ExecutionReports, and Graph diffs
- Clear diff output for test failures
- Deterministic snapshot content with sorted keys
- Stable timestamps and consistent formatting

## Interface Specifications

### Temp FS & Workspace Harnesses

```typescript
export interface TempWorkspace {
  root: string;
  file(path: string, content: string): Promise<void>;
  read(path: string): Promise<string>;
  tree(): Promise<Record<string, string>>;
  cleanup(): Promise<void>;
}

/**
 * Create a temporary workspace for testing
 */
export async function createTempWorkspace(options?: {
  prefix?: string;
  clock?: Clock;
}): Promise<TempWorkspace>;

/**
 * Write a file to a temporary workspace
 */
export async function writeFile(
  workspace: TempWorkspace,
  path: string,
  content: string
): Promise<void>;

/**
 * Read a file from a temporary workspace
 */
export async function readFile(
  workspace: TempWorkspace,
  path: string
): Promise<string>;

/**
 * Compare directory structure and contents
 */
export async function expectDirEquals(
  workspace: TempWorkspace,
  expected: Record<string, string>
): Promise<void>;

/**
 * Create a golden snapshot for comparison
 */
export async function golden(
  workspace: TempWorkspace,
  path: string
): Promise<void>;
```

### In-Memory Adapters

#### Graph Adapter (MVCC-lite)

```typescript
export interface GraphAdapter {
  ingest(options: {
    file: string;
    defines: string[];
    commit: string;
  }): Promise<void>;
  
  query<T>(
    cypher: string,
    params: Record<string, any>,
    options?: {
      commit?: string;
    }
  ): Promise<T[]>;
}

/**
 * Create an in-memory Graph adapter
 */
export function makeGraphAdapter(): GraphAdapter;
```

#### Chronicle Adapter (Append-Only)

```typescript
export interface ChronicleAdapter {
  append(
    path: string,
    event: ChronicleEvent
  ): Promise<void>;
  
  read(path: string): Promise<ChronicleEvent[]>;
  
  tail(
    path: string,
    n?: number
  ): Promise<ChronicleEvent[]>;
}

/**
 * Create an in-memory Chronicle adapter
 */
export function makeChronicle(): ChronicleAdapter;
```

#### LLM Adapter (Deterministic)

```typescript
export interface LLMClient {
  chat(options: ChatOptions): AsyncIterable<StreamEvent>;
}

/**
 * Create a deterministic LLM adapter
 */
export function makeLLM(options?: {
  seed?: number;
  tools?: Record<string, ToolExecutor>;
}): LLMClient;
```

#### Tools Adapter (Sandboxed Fakes)

```typescript
export interface ToolRegistry {
  get(name: string): Tool;
  register(tool: Tool): void;
  execute(name: string, input: any, context: ToolContext): Promise<any>;
}

/**
 * Create a tools adapter
 */
export function makeTools(options?: {
  readOnly?: boolean;
}): ToolRegistry;
```

### Agent Scenario DSL & Harnesses

```typescript
export interface Scenario {
  withWorkspace(
    setup: (ws: TempWorkspace) => Promise<void>
  ): Scenario;
  
  withGraph(): Scenario;
  
  withChronicle(): Scenario;
  
  withLLM(options?: {
    seed?: number;
  }): Scenario;
  
  withTools(options?: {
    readOnly?: boolean;
  }): Scenario;
  
  withGuardian(filePath: string): Scenario;
  
  withDelegator(): Scenario;
  
  sageDraftPlan(options: {
    goal: string;
  }): Promise<Plan>;
  
  guardian(filePath: string): Agent;
  
  delegator(): Agent;
  
  expectChronicle(path: string): ChronicleExpectation;
  
  expectGraph(query: string, params: any): GraphExpectation;
  
  flushDaemons(): Promise<void>;
}

export interface ChronicleExpectation {
  toContainEvent(event: Partial<ChronicleEvent>): Promise<void>;
}

export interface GraphExpectation {
  toReturn(rows: any[]): Promise<void>;
}

/**
 * Create a test scenario
 */
export async function scenario(): Promise<Scenario>;
```

### Protocol Matchers & Assertions

```typescript
export interface DirectoryMatcher {
  toEqualDir(expected: Record<string, string>): Promise<void>;
}

export interface ChronicleEventMatcher {
  toContainEvent(event: Partial<ChronicleEvent>): Promise<void>;
}

export interface GraphNodeMatcher {
  toBeCommitAddressable(): Promise<void>;
}

export interface TransactionMatcher {
  toRespectTransactionBoundary(): Promise<void>;
}

/**
 * Setup custom matchers for Vitest/Jest
 */
export function setupMatchers(): void;
```

## Temp FS & Workspace Harnesses

### Isolated Filesystem Testing

- Each test runs in a completely isolated temporary filesystem
- Unique temporary directories with configurable prefixes
- Automatic cleanup on test completion (success or failure)
- Path guards preventing writes outside workspace boundaries

### File Operations API

- `workspace.file(path, content)` for creating files
- `workspace.read(path)` for reading file contents
- `workspace.tree()` for getting complete directory structure
- Path validation and normalization utilities

### Directory Comparison & Diffing

- `expectDirEquals(workspace, expectedStructure)` matcher
- Pretty-printed diffs for directory structure mismatches
- File content comparison with unified diff output
- Handle binary files and large files gracefully

### Golden Snapshot Testing

- `golden(workspace, path)` saves/compares against snapshots
- Store snapshots in `__snapshots__/` directory next to tests
- Automatic snapshot creation in record mode
- Deterministic snapshot content (sorted keys, stable timestamps)

### Test Framework Integration

- Vitest/Jest integration with proper lifecycle hooks
- Automatic cleanup on test completion (success or failure)
- Concurrent test isolation (unique temp dirs)
- Memory leak prevention and resource cleanup

## In-Memory Adapters

### Graph Adapter (MVCC-lite)

- In-memory graph storage with commit tracking
- `first_seen`/`last_seen` indices for versioning
- Basic Cypher query resolver for common patterns
- Support for MATCH, WHERE, RETURN with simple node/edge patterns
- Commit-aware query filtering

### Chronicle Adapter (Append-Only)

- In-memory event storage with append-only semantics
- Event ID computation using canonical JSON hashing
- Idempotent append handling (skip duplicates)
- Time-ordered reads and tailing helpers
- Proper event validation

### LLM Adapter (Deterministic)

- Seeded token generation for reproducible outputs
- Tool call emission based on configured tool schemas
- Configurable response patterns and tool behaviors
- Usage tracking and streaming event synthesis
- Deterministic behavior across multiple runs

### Tools Adapter (Sandboxed Fakes)

- Fake implementations of Read, Write, Edit, Bash tools
- Configurable quotas, timeouts, and permission policies
- Dry-run mode support for mutation preview
- Execution tracking and result validation
- Error injection capabilities for failure testing

## Agent Scenario DSL & Harnesses

### End-to-End Agent Testing

- Stand up complete Plan/Approve/Delegate flows in one place
- Compose workspace, graph, chronicle, LLM, and tools in one setup
- Agent harnesses for Guardian and Delegator testing
- Scenario DSL for readable test definitions

### Agent Interaction Helpers

- `sc.sageDraftPlan({ goal })` to create plans
- `sc.guardian(filePath).reviewPlan(plan)` to review plans
- `sc.delegator.execute(plan)` to execute plans
- Assertion helpers for validating outcomes

### Expectation Helpers

- `sc.expectChronicle(path).toContainEvent(match)` for chronicle validation
- `sc.expectGraph(query, params).toReturn(rows)` for graph validation
- `sc.flushDaemons()` to deliver pending filesystem events

## Protocol Matchers & Assertions

### Custom Test Matchers

- `toEqualDir(expectedStructure)` for directory comparison
- `toContainEvent(eventLike)` for chronicle event matching
- `toBeCommitAddressable()` for graph node validation
- `toRespectTransactionBoundary()` for transaction validation

### Matcher Registration

- Automatic registration with Vitest/Jest
- Clear error messages with diff output
- Type-safe matcher implementations
- Integration with test framework reporting

## Clocks, RNG, and Time

### Deterministic Time Management

- `fixed(timestamp)` for frozen time sources
- `advance(clock, duration)` for time progression
- Integration with temp workspace creation
- Consistent timestamps across test runs

### Seeded Random Number Generation

- `withSeed(seed)` for reproducible randomness
- Integration with LLM token generation
- Consistent random sequences across runs
- Support for multiple RNG instances

## Error Handling

### Test Failure Reporting

- Clear error messages with context
- Pretty-printed diffs for comparison failures
- Stack traces with relevant source information
- Integration with test framework error reporting

### Resource Management

- Automatic cleanup of temporary files and directories
- Memory leak prevention through proper disposal
- Resource usage monitoring and limits
- Graceful handling of cleanup failures

## Advanced Features

### CLI Runner & Transcript Capture

- CLI runner (Ink) with transcript capture
- Mocks MCP/LLM providers for deterministic testing
- Captures streaming output deterministically
- UI matchers for `<Chat>` and tool-call renders

### Daemon Simulator

- Daemon event simulator & outage windows
- Emits `ROGUE_EDIT_DETECTED`, outage windows, and backfill passes
- Useful for Reconciliation & Bullet Wound scenarios
- Integration with chronicle and graph adapters

### CI Guidance

- Run unit tests with `--runInBand` for deterministic stdout ordering
- Prefer seeded LLM adapter in CI; disable external providers
- Cache `pnpm` store and `node_modules/.vite` to speed up UI tests
- Parallel test execution with proper isolation

## Future Extensions

This contract may be extended as test-utils evolves to include:

- Additional adapter implementations for new SAGE packages
- Enhanced scenario DSL with more complex agent interactions
- Advanced mocking capabilities for external dependencies
- Performance testing utilities and benchmarks
- Integration with cloud-based testing infrastructure
- Enhanced debugging and tracing capabilities
- Support for property-based testing and fuzzing

---

📦 # 📦 Package: tools (CONTRACT)

> **📁 Source File:** `packages/tools/CONTRACT.md` • *377 lines, 2388 tokens* • Hash: `1bb370be`

# Tools Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/tools` package.

## Overview

`@sage/tools` is a sandboxed, type-safe capability layer for SAGE agents. Each tool is a **well-defined, auditable action** with strongly-typed inputs and outputs. Tools are invoked via a central **registry** and described with **JSON Schema** for LLM tool-calling.

This contract specifies the expected behavior, interfaces, and guarantees that the tools implementation must provide.

## Core Guarantees

### Type Safety

- All inputs/outputs are validated using Zod and JSON Schema
- Strong typing ensures compile-time error detection
- Runtime validation prevents invalid inputs from reaching tool implementations
- Type inference provides excellent developer experience

### Principle of Least Power

- Tools are narrowly scoped with explicit permissions
- Each tool has a single, well-defined purpose
- Tools opt-in to mutating abilities rather than having broad permissions
- Permission system allows fine-grained access control

### Auditability

- Every call returns a machine-readable transcript (args, duration, exit status)
- Execution metadata includes timing, resource usage, and error information
- All tool calls are logged for debugging and monitoring
- Deterministic interfaces ensure reproducible behavior

### Deterministic Interfaces

- Stable schemas with semantic versioning per tool
- Consistent input/output formats across tool versions
- Backward compatibility within major version releases
- Clear deprecation policies for interface changes

## Interface Specifications

### Tool Interface

```typescript
export interface Tool<I, O> {
  name: string;
  description?: string;
  schema: JSONSchema; // for LLM tool-calls
  validate(input: unknown): I; // Zod runtime validation
  execute(input: I, ctx: ToolContext): Promise<ToolResult<O>>;
  version?: string; // semantic version per tool
}

export interface ToolContext {
  cwd: string;
  env?: Record<string, string>;
  dryRun?: boolean;
  permissions?: string[]; // e.g., ["fs:read", "fs:write:src/**"]
  logger?: (evt: ToolLog) => void;
  /**
   * An optional secret provider for just-in-time value injection.
   * If provided, the tool runner is responsible for placeholder substitution.
   */
  secretProvider?: import("@sage/utils").SecretProvider;
}

export interface ToolResult<T> {
  ok: boolean;
  data?: T;
  error?: { code: string; message: string };
  meta?: { startedAt: string; endedAt: string; durationMs: number };
}
```

### Tool Registry

```typescript
export interface ToolRegistry {
  /**
   * Register a tool in the registry
   */
  register(tool: Tool<any, any>): void;

  /**
   * Get a tool by name
   */
  get(name: string): Tool<any, any>;

  /**
   * Get all tool schemas for LLM tool-calling
   */
  getToolSchemas(): ToolSchema[];

  /**
   * Check if a tool is registered
   */
  has(name: string): boolean;

  /**
   * Remove a tool from the registry
   */
  remove(name: string): void;

  /**
   * Clear all tools from the registry
   */
  clear(): void;
}
```

### Standard Tools

#### Read Tool

```typescript
export interface ReadToolInput {
  file: string;
}

export interface ReadToolOutput {
  content: string;
}

/**
 * Create a Read tool instance
 */
export function createReadTool(): Tool<ReadToolInput, ReadToolOutput>;
```

#### Write Tool

```typescript
export interface WriteToolInput {
  file: string;
  content: string;
}

export interface WriteToolOutput {
  written: boolean;
}

/**
 * Create a Write tool instance
 */
export function createWriteTool(): Tool<WriteToolInput, WriteToolOutput>;
```

#### Edit Tool

```typescript
export interface EditToolInput {
  file: string;
  patch: string; // unified diff
  strategy?: "apply" | "check";
}

export interface EditToolOutput {
  applied: boolean;
  diff?: string;
}

/**
 * Create an Edit tool instance
 */
export function createEditTool(): Tool<EditToolInput, EditToolOutput>;
```

#### Bash Tool

```typescript
export interface BashToolInput {
  command: string;
  args?: string[];
}

export interface BashToolOutput {
  stdout: string;
  stderr: string;
  exitCode: number;
}

/**
 * Create a Bash tool instance
 */
export function createBashTool(): Tool<BashToolInput, BashToolOutput>;
```

#### GraphQuery Tool

```typescript
export interface GraphQueryToolInput {
  query: string;
  params?: Record<string, any>;
  commit?: string;
}

export interface GraphQueryToolOutput {
  results: any[];
}

/**
 * GraphQuery tool instance
 */
export const GraphQuery: Tool<GraphQueryToolInput, GraphQueryToolOutput>;
```

## Security & Sandboxing

### Process Isolation

- Child processes spawned with restricted environment and working directory
- Limited system resource access to prevent abuse
- Isolated execution contexts for each tool call
- Proper cleanup of temporary resources

### Allow/Deny Lists

- Per-tool and per-call command allowlists (e.g., `git`, `tsc` allowed; network calls denied)
- Configurable security policies for different environments
- Runtime validation of commands against allowlists
- Clear error messages for denied operations

### I/O Quotas

- Max stdout/stderr bytes to prevent resource exhaustion
- Execution timeouts to prevent hanging processes
- CPU and filesystem usage limits
- Graceful handling of quota violations

### Path Policies

- Prevent writes outside workspace to maintain isolation
- Protect `.sage/` directory by default (except Chronicle adapters)
- Validate all file paths against security policies
- Normalize and resolve paths to prevent directory traversal

### Dry-run Mode

- Simulate effects and return diffs without mutation
- Safe way to preview tool effects
- Useful for testing and validation
- Clear indication when in dry-run mode

## Secret Management (Vault-Warden Protocol)

### Secret Resolver Middleware

- Before a tool's `execute` method is called, a Secret Resolver middleware scans all string-based inputs for placeholders (e.g., `$ENV.GITHUB_API_KEY`)
- Just-in-time injection when a `secretProvider` is present in the `ToolContext`
- Redaction of secrets from any `stdout`, `stderr`, or `ToolResult` data after execution

### Secret Provider Interface

```typescript
/**
 * An interface for a provider that can resolve secret values from a secure backend.
 * This is the core of the Vault-Warden Protocol.
 */
export interface SecretProvider {
  /**
   * Fetches a secret value by its key.
   * @param key The identifier of the secret (e.g., "GITHUB_API_KEY").
   * @returns The secret value, or undefined if not found.
   */
  get(key: string): Promise<string | undefined>;
}
```

## Error Taxonomy

### EVALIDATION

- Input failed Zod/JSON Schema validation
- Clear error messages with validation details
- Early detection of invalid inputs
- Prevents invalid data from reaching tool implementations

### EPERMISSION

- Denied by permission or path policy
- Clear indication of which permission was denied
- Guidance on how to resolve permission issues
- Audit trail of permission checks

### ERUNTIME

- Tool threw during execution
- Proper error wrapping and context preservation
- Stack trace information for debugging
- Recovery strategies when possible

### ETIMEOUT

- Exceeded max execution time
- Configurable timeout values per tool
- Graceful termination of timed-out processes
- Clear error messages with timeout details

### EQUOTA

- stdout/stderr or file size limit exceeded
- Resource usage monitoring and limits
- Graceful handling of quota violations
- Clear error messages with quota details

## Patterns

### Transaction Boundary

- Delegator runs `Edit`/`Write` only inside a staging workspace
- Commit is atomic after validators pass
- Rollback on validation failures
- Isolated execution environments

### Read-only by Default

- Tools opt-in to mutating abilities
- Registry can be instantiated in read-only mode for brainstorming sessions
- Clear distinction between read and write operations
- Safe default behavior for exploratory use

### Deterministic Mode

- Disable time, randomness, and network for reproducible runs
- Useful for testing and debugging
- Configurable deterministic behavior
- Consistent outputs for identical inputs

## Advanced Features

### LLM Integration

- Tools described with JSON Schema for LLM tool-calling
- Automatic schema generation from Zod definitions
- Integration with @sage/llm for seamless tool usage
- Default auto-approval policy for read-only tools

### Testing Support

- Use @sage/test-utils to mount a temp workspace
- Inject mock adapters (Graph/Chronicle) for isolated testing
- Verify diffs before/after tool execution
- Deterministic testing with controlled inputs

### Custom Tool Definition

```typescript
export interface ToolDefinition<T extends z.ZodObject<any> = any> {
  name: string;
  description: string;
  parameters: T;
  implementation: (
    args: z.infer<T>,
    context: ToolContext
  ) => Promise<any>;
}

/**
 * Define a custom tool
 */
export function defineTool<T extends z.ZodObject<any>>(
  definition: ToolDefinition<T>
): Tool<z.infer<T>, any>;
```

## Future Extensions

This contract may be extended as tools evolves to include:

- Additional standard tools for common operations
- Enhanced security features and policies
- Advanced monitoring and observability capabilities
- Integration with cloud-based tool providers
- Support for streaming tool outputs
- Enhanced error recovery and retry mechanisms
- Advanced permission and access control features

---

📦 # 📦 Package: ui (CONTRACT)

> **📁 Source File:** `packages/ui/CONTRACT.md` • *452 lines, 2663 tokens* • Hash: `3ea4fc84`

# UI Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/ui` package.

## Overview

`@sage/ui` is a **renderer-agnostic** UI kit for SAGE. It exports **platform-neutral primitives** — `Text`, `Row`, `Column`, `Box`, etc. — and maps them to concrete renderers (CLI via Ink, Web via React DOM) behind the scenes. Components written against these primitives don't know (or care) whether they're in a terminal or a browser.

This contract specifies the expected behavior, interfaces, and guarantees that the UI implementation must provide.

## Core Guarantees

### Renderer-Agnostic

- No direct Ink or DOM imports in app code
- Components work consistently across CLI and Web renderers
- Renderer-specific logic is contained within adapters
- Same component code runs unchanged on both platforms

### Streaming-Ready

- Components accept async iterables and progressive updates
- Real-time rendering of streaming content
- Proper handling of incomplete or delayed data
- Smooth user experience during streaming operations

### Accessible by Default

- Reasonable roles/ARIA on Web for screen readers
- TTY-friendly fallbacks on CLI for terminal users
- Keyboard navigation support
- Semantic HTML structure on Web

### Themeable

- Shared theme object (tokens) applied consistently per renderer
- Customizable color schemes, spacing, and typography
- Runtime theme switching capabilities
- CSS variable mapping on Web, Ink style mapping on CLI

## Interface Specifications

### Core Primitives

```typescript
// Alignment types
export type Align = "start" | "center" | "end";

// Primitive component props
export interface TextProps {
  /** Text variant styling */
  variant?: "title" | "subtitle" | "body" | "mono";
  /** Dim the text */
  dim?: boolean;
  /** Bold text */
  bold?: boolean;
  /** Wrap text */
  wrap?: boolean;
  /** Text content */
  children?: ReactNode;
}

export interface RowProps {
  /** Gap between children */
  gap?: number;
  /** Alignment of children along the cross axis */
  align?: Align;
  /** Alignment of children along the main axis */
  justify?: Align;
  /** Row content */
  children?: ReactNode;
}

export interface ColumnProps {
  /** Gap between children */
  gap?: number;
  /** Alignment of children along the cross axis */
  align?: Align;
  /** Alignment of children along the main axis */
  justify?: Align;
  /** Column content */
  children?: ReactNode;
}

export interface BoxProps {
  /** Padding around content */
  padding?: number;
  /** Margin around the box */
  margin?: number;
  /** Show border */
  border?: boolean;
  /** Rounded corners */
  rounded?: boolean;
  /** Box content */
  children?: ReactNode;
}
```

### Higher-Level Components

```typescript
export interface ChatProps {
  /** Stream of events from @sage/llm */
  stream: AsyncIterable<StreamEvent>;
  /** Chat content */
  children?: ReactNode;
}

export interface AssistantTurnProps {
  /** Assistant turn content */
  children?: ReactNode;
}

export interface UserMessageProps {
  /** User message content */
  children?: ReactNode;
}

export interface ToolCallProps {
  /** Tool name */
  name: string;
  /** Tool arguments */
  args: any;
  /** Tool call result */
  result?: any;
}

export interface SpinnerProps {
  /** Spinner content */
  children?: ReactNode;
}
```

### Theme System

```typescript
export interface Theme {
  colors: {
    primary: string;
    dim: string;
    success: string;
    warning: string;
    error: string;
    background: string;
    text: string;
  };
  spacing: {
    xs: number;
    sm: number;
    md: number;
    lg: number;
  };
  borders: {
    radius: number;
    width: number;
  };
  typography: {
    fontSize: {
      title: number;
      subtitle: number;
      body: number;
      mono: number;
    };
    fontFamily: {
      sans: string;
      mono: string;
    };
  };
}

export interface ThemeProviderProps {
  value: Theme;
  children: ReactNode;
}
```

## Architecture

### Renderer Adapters

The UI package uses a adapter-based architecture to support multiple renderers:

```
App Code ─▶ @sage/ui primitives ─▶ Renderer Adapter (cli | web)
                                 └▶ Theme (tokens)
```

#### CLI Adapter

- Wraps primitives with Ink under the hood
- Maps theme tokens to Ink styles
- Provides TTY-friendly fallbacks
- Handles terminal-specific interactions

#### Web Adapter

- Wraps primitives with React DOM (div/span) and CSS
- Maps theme tokens to CSS variables
- Provides ARIA roles for accessibility
- Handles browser-specific interactions

### Component Implementation

All higher-level components are implemented **only** in terms of primitives (`Text`, `Row`, `Column`, `Box`) so they stay renderer-agnostic.

## Primitives

### Text

The Text primitive provides styled text rendering:

- `variant`: 'title' | 'subtitle' | 'body' | 'mono'
- `dim`: Boolean to dim the text
- `bold`: Boolean for bold text
- `wrap`: Boolean to control text wrapping

### Row

The Row primitive provides horizontal layout:

- `gap`: Number for spacing between children
- `align`: Alignment along the cross axis ('start' | 'center' | 'end')
- `justify`: Alignment along the main axis ('start' | 'center' | 'end')

### Column

The Column primitive provides vertical layout:

- `gap`: Number for spacing between children
- `align`: Alignment along the cross axis ('start' | 'center' | 'end')
- `justify`: Alignment along the main axis ('start' | 'center' | 'end')

### Box

The Box primitive provides container styling:

- `padding`: Number for padding around content
- `margin`: Number for margin around the box
- `border`: Boolean to show border
- `rounded`: Boolean for rounded corners

## Higher-Level Components

### Chat

Renders a conversation stream accepting `AsyncIterable<StreamEvent>` from `@sage/llm`:

- Real-time rendering of streaming content
- Proper handling of different event types
- Smooth scrolling and focus management
- Error handling and recovery

### AssistantTurn / UserMessage

Message wrappers for assistant and user messages:

- Distinct styling for different message types
- Proper attribution and ordering
- Support for rich content types
- Accessibility features

### ToolCall

Shows tool invocations with live results:

- Clear display of tool name and arguments
- Real-time updating of tool results
- Error state handling
- Collapsible/expandable sections

### Spinner

Renderer-appropriate busy indicator:

- Platform-specific spinner animations
- Consistent sizing and positioning
- Accessible loading indicators
- Customizable appearance

## Theming

### Theme Tokens

The theme system uses a shared theme object with tokens for:

- Colors: primary, dim, success, warning, error, background, text
- Spacing: xs, sm, md, lg
- Borders: radius, width
- Typography: fontSize, fontFamily

### Theme Provider

The ThemeProvider component allows runtime theme switching:

- Context-based theme distribution
- Default theme fallbacks
- Theme merging capabilities
- Performance-optimized updates

## Streaming Patterns

### Async Iterable Support

Components accept `AsyncIterable<StreamEvent>` for real-time rendering:

- Proper handling of incomplete or delayed data
- Memory-efficient rendering of large streams
- Graceful error handling and recovery
- Cleanup of resources on unmount

### Event Handling

Different event types from `@sage/llm` are handled appropriately:

- Text events render as streaming text
- Tool call events render as tool invocation UI
- Tool result events update tool call UI
- Error events render as error messages

## Usage Patterns

### Adapter Selection

Choose an adapter once at your app's entrypoint:

```tsx
// CLI entry (apps/cli)
import { render } from "ink";
import { UI } from "@sage/ui/cli"; // uses Ink under the hood

render(<UI.App />);

// Web entry (future dev server)
import { createRoot } from "react-dom/client";
import { UI } from "@sage/ui/web"; // uses React DOM under the hood

createRoot(document.getElementById("root")!).render(<UI.App />);
```

### Component Composition

Prefer `Row`/`Column` composition over ad-hoc layout props:

```tsx
// Good - Clear composition
<Column gap={1}>
  <Row gap={1} align="center">
    <Text variant="title">Title</Text>
    <Text dim>Subtitle</Text>
  </Row>
  <Text>Content</Text>
</Column>

// Avoid - Ad-hoc layout
<div style={{ display: "flex", flexDirection: "column", gap: 8 }}>
  <div style={{ display: "flex", alignItems: "center", gap: 4 }}>
    <span style={{ fontSize: 24 }}>Title</span>
    <span style={{ opacity: 0.6 }}>Subtitle</span>
  </div>
  <p>Content</p>
</div>
```

## Testing

### Component Testing

- Components are pure React and testable with React Testing Library
- Snapshot both adapters to ensure parity across CLI/Web renderers
- Test accessibility features with axe-core or similar tools
- Verify streaming behavior with mock async iterables

### Adapter Testing

- Test adapter implementations separately
- Verify theme token mapping
- Ensure consistent rendering across platforms
- Test edge cases and error conditions

## Advanced Features

### Custom Primitives

The system supports extending with custom primitives:

```typescript
interface CustomComponentProps {
  // Custom props
}

const CustomComponent = (props: CustomComponentProps) => {
  // Implementation using existing primitives
  return (
    <Box border padding={1}>
      <Text variant="body">{props.children}</Text>
    </Box>
  );
};
```

### Dynamic Theming

Runtime theme switching with smooth transitions:

```tsx
const ThemedApp = () => {
  const [theme, setTheme] = useState(lightTheme);
  
  return (
    <ThemeProvider value={theme}>
      <App />
      <button onClick={() => setTheme(theme === lightTheme ? darkTheme : lightTheme)}>
        Toggle Theme
      </button>
    </ThemeProvider>
  );
};
```

### Responsive Design

Adaptive layouts that work across different screen sizes:

```tsx
const ResponsiveLayout = () => {
  const isMobile = useMediaQuery("(max-width: 768px)");
  
  return isMobile ? (
    <Column gap={1}>
      <Content />
    </Column>
  ) : (
    <Row gap={2}>
      <Sidebar />
      <Content />
    </Row>
  );
};
```

## Future Extensions

This contract may be extended as UI evolves to include:

- Additional primitives for common UI patterns
- Advanced theming capabilities with dark mode support
- Internationalization and localization features
- Animation and transition support
- Advanced layout primitives (Grid, Flex, etc.)
- Integration with design system libraries
- Enhanced accessibility features
- Performance optimizations for large component trees

---

📦 # 📦 Package: utils (CONTRACT)

> **📁 Source File:** `packages/utils/CONTRACT.md` • *364 lines, 2362 tokens* • Hash: `dcd48430`

# Utils Contract

This document defines the behavioral guarantees and interface specifications for the `@sage/utils` package.

## Overview

This package provides the foundational utilities that all other SAGE packages depend on. It includes shared types, error handling, canonicalization helpers, and time/random abstractions needed for deterministic testing.

This contract specifies the expected behavior, interfaces, and guarantees that the utils implementation must provide.

## Core Guarantees

### Minimal Dependencies

- Zero runtime dependencies outside of the standard library
- No I/O operations unless explicitly needed
- No framework assumptions or tight coupling
- Pure utility functions with no side effects

### Deterministic Operations

- Time abstractions with predictable behavior
- Seeded random number generation for reproducible results
- Consistent hashing and canonicalization
- Stable type definitions across versions

### Type Safety

- Strongly typed interfaces and utilities
- Compile-time error detection
- Runtime validation where needed
- Clear error taxonomy and handling

### Performance

- Optimized utility functions
- Minimal memory footprint
- Efficient serialization and hashing
- Fast error creation and handling

## Interface Specifications

### Core Types

```typescript
export type ISO8601 = string & { __brand: 'ISO8601' };

export interface Clock {
  now(): ISO8601;
}

export interface Random {
  int(): number;
  float(): number;
}

export interface TypedError extends Error {
  code: string;
  cause?: unknown;
}

/**
 * An interface for a provider that can resolve secret values from a secure backend.
 * This is the core of the Vault-Warden Protocol.
 */
export interface SecretProvider {
  /**
   * Fetches a secret value by its key.
   * @param key The identifier of the secret (e.g., "GITHUB_API_KEY").
   * @returns The secret value, or undefined if not found.
   */
  get(key: string): Promise<string | undefined>;
}
```

### Error Handling

```typescript
export class ErrorCodes {
  static readonly VALIDATION = "EVALIDATION";
  static readonly IO = "EIO";
  static readonly NETWORK = "ENETWORK";
  static readonly PARSE = "EPARSE";
  static readonly TIMEOUT = "ETIMEOUT";
  static readonly PERMISSION = "EPERMISSION";
  static readonly NOT_FOUND = "ENOTFOUND";
  static readonly CONFLICT = "ECONFLICT";
  static readonly UNAVAILABLE = "EUNAVAILABLE";
  static readonly UNSUPPORTED = "EUNSUPPORTED";
  static readonly INVALID_STATE = "EINVALIDSTATE";
  static readonly QUOTA = "EQUOTA";
  static readonly RATE_LIMIT = "ERATELIMIT";
  static readonly SECURITY = "ESECURITY";
  static readonly CONFIG = "ECONFIG";
  static readonly DEPRECATED = "EDEPRECATED";
  static readonly INTERNAL = "EINTERNAL";
}

export function err(
  code: string,
  message: string,
  meta?: Record<string, any>
): TypedError;

export function isTypedError(error: unknown): error is TypedError;

export function isErrorCode(error: TypedError, code: string): boolean;

export function serializeError(error: Error): string;

export function formatErrorMessage(error: TypedError): string;
```

### Canonicalization and Crypto

```typescript
export function canonicalJSONStringify(obj: any): string;

export function sha256(content: string): Promise<string>;
```

### Clock and Random

```typescript
export class SystemClock implements Clock {
  now(): ISO8601;
}

export class FixedClock implements Clock {
  now(): ISO8601;
}

export class SystemRandom implements Random {
  int(): number;
  float(): number;
}

export class SeededRandom implements Random {
  int(): number;
  float(): number;
}
```

### Logging

```typescript
export class Logger {
  constructor(serviceName?: string, logFileName?: string);
  
  info(message: string, ...meta: any[]): void;
  warn(message: string, ...meta: any[]): void;
  error(message: string, ...meta: any[]): void;
  debug(message: string, ...meta: any[]): void;
  
  clearLogFile(): void;
}
```

## Core Types and Interfaces

### ISO8601

A branded string type for ISO 8601 formatted timestamps:

- Ensures type safety for timestamp values
- Prevents accidental string concatenation with non-timestamps
- Provides consistent timestamp format across the ecosystem

### Clock

An interface for time abstraction:

- `now()`: Returns the current time as an ISO8601 string
- Enables deterministic testing with FixedClock
- Supports system time with SystemClock

### Random

An interface for random number generation:

- `int()`: Returns a random integer
- `float()`: Returns a random float between 0 and 1
- Enables deterministic testing with SeededRandom
- Supports system randomness with SystemRandom

### TypedError

An interface for typed errors:

- Extends the standard Error interface
- Includes a code property for error categorization
- Optional cause property for error chaining
- Enables structured error handling across packages

### SecretProvider

An interface for secret resolution:

- Core of the Vault-Warden Protocol
- Enables just-in-time secret injection
- Supports secure secret management
- Prevents secret leakage in logs and storage

## Error Handling

### Error Codes

A comprehensive taxonomy of error codes:

- `EVALIDATION`: Input validation errors
- `EIO`: Input/output errors
- `ENETWORK`: Network-related errors
- `EPARSE`: Parsing errors
- `ETIMEOUT`: Timeout errors
- `EPERMISSION`: Permission denied errors
- `ENOTFOUND`: Resource not found errors
- `ECONFLICT`: Resource conflict errors
- `EUNAVAILABLE`: Service unavailable errors
- `EUNSUPPORTED`: Unsupported operation errors
- `EINVALIDSTATE`: Invalid state errors
- `EQUOTA`: Quota exceeded errors
- `ERATELIMIT`: Rate limit exceeded errors
- `ESECURITY`: Security-related errors
- `ECONFIG`: Configuration errors
- `EDEPRECATED`: Use of deprecated features
- `EINTERNAL`: Internal errors

### Error Creation

Utilities for creating typed errors:

- `err()`: Creates a new TypedError with code, message, and metadata
- Consistent error structure across the ecosystem
- Support for error metadata and context
- Proper stack trace preservation

### Error Checking

Utilities for checking error types:

- `isTypedError()`: Type guard for TypedError instances
- `isErrorCode()`: Checks if an error has a specific code
- Enables safe error handling in TypeScript
- Supports error pattern matching

### Error Serialization

Utilities for serializing errors:

- `serializeError()`: Converts an error to a string representation
- `formatErrorMessage()`: Formats an error message for display
- Preserves error metadata and context
- Supports cross-process error communication

## Canonicalization and Crypto

### Canonical JSON

Utilities for canonical JSON serialization:

- `canonicalJSONStringify()`: Serializes objects to canonical JSON
- Ensures consistent key ordering
- Removes whitespace and formatting
- Supports deterministic hashing

### SHA-256

Cryptographic hashing utilities:

- `sha256()`: Computes SHA-256 hash of content
- Returns hexadecimal string representation
- Supports async operations
- Uses platform-native crypto when available

## Clock and Random

### System Implementations

Platform-native implementations:

- `SystemClock`: Uses system time for real-world applications
- `SystemRandom`: Uses system randomness for real-world applications
- Provides high-quality entropy sources
- Supports production environments

### Deterministic Implementations

Controlled implementations for testing:

- `FixedClock`: Returns a fixed time for deterministic testing
- `SeededRandom`: Uses a seed for reproducible random sequences
- Enables consistent test results
- Supports debugging and reproduction

## Advanced Features

### Directory Management

Utilities for directory operations:

- Cross-platform path handling
- Directory creation and cleanup
- Temporary directory management
- Secure file operations

### TTY Utilities

Terminal detection and handling:

- `checkTTY()`: Determines if running in a TTY environment
- Enables adaptive UI behavior
- Supports both terminal and non-terminal environments
- Facilitates testing and automation

### Progress Tracking

Utilities for progress indication:

- Progress tracking with percentage completion
- ETA calculation and display
- Supports both terminal and non-terminal environments
- Configurable update intervals

### Pretty Task Execution

Utilities for task execution with formatting:

- Formatted task execution with status updates
- Success and failure handling
- Supports both synchronous and asynchronous tasks
- Configurable output formatting

## Testing Support

### Deterministic Testing

Support for reproducible tests:

- Fixed time sources for consistent timestamps
- Seeded random number generation
- Mock implementations for external dependencies
- Isolated test environments

### Error Testing

Support for error condition testing:

- Comprehensive error taxonomy
- Easy error creation for test scenarios
- Error pattern matching utilities
- Mock error injection capabilities

## Future Extensions

This contract may be extended as utils evolves to include:

- Additional utility functions for common operations
- Enhanced error handling and reporting features
- Advanced cryptographic primitives
- Internationalization and localization utilities
- Performance monitoring and profiling tools
- Advanced logging and tracing capabilities
- Enhanced security utilities
- Integration with external utility libraries

---

